{"version":3,"file":"speech-commands.esm.js","sources":["../src/browser_fft_utils.ts","../src/browser_fft_extractor.ts","../src/generic_utils.ts","../src/training_utils.ts","../src/dataset.ts","../src/version.ts","../src/browser_fft_recognizer.ts","../src/index.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs';\nimport {promisify} from 'util';\n\nimport {RawAudioData} from './types';\n\nexport async function loadMetadataJson(url: string):\n    Promise<{wordLabels: string[]}> {\n  const HTTP_SCHEME = 'http://';\n  const HTTPS_SCHEME = 'https://';\n  const FILE_SCHEME = 'file://';\n  if (url.indexOf(HTTP_SCHEME) === 0 || url.indexOf(HTTPS_SCHEME) === 0) {\n    const response = await fetch(url);\n    const parsed = await response.json();\n    return parsed;\n  } else if (url.indexOf(FILE_SCHEME) === 0) {\n    // tslint:disable-next-line:no-require-imports\n    const fs = require('fs');\n    const readFile = promisify(fs.readFile);\n\n    return JSON.parse(\n        await readFile(url.slice(FILE_SCHEME.length), {encoding: 'utf-8'}));\n  } else {\n    throw new Error(\n        `Unsupported URL scheme in metadata URL: ${url}. ` +\n        `Supported schemes are: http://, https://, and ` +\n        `(node.js-only) file://`);\n  }\n}\n\nlet EPSILON: number = null;\n\n/**\n * Normalize the input into zero mean and unit standard deviation.\n *\n * This function is safe against divison-by-zero: In case the standard\n * deviation is zero, the output will be all-zero.\n *\n * @param x Input tensor.\n * @param y Output normalized tensor.\n */\nexport function normalize(x: tf.Tensor): tf.Tensor {\n  if (EPSILON == null) {\n    EPSILON = tf.backend().epsilon();\n  }\n  return tf.tidy(() => {\n    const {mean, variance} = tf.moments(x);\n    // Add an EPSILON to the denominator to prevent division-by-zero.\n    return x.sub(mean).div(variance.sqrt().add(EPSILON));\n  });\n}\n\n/**\n * Z-Normalize the elements of a Float32Array.\n *\n * Subtract the mean and divide the result by the standard deviation.\n *\n * @param x The Float32Array to normalize.\n * @return Noramlzied Float32Array.\n */\nexport function normalizeFloat32Array(x: Float32Array): Float32Array {\n  if (x.length < 2) {\n    throw new Error(\n        'Cannot normalize a Float32Array with fewer than 2 elements.');\n  }\n  if (EPSILON == null) {\n    EPSILON = tf.backend().epsilon();\n  }\n  return tf.tidy(() => {\n    const {mean, variance} = tf.moments(tf.tensor1d(x));\n    const meanVal = mean.arraySync() as number;\n    const stdVal = Math.sqrt(variance.arraySync() as number);\n    const yArray = Array.from(x).map(y => (y - meanVal) / (stdVal + EPSILON));\n    return new Float32Array(yArray);\n  });\n}\n\nexport function getAudioContextConstructor(): AudioContext {\n  // tslint:disable-next-line:no-any\n  return (window as any).AudioContext || (window as any).webkitAudioContext;\n}\n\nexport async function getAudioMediaStream(\n    audioTrackConstraints?: MediaTrackConstraints): Promise<MediaStream> {\n  return navigator.mediaDevices.getUserMedia({\n    audio: audioTrackConstraints == null ? true : audioTrackConstraints,\n    video: false\n  });\n}\n\n/**\n * Play raw audio waveform\n * @param rawAudio Raw audio data, including the waveform and the sampling rate.\n * @param onEnded Callback function to execute when the playing ends.\n */\nexport function playRawAudio(\n    rawAudio: RawAudioData, onEnded: () => void|Promise<void>): void {\n  const audioContextConstructor =\n      // tslint:disable-next-line:no-any\n      (window as any).AudioContext || (window as any).webkitAudioContext;\n  const audioContext: AudioContext = new audioContextConstructor();\n  const arrayBuffer =\n      audioContext.createBuffer(1, rawAudio.data.length, rawAudio.sampleRateHz);\n  const nowBuffering = arrayBuffer.getChannelData(0);\n  nowBuffering.set(rawAudio.data);\n  const source = audioContext.createBufferSource();\n  source.buffer = arrayBuffer;\n  source.connect(audioContext.destination);\n  source.start();\n  source.onended = () => {\n    if (onEnded != null) {\n      onEnded();\n    }\n  };\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Audio FFT Feature Extractor based on Browser-Native FFT.\n */\n\nimport * as tf from '@tensorflow/tfjs';\n\nimport {getAudioContextConstructor, getAudioMediaStream} from './browser_fft_utils';\nimport {FeatureExtractor, RecognizerParams} from './types';\n\nexport type SpectrogramCallback = (freqData: tf.Tensor, timeData?: tf.Tensor) =>\n    Promise<boolean>;\n\n/**\n * Configurations for constructing BrowserFftFeatureExtractor.\n */\nexport interface BrowserFftFeatureExtractorConfig extends RecognizerParams {\n  /**\n   * Number of audio frames (i.e., frequency columns) per spectrogram.\n   */\n  numFramesPerSpectrogram: number;\n\n  /**\n   * Suppression period in milliseconds.\n   *\n   * How much time to rest (not call the spectrogramCallback) every time\n   * a word with probability score above threshold is recognized.\n   */\n  suppressionTimeMillis: number;\n\n  /**\n   * A callback that is invoked every time a full spectrogram becomes\n   * available.\n   *\n   * `x` is a single-example tf.Tensor instance that includes the batch\n   * dimension.\n   * The return value is assumed to be whether a flag for whether the\n   * suppression period should initiate, e.g., when a word is recognized.\n   */\n  spectrogramCallback: SpectrogramCallback;\n\n  /**\n   * Truncate each spectrogram column at how many frequency points.\n   *\n   * If `null` or `undefined`, will do no truncation.\n   */\n  columnTruncateLength?: number;\n\n  /**\n   * Overlap factor. Must be >=0 and <1.\n   * For example, if the model takes a frame length of 1000 ms,\n   * and if overlap factor is 0.4, there will be a 400ms\n   * overlap between two successive frames, i.e., frames\n   * will be taken every 600 ms.\n   */\n  overlapFactor: number;\n\n  /**\n   * Whether to collect the raw time-domain audio waveform in addition to the\n   * spectrogram.\n   *\n   * Default: `false`.\n   */\n  includeRawAudio?: boolean;\n}\n\n/**\n * Audio feature extractor based on Browser-native FFT.\n *\n * Uses AudioContext and analyser node.\n */\nexport class BrowserFftFeatureExtractor implements FeatureExtractor {\n  // Number of frames (i.e., columns) per spectrogram used for classification.\n  readonly numFrames: number;\n\n  // Audio sampling rate in Hz.\n  readonly sampleRateHz: number;\n\n  // The FFT length for each spectrogram column.\n  readonly fftSize: number;\n\n  // Truncation length for spectrogram columns.\n  readonly columnTruncateLength: number;\n\n  // Overlapping factor: the ratio between the temporal spacing between\n  // consecutive spectrograms and the length of each individual spectrogram.\n  readonly overlapFactor: number;\n  readonly includeRawAudio: boolean;\n\n  private readonly spectrogramCallback: SpectrogramCallback;\n\n  private stream: MediaStream;\n  // tslint:disable-next-line:no-any\n  private audioContextConstructor: any;\n  private audioContext: AudioContext;\n  private analyser: AnalyserNode;\n  private tracker: Tracker;\n  private freqData: Float32Array;\n  private timeData: Float32Array;\n  private freqDataQueue: Float32Array[];\n  private timeDataQueue: Float32Array[];\n  // tslint:disable-next-line:no-any\n  private frameIntervalTask: any;\n  private frameDurationMillis: number;\n\n  private suppressionTimeMillis: number;\n\n  /**\n   * Constructor of BrowserFftFeatureExtractor.\n   *\n   * @param config Required configuration object.\n   */\n  constructor(config: BrowserFftFeatureExtractorConfig) {\n    if (config == null) {\n      throw new Error(\n          `Required configuration object is missing for ` +\n          `BrowserFftFeatureExtractor constructor`);\n    }\n\n    if (config.spectrogramCallback == null) {\n      throw new Error(`spectrogramCallback cannot be null or undefined`);\n    }\n\n    if (!(config.numFramesPerSpectrogram > 0)) {\n      throw new Error(\n          `Invalid value in numFramesPerSpectrogram: ` +\n          `${config.numFramesPerSpectrogram}`);\n    }\n\n    if (config.suppressionTimeMillis < 0) {\n      throw new Error(\n          `Expected suppressionTimeMillis to be >= 0, ` +\n          `but got ${config.suppressionTimeMillis}`);\n    }\n    this.suppressionTimeMillis = config.suppressionTimeMillis;\n\n    this.spectrogramCallback = config.spectrogramCallback;\n    this.numFrames = config.numFramesPerSpectrogram;\n    this.sampleRateHz = config.sampleRateHz || 44100;\n    this.fftSize = config.fftSize || 1024;\n    this.frameDurationMillis = this.fftSize / this.sampleRateHz * 1e3;\n    this.columnTruncateLength = config.columnTruncateLength || this.fftSize;\n    this.overlapFactor = config.overlapFactor;\n    this.includeRawAudio = config.includeRawAudio;\n\n    tf.util.assert(\n        this.overlapFactor >= 0 && this.overlapFactor < 1,\n        () => `Expected overlapFactor to be >= 0 and < 1, ` +\n            `but got ${this.overlapFactor}`);\n\n    if (this.columnTruncateLength > this.fftSize) {\n      throw new Error(\n          `columnTruncateLength ${this.columnTruncateLength} exceeds ` +\n          `fftSize (${this.fftSize}).`);\n    }\n\n    this.audioContextConstructor = getAudioContextConstructor();\n  }\n\n  async start(audioTrackConstraints?: MediaTrackConstraints):\n      Promise<Float32Array[]|void> {\n    if (this.frameIntervalTask != null) {\n      throw new Error(\n          'Cannot start already-started BrowserFftFeatureExtractor');\n    }\n\n    this.stream = await getAudioMediaStream(audioTrackConstraints);\n\n    this.audioContext = new this.audioContextConstructor() as AudioContext;\n    if (this.audioContext.sampleRate !== this.sampleRateHz) {\n      console.warn(\n          `Mismatch in sampling rate: ` +\n          `Expected: ${this.sampleRateHz}; ` +\n          `Actual: ${this.audioContext.sampleRate}`);\n    }\n    const streamSource = this.audioContext.createMediaStreamSource(this.stream);\n    this.analyser = this.audioContext.createAnalyser();\n    this.analyser.fftSize = this.fftSize * 2;\n    this.analyser.smoothingTimeConstant = 0.0;\n    streamSource.connect(this.analyser);\n    // Reset the queue.\n    this.freqDataQueue = [];\n    this.freqData = new Float32Array(this.fftSize);\n    if (this.includeRawAudio) {\n      this.timeDataQueue = [];\n      this.timeData = new Float32Array(this.fftSize);\n    }\n    const period =\n        Math.max(1, Math.round(this.numFrames * (1 - this.overlapFactor)));\n    this.tracker = new Tracker(\n        period,\n        Math.round(this.suppressionTimeMillis / this.frameDurationMillis));\n    this.frameIntervalTask = setInterval(\n        this.onAudioFrame.bind(this), this.fftSize / this.sampleRateHz * 1e3);\n  }\n\n  private async onAudioFrame() {\n    this.analyser.getFloatFrequencyData(this.freqData);\n    if (this.freqData[0] === -Infinity) {\n      return;\n    }\n\n    this.freqDataQueue.push(this.freqData.slice(0, this.columnTruncateLength));\n    if (this.includeRawAudio) {\n      this.analyser.getFloatTimeDomainData(this.timeData);\n      this.timeDataQueue.push(this.timeData.slice());\n    }\n    if (this.freqDataQueue.length > this.numFrames) {\n      // Drop the oldest frame (least recent).\n      this.freqDataQueue.shift();\n    }\n    const shouldFire = this.tracker.tick();\n    if (shouldFire) {\n      const freqData = flattenQueue(this.freqDataQueue);\n      const freqDataTensor = getInputTensorFromFrequencyData(\n          freqData, [1, this.numFrames, this.columnTruncateLength, 1]);\n      let timeDataTensor: tf.Tensor;\n      if (this.includeRawAudio) {\n        const timeData = flattenQueue(this.timeDataQueue);\n        timeDataTensor = getInputTensorFromFrequencyData(\n            timeData, [1, this.numFrames * this.fftSize]);\n      }\n      const shouldRest =\n          await this.spectrogramCallback(freqDataTensor, timeDataTensor);\n      if (shouldRest) {\n        this.tracker.suppress();\n      }\n      tf.dispose([freqDataTensor, timeDataTensor]);\n    }\n  }\n\n  async stop(): Promise<void> {\n    if (this.frameIntervalTask == null) {\n      throw new Error(\n          'Cannot stop because there is no ongoing streaming activity.');\n    }\n    clearInterval(this.frameIntervalTask);\n    this.frameIntervalTask = null;\n    this.analyser.disconnect();\n    this.audioContext.close();\n    if (this.stream != null && this.stream.getTracks().length > 0) {\n      this.stream.getTracks()[0].stop();\n    }\n  }\n\n  setConfig(params: RecognizerParams) {\n    throw new Error(\n        'setConfig() is not implemented for BrowserFftFeatureExtractor.');\n  }\n\n  getFeatures(): Float32Array[] {\n    throw new Error(\n        'getFeatures() is not implemented for ' +\n        'BrowserFftFeatureExtractor. Use the spectrogramCallback ' +\n        'field of the constructor config instead.');\n  }\n}\n\nexport function flattenQueue(queue: Float32Array[]): Float32Array {\n  const frameSize = queue[0].length;\n  const freqData = new Float32Array(queue.length * frameSize);\n  queue.forEach((data, i) => freqData.set(data, i * frameSize));\n  return freqData;\n}\n\nexport function getInputTensorFromFrequencyData(\n    freqData: Float32Array, shape: number[]): tf.Tensor {\n  const vals = new Float32Array(tf.util.sizeFromShape(shape));\n  // If the data is less than the output shape, the rest is padded with zeros.\n  vals.set(freqData, vals.length - freqData.length);\n  return tf.tensor(vals, shape);\n}\n\n/**\n * A class that manages the firing of events based on periods\n * and suppression time.\n */\nexport class Tracker {\n  readonly period: number;\n  readonly suppressionTime: number;\n\n  private counter: number;\n  private suppressionOnset: number;\n\n  /**\n   * Constructor of Tracker.\n   *\n   * @param period The event-firing period, in number of frames.\n   * @param suppressionPeriod The suppression period, in number of frames.\n   */\n  constructor(period: number, suppressionPeriod: number) {\n    this.period = period;\n    this.suppressionTime = suppressionPeriod == null ? 0 : suppressionPeriod;\n    this.counter = 0;\n\n    tf.util.assert(\n        this.period > 0,\n        () => `Expected period to be positive, but got ${this.period}`);\n  }\n\n  /**\n   * Mark a frame.\n   *\n   * @returns Whether the event should be fired at the current frame.\n   */\n  tick(): boolean {\n    this.counter++;\n    const shouldFire = (this.counter % this.period === 0) &&\n        (this.suppressionOnset == null ||\n         this.counter - this.suppressionOnset > this.suppressionTime);\n    return shouldFire;\n  }\n\n  /**\n   * Order the beginning of a supression period.\n   */\n  suppress() {\n    this.suppressionOnset = this.counter;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers A number of array buffers to concatenate.\n * @returns Result of concatenating `buffers` in order.\n */\nexport function concatenateArrayBuffers(buffers: ArrayBuffer[]): ArrayBuffer {\n  let totalByteLength = 0;\n  buffers.forEach((buffer: ArrayBuffer) => {\n    totalByteLength += buffer.byteLength;\n  });\n\n  const temp = new Uint8Array(totalByteLength);\n  let offset = 0;\n  buffers.forEach((buffer: ArrayBuffer) => {\n    temp.set(new Uint8Array(buffer), offset);\n    offset += buffer.byteLength;\n  });\n  return temp.buffer;\n}\n\n/**\n * Concatenate Float32Arrays.\n *\n * @param xs Float32Arrays to concatenate.\n * @return The result of the concatenation.\n */\nexport function concatenateFloat32Arrays(xs: Float32Array[]): Float32Array {\n  let totalLength = 0;\n  xs.forEach(x => totalLength += x.length);\n  const concatenated = new Float32Array(totalLength);\n  let index = 0;\n  xs.forEach(x => {\n    concatenated.set(x, index);\n    index += x.length;\n  });\n  return concatenated;\n}\n\n/** Encode a string as an ArrayBuffer. */\nexport function string2ArrayBuffer(str: string): ArrayBuffer {\n  if (str == null) {\n    throw new Error('Received null or undefind string');\n  }\n  // NOTE(cais): This implementation is inefficient in terms of memory.\n  // But it works for UTF-8 strings. Just don't use on for very long strings.\n  const strUTF8 = unescape(encodeURIComponent(str));\n  const buf = new Uint8Array(strUTF8.length);\n  for (let i = 0; i < strUTF8.length; ++i) {\n    buf[i] = strUTF8.charCodeAt(i);\n  }\n  return buf.buffer;\n}\n\n/** Decode an ArrayBuffer as a string. */\nexport function arrayBuffer2String(buffer: ArrayBuffer): string {\n  if (buffer == null) {\n    throw new Error('Received null or undefind buffer');\n  }\n  const buf = new Uint8Array(buffer);\n  return decodeURIComponent(escape(String.fromCharCode(...buf)));\n}\n\n/** Generate a pseudo-random UID. */\nexport function getUID(): string {\n  function s4() {\n    return Math.floor((1 + Math.random()) * 0x10000).toString(16).substring(1);\n  }\n  return s4() + s4() + '-' + s4() + '-' + s4() + '-' + s4() + '-' + s4() +\n      s4() + s4();\n}\n\nexport function getRandomInteger(min: number, max: number): number {\n  return Math.floor((max - min) * Math.random()) + min;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Utility functions for training and transfer learning of the speech-commands\n * model.\n */\n\nimport * as tf from '@tensorflow/tfjs';\n\n/**\n * Split feature and target tensors into train and validation (val) splits.\n *\n * Given sufficent number of examples, the train and val sets will be\n * balanced with respect to the classes.\n *\n * @param xs Features tensor, of shape [numExamples, ...].\n * @param ys Targets tensors, of shape [numExamples, numClasses]. Assumed to be\n *   one-hot categorical encoding.\n * @param valSplit A number > 0 and < 1, fraction of examples to use\n *   as the validation set.\n * @returns trainXs: training features tensor; trainYs: training targets\n *   tensor; valXs: validation features tensor; valYs: validation targets\n *   tensor.\n */\nexport function balancedTrainValSplit(\n    xs: tf.Tensor, ys: tf.Tensor, valSplit: number): {\n  trainXs: tf.Tensor,\n  trainYs: tf.Tensor,\n  valXs: tf.Tensor,\n  valYs: tf.Tensor\n} {\n  tf.util.assert(\n      valSplit > 0 && valSplit < 1,\n      () => `validationSplit is expected to be >0 and <1, ` +\n          `but got ${valSplit}`);\n\n  return tf.tidy(() => {\n    const classIndices = ys.argMax(-1).dataSync();\n\n    const indicesByClasses: number[][] = [];\n    for (let i = 0; i < classIndices.length; ++i) {\n      const classIndex = classIndices[i];\n      if (indicesByClasses[classIndex] == null) {\n        indicesByClasses[classIndex] = [];\n      }\n      indicesByClasses[classIndex].push(i);\n    }\n    const numClasses = indicesByClasses.length;\n\n    const trainIndices: number[] = [];\n    const valIndices: number[] = [];\n\n    // Randomly shuffle the list of indices in each array.\n    indicesByClasses.map(classIndices => tf.util.shuffle(classIndices));\n    for (let i = 0; i < numClasses; ++i) {\n      const classIndices = indicesByClasses[i];\n      const cutoff = Math.round(classIndices.length * (1 - valSplit));\n      for (let j = 0; j < classIndices.length; ++j) {\n        if (j < cutoff) {\n          trainIndices.push(classIndices[j]);\n        } else {\n          valIndices.push(classIndices[j]);\n        }\n      }\n    }\n\n    const trainXs = tf.gather(xs, trainIndices);\n    const trainYs = tf.gather(ys, trainIndices);\n    const valXs = tf.gather(xs, valIndices);\n    const valYs = tf.gather(ys, valIndices);\n    return {trainXs, trainYs, valXs, valYs};\n  });\n}\n\n/**\n * Same as balancedTrainValSplit, but for number arrays or Float32Arrays.\n */\nexport function balancedTrainValSplitNumArrays(\n    xs: number[][]|Float32Array[], ys: number[], valSplit: number): {\n  trainXs: number[][]|Float32Array[],\n  trainYs: number[],\n  valXs: number[][]|Float32Array[],\n  valYs: number[]\n} {\n  tf.util.assert(\n      valSplit > 0 && valSplit < 1,\n      () => `validationSplit is expected to be >0 and <1, ` +\n          `but got ${valSplit}`);\n  const isXsFloat32Array = !Array.isArray(xs[0]);\n\n  const classIndices = ys;\n\n  const indicesByClasses: number[][] = [];\n  for (let i = 0; i < classIndices.length; ++i) {\n    const classIndex = classIndices[i];\n    if (indicesByClasses[classIndex] == null) {\n      indicesByClasses[classIndex] = [];\n    }\n    indicesByClasses[classIndex].push(i);\n  }\n  const numClasses = indicesByClasses.length;\n\n  const trainIndices: number[] = [];\n  const valIndices: number[] = [];\n\n  // Randomly shuffle the list of indices in each array.\n  indicesByClasses.map(classIndices => tf.util.shuffle(classIndices));\n  for (let i = 0; i < numClasses; ++i) {\n    const classIndices = indicesByClasses[i];\n    const cutoff = Math.round(classIndices.length * (1 - valSplit));\n    for (let j = 0; j < classIndices.length; ++j) {\n      if (j < cutoff) {\n        trainIndices.push(classIndices[j]);\n      } else {\n        valIndices.push(classIndices[j]);\n      }\n    }\n  }\n\n  if (isXsFloat32Array) {\n    const trainXs: Float32Array[] = [];\n    const trainYs: number[] = [];\n    const valXs: Float32Array[] = [];\n    const valYs: number[] = [];\n    for (const index of trainIndices) {\n      trainXs.push(xs[index] as Float32Array);\n      trainYs.push(ys[index]);\n    }\n    for (const index of valIndices) {\n      valXs.push(xs[index] as Float32Array);\n      valYs.push(ys[index]);\n    }\n    return {trainXs, trainYs, valXs, valYs};\n  } else {\n    const trainXs: number[][] = [];\n    const trainYs: number[] = [];\n    const valXs: number[][] = [];\n    const valYs: number[] = [];\n    for (const index of trainIndices) {\n      trainXs.push(xs[index] as number[]);\n      trainYs.push(ys[index]);\n    }\n    for (const index of valIndices) {\n      valXs.push(xs[index] as number[]);\n      valYs.push(ys[index]);\n    }\n    return {trainXs, trainYs, valXs, valYs};\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs';\nimport {normalize} from './browser_fft_utils';\nimport {arrayBuffer2String, concatenateArrayBuffers, getRandomInteger, getUID, string2ArrayBuffer} from './generic_utils';\nimport {balancedTrainValSplitNumArrays} from './training_utils';\nimport {AudioDataAugmentationOptions, Example, SpectrogramData} from './types';\n\n// Descriptor for serialized dataset files: stands for:\n//   TensorFlow.js Speech-Commands Dataset.\n// DO NOT EVER CHANGE THIS!\nexport const DATASET_SERIALIZATION_DESCRIPTOR = 'TFJSSCDS';\n\n// A version number for the serialization. Since this needs\n// to be encoded within a length-1 Uint8 array, it must be\n//   1. an positive integer.\n//   2. monotonically increasing over its change history.\n// Item 1 is checked by unit tests.\nexport const DATASET_SERIALIZATION_VERSION = 1;\n\n/**\n * Specification for an `Example` (see above).\n *\n * Used for serialization of `Example`.\n */\nexport interface ExampleSpec {\n  /** A label for the example. */\n  label: string;\n\n  /** Number of frames in the spectrogram. */\n  spectrogramNumFrames: number;\n\n  /** The length of each frame in the spectrogram. */\n  spectrogramFrameSize: number;\n\n  /** The key frame index of the spectrogram. */\n  spectrogramKeyFrameIndex?: number;\n\n  /** Number of samples in the raw PCM-format audio (if any). */\n  rawAudioNumSamples?: number;\n\n  /** Sampling rate of the raw audio (if any). */\n  rawAudioSampleRateHz?: number;\n}\n\n/**\n * Serialized Dataset, containing a number of `Example`s in their\n * serialized format.\n *\n * This format consists of a plain-old JSON object as the manifest,\n * along with a flattened binary `ArrayBuffer`. The format facilitates\n * storage and transmission.\n */\nexport interface SerializedExamples {\n  /**\n   * Specifications of the serialized `Example`s, serialized as a string.\n   */\n  manifest: ExampleSpec[];\n\n  /**\n   * Serialized binary data from the `Example`s.\n   *\n   * Including the spectrograms and the raw audio (if any).\n   *\n   * For example, assuming `manifest.length` is `N`, the format of the\n   * `ArrayBuffer` is as follows:\n   *\n   *   [spectrogramData1, rawAudio1 (if any),\n   *    spectrogramData2, rawAudio2 (if any),\n   *    ...\n   *    spectrogramDataN, rawAudioN (if any)]\n   */\n  data: ArrayBuffer;\n}\n\nexport const BACKGROUND_NOISE_TAG = '_background_noise_';\n\n/**\n * Configuration for getting spectrograms as tensors.\n */\nexport interface GetDataConfig extends AudioDataAugmentationOptions {\n  /**\n   * Number of frames.\n   *\n   * This must be smaller than or equal to the # of frames of each\n   * example held by the dataset.\n   *\n   * If the # of frames of an example is greater than this number,\n   * the following heuristics will be used to extra >= 1 examples\n   * of length numFrames from the original example:\n   *\n   *   - If the label of the example is `BAKCGROUND_NOISE_TAG`,\n   *     the example will be splitted into multiple examples using the\n   *     `hopFrames` parameter (see below).\n   *   - If the label of the example is not `BACKGROUND_NOISE_TAG`,\n   *     the example will be splitted into multiple examples that\n   *     all contain the maximum-intensity frame using the `hopFrames`\n   *     parameter.\n   */\n  numFrames?: number;\n\n  /**\n   * Hop length in number of frames.\n   *\n   * Used when splitting a long example into multiple shorter ones.\n   *\n   * Must be provided if any such long examples exist.\n   */\n  hopFrames?: number;\n\n  /**\n   * Whether the spectrogram of each example will be normalized.\n   *\n   * Normalization means:\n   * - Subtracting the mean, and\n   * - Dividing the result by the standard deviation.\n   *\n   * Default: `true`.\n   */\n  normalize?: boolean;\n\n  /**\n   * Whether the examples will be shuffled prior to merged into\n   * `tf.Tensor`s.\n   *\n   * Default: `true`.\n   */\n  shuffle?: boolean;\n\n  /**\n   * Whether to obtain a `tf.data.Datasaet` object.\n   *\n   * Default: `false`.\n   */\n  getDataset?: boolean;\n\n  /**\n   * Batch size for dataset.\n   *\n   * Applicable only if `getDataset === true`.\n   */\n  datasetBatchSize?: number;\n\n  /**\n   * Validation split for the datasaet.\n   *\n   * Applicable only if `getDataset === true`.\n   *\n   * The data will be divided into two fractions of relative sizes\n   * `[1 - datasetValidationSplit, datasetValidationSplit]`, for the\n   * training and validation `tf.data.Dataset` objects, respectively.\n   *\n   * Must be a number between 0 and 1.\n   * Default: 0.15.\n   */\n  datasetValidationSplit?: number;\n}\n\n// tslint:disable-next-line:no-any\nexport type SpectrogramAndTargetsTfDataset = tf.data.Dataset<{}>;\n\n/**\n * A serializable, mutable set of speech/audio `Example`s;\n */\nexport class Dataset {\n  private examples: {[id: string]: Example};\n  private label2Ids: {[label: string]: string[]};\n\n  /**\n   * Constructor of `Dataset`.\n   *\n   * If called with no arguments (i.e., `artifacts` == null), an empty dataset\n   * will be constructed.\n   *\n   * Else, the dataset will be deserialized from `artifacts`.\n   *\n   * @param serialized Optional serialization artifacts to deserialize.\n   */\n  constructor(serialized?: ArrayBuffer) {\n    this.examples = {};\n    this.label2Ids = {};\n    if (serialized != null) {\n      // Deserialize from the provided artifacts.\n      const artifacts = arrayBuffer2SerializedExamples(serialized);\n      let offset = 0;\n      for (let i = 0; i < artifacts.manifest.length; ++i) {\n        const spec = artifacts.manifest[i];\n        let byteLen = spec.spectrogramNumFrames * spec.spectrogramFrameSize;\n        if (spec.rawAudioNumSamples != null) {\n          byteLen += spec.rawAudioNumSamples;\n        }\n        byteLen *= 4;\n        this.addExample(deserializeExample(\n            {spec, data: artifacts.data.slice(offset, offset + byteLen)}));\n        offset += byteLen;\n      }\n    }\n  }\n\n  /**\n   * Add an `Example` to the `Dataset`\n   *\n   * @param example A `Example`, with a label. The label must be a non-empty\n   *   string.\n   * @returns The UID for the added `Example`.\n   */\n  addExample(example: Example): string {\n    tf.util.assert(example != null, () => 'Got null or undefined example');\n    tf.util.assert(\n        example.label != null && example.label.length > 0,\n        () => `Expected label to be a non-empty string, ` +\n            `but got ${JSON.stringify(example.label)}`);\n    const uid = getUID();\n    this.examples[uid] = example;\n    if (!(example.label in this.label2Ids)) {\n      this.label2Ids[example.label] = [];\n    }\n    this.label2Ids[example.label].push(uid);\n    return uid;\n  }\n\n  /**\n   * Merge the incoming dataset into this dataset\n   *\n   * @param dataset The incoming dataset to be merged into this dataset.\n   */\n  merge(dataset: Dataset): void {\n    tf.util.assert(\n        dataset !== this, () => 'Cannot merge a dataset into itself');\n    const vocab = dataset.getVocabulary();\n    for (const word of vocab) {\n      const examples = dataset.getExamples(word);\n      for (const example of examples) {\n        this.addExample(example.example);\n      }\n    }\n  }\n\n  /**\n   * Get a map from `Example` label to number of `Example`s with the label.\n   *\n   * @returns A map from label to number of example counts under that label.\n   */\n  getExampleCounts(): {[label: string]: number} {\n    const counts: {[label: string]: number} = {};\n    for (const uid in this.examples) {\n      const example = this.examples[uid];\n      if (!(example.label in counts)) {\n        counts[example.label] = 0;\n      }\n      counts[example.label]++;\n    }\n    return counts;\n  }\n\n  /**\n   * Get all examples of a given label, with their UIDs.\n   *\n   * @param label The requested label.\n   * @return All examples of the given `label`, along with their UIDs.\n   *   The examples are sorted in the order in which they are added to the\n   *   `Dataset`.\n   * @throws Error if label is `null` or `undefined`.\n   */\n  getExamples(label: string): Array<{uid: string, example: Example}> {\n    tf.util.assert(\n        label != null,\n        () =>\n            `Expected label to be a string, but got ${JSON.stringify(label)}`);\n    tf.util.assert(\n        label in this.label2Ids,\n        () => `No example of label \"${label}\" exists in dataset`);\n    const output: Array<{uid: string, example: Example}> = [];\n    this.label2Ids[label].forEach(id => {\n      output.push({uid: id, example: this.examples[id]});\n    });\n    return output;\n  }\n\n  /**\n   * Get all examples and labels as tensors.\n   *\n   * - If `label` is provided and exists in the vocabulary of the `Dataset`,\n   *   the spectrograms of all `Example`s under the `label` will be returned\n   *   as a 4D `tf.Tensor` as `xs`. The shape of the `tf.Tensor` will be\n   *     `[numExamples, numFrames, frameSize, 1]`\n   *   where\n   *     - `numExamples` is the number of `Example`s with the label\n   *     - `numFrames` is the number of frames in each spectrogram\n   *     - `frameSize` is the size of each spectrogram frame.\n   *   No label Tensor will be returned.\n   * - If `label` is not provided, all `Example`s will be returned as `xs`.\n   *   In addition, `ys` will contain a one-hot encoded list of labels.\n   *   - The shape of `xs` will be: `[numExamples, numFrames, frameSize, 1]`\n   *   - The shape of `ys` will be: `[numExamples, vocabularySize]`.\n   *\n   * @returns If `config.getDataset` is `true`, returns two `tf.data.Dataset`\n   *   objects, one for training and one for validation.\n   *   Else, xs` and `ys` tensors. See description above.\n   * @throws Error\n   *   - if not all the involved spectrograms have matching `numFrames` and\n   *     `frameSize`, or\n   *   - if `label` is provided and is not present in the vocabulary of the\n   *     `Dataset`, or\n   *   - if the `Dataset` is currently empty.\n   */\n  getData(label?: string, config?: GetDataConfig): {\n    xs: tf.Tensor4D,\n    ys?: tf.Tensor2D\n  }|[SpectrogramAndTargetsTfDataset, SpectrogramAndTargetsTfDataset] {\n    tf.util.assert(\n        this.size() > 0,\n        () =>\n            `Cannot get spectrograms as tensors because the dataset is empty`);\n    const vocab = this.getVocabulary();\n    if (label != null) {\n      tf.util.assert(\n          vocab.indexOf(label) !== -1,\n          () => `Label ${label} is not in the vocabulary ` +\n              `(${JSON.stringify(vocab)})`);\n    } else {\n      // If all words are requested, there must be at least two words in the\n      // vocabulary to make one-hot encoding possible.\n      tf.util.assert(\n          vocab.length > 1,\n          () => `One-hot encoding of labels requires the vocabulary to have ` +\n              `at least two words, but it has only ${vocab.length} word.`);\n    }\n\n    if (config == null) {\n      config = {};\n    }\n\n    // Get the numFrames lengths of all the examples currently held by the\n    // dataset.\n    const sortedUniqueNumFrames = this.getSortedUniqueNumFrames();\n    let numFrames: number;\n    let hopFrames: number;\n    if (sortedUniqueNumFrames.length === 1) {\n      numFrames = config.numFrames == null ? sortedUniqueNumFrames[0] :\n                                             config.numFrames;\n      hopFrames = config.hopFrames == null ? 1 : config.hopFrames;\n    } else {\n      numFrames = config.numFrames;\n      tf.util.assert(\n          numFrames != null && Number.isInteger(numFrames) && numFrames > 0,\n          () => `There are ${\n                    sortedUniqueNumFrames.length} unique lengths among ` +\n              `the ${this.size()} examples of this Dataset, hence numFrames ` +\n              `is required. But it is not provided.`);\n      tf.util.assert(\n          numFrames <= sortedUniqueNumFrames[0],\n          () => `numFrames (${numFrames}) exceeds the minimum numFrames ` +\n              `(${sortedUniqueNumFrames[0]}) among the examples of ` +\n              `the Dataset.`);\n\n      hopFrames = config.hopFrames;\n      tf.util.assert(\n          hopFrames != null && Number.isInteger(hopFrames) && hopFrames > 0,\n          () => `There are ${\n                    sortedUniqueNumFrames.length} unique lengths among ` +\n              `the ${this.size()} examples of this Dataset, hence hopFrames ` +\n              `is required. But it is not provided.`);\n    }\n\n    // Normalization is performed by default.\n    const toNormalize = config.normalize == null ? true : config.normalize;\n\n    return tf.tidy(() => {\n      let xTensors: tf.Tensor3D[] = [];\n      let xArrays: Float32Array[] = [];\n\n      let labelIndices: number[] = [];\n      let uniqueFrameSize: number;\n      for (let i = 0; i < vocab.length; ++i) {\n        const currentLabel = vocab[i];\n        if (label != null && currentLabel !== label) {\n          continue;\n        }\n        const ids = this.label2Ids[currentLabel];\n        for (const id of ids) {\n          const example = this.examples[id];\n          const spectrogram = example.spectrogram;\n          const frameSize = spectrogram.frameSize;\n          if (uniqueFrameSize == null) {\n            uniqueFrameSize = frameSize;\n          } else {\n            tf.util.assert(\n                frameSize === uniqueFrameSize,\n                () => `Mismatch in frameSize  ` +\n                    `(${frameSize} vs ${uniqueFrameSize})`);\n          }\n\n          const snippetLength = spectrogram.data.length / frameSize;\n          let focusIndex = null;\n          if (currentLabel !== BACKGROUND_NOISE_TAG) {\n            focusIndex = spectrogram.keyFrameIndex == null ?\n                getMaxIntensityFrameIndex(spectrogram).dataSync()[0] :\n                spectrogram.keyFrameIndex;\n          }\n          // TODO(cais): See if we can get rid of dataSync();\n\n          const snippet =\n              tf.tensor3d(spectrogram.data, [snippetLength, frameSize, 1]);\n          const windows =\n              getValidWindows(snippetLength, focusIndex, numFrames, hopFrames);\n          for (const window of windows) {\n            const windowedSnippet = tf.tidy(() => {\n              const output = snippet.slice(\n                  [window[0], 0, 0], [window[1] - window[0], -1, -1]);\n              return toNormalize ? normalize(output) : output;\n            });\n            if (config.getDataset) {\n              // TODO(cais): See if we can do away with dataSync();\n              // TODO(cais): Shuffling?\n              xArrays.push(windowedSnippet.dataSync() as Float32Array);\n            } else {\n              xTensors.push(windowedSnippet as tf.Tensor3D);\n            }\n            if (label == null) {\n              labelIndices.push(i);\n            }\n          }\n          tf.dispose(snippet);  // For memory saving.\n        }\n      }\n\n      if (config.augmentByMixingNoiseRatio != null) {\n        this.augmentByMixingNoise(\n            config.getDataset ? xArrays :\n                                xTensors as Array<Float32Array|tf.Tensor>,\n            labelIndices, config.augmentByMixingNoiseRatio);\n      }\n\n      const shuffle = config.shuffle == null ? true : config.shuffle;\n      if (config.getDataset) {\n        const batchSize =\n            config.datasetBatchSize == null ? 32 : config.datasetBatchSize;\n\n        // Split the data into two splits: training and validation.\n        const valSplit = config.datasetValidationSplit == null ?\n            0.15 :\n            config.datasetValidationSplit;\n        tf.util.assert(\n            valSplit > 0 && valSplit < 1,\n            () => `Invalid dataset validation split: ${valSplit}`);\n\n        const zippedXandYArrays =\n            xArrays.map((xArray, i) => [xArray, labelIndices[i]]);\n        tf.util.shuffle(\n            zippedXandYArrays);  // Shuffle the data before splitting.\n        xArrays = zippedXandYArrays.map(item => item[0]) as Float32Array[];\n        const yArrays = zippedXandYArrays.map(item => item[1]) as number[];\n        const {trainXs, trainYs, valXs, valYs} =\n            balancedTrainValSplitNumArrays(xArrays, yArrays, valSplit);\n\n        // TODO(cais): The typing around Float32Array is not working properly\n        // for tf.data currently. Tighten the types when the tf.data bug is\n        // fixed.\n        // tslint:disable:no-any\n        const xTrain =\n            tf.data.array(trainXs as any).map(x => tf.tensor3d(x as any, [\n              numFrames, uniqueFrameSize, 1\n            ]));\n        const yTrain = tf.data.array(trainYs).map(\n            y => tf.oneHot([y], vocab.length).squeeze([0]));\n        // TODO(cais): See if we can tighten the typing.\n        let trainDataset = tf.data.zip({xs: xTrain, ys: yTrain});\n        if (shuffle) {\n          // Shuffle the dataset.\n          trainDataset = trainDataset.shuffle(xArrays.length);\n        }\n        trainDataset = trainDataset.batch(batchSize).prefetch(4);\n\n        const xVal =\n            tf.data.array(valXs as any).map(x => tf.tensor3d(x as any, [\n              numFrames, uniqueFrameSize, 1\n            ]));\n        const yVal = tf.data.array(valYs).map(\n            y => tf.oneHot([y], vocab.length).squeeze([0]));\n        let valDataset = tf.data.zip({xs: xVal, ys: yVal});\n        valDataset = valDataset.batch(batchSize).prefetch(4);\n        // tslint:enable:no-any\n\n        // tslint:disable-next-line:no-any\n        return [trainDataset, valDataset] as any;\n      } else {\n        if (shuffle) {\n          // Shuffle the data.\n          const zipped: Array<{x: tf.Tensor3D, y: number}> = [];\n          xTensors.forEach((xTensor, i) => {\n            zipped.push({x: xTensor, y: labelIndices[i]});\n          });\n          tf.util.shuffle(zipped);\n          xTensors = zipped.map(item => item.x);\n          labelIndices = zipped.map(item => item.y);\n        }\n\n        const targets = label == null ?\n            tf.oneHot(tf.tensor1d(labelIndices, 'int32'), vocab.length)\n                .asType('float32') :\n            undefined;\n        return {\n          xs: tf.stack(xTensors) as tf.Tensor4D,\n          ys: targets as tf.Tensor2D\n        };\n      }\n    });\n  }\n\n  private augmentByMixingNoise<T extends tf.Tensor|Float32Array>(\n      xs: T[], labelIndices: number[], ratio: number): void {\n    if (xs == null || xs.length === 0) {\n      throw new Error(\n          `Cannot perform augmentation because data is null or empty`);\n    }\n    const isTypedArray = xs[0] instanceof Float32Array;\n\n    const vocab = this.getVocabulary();\n    const noiseExampleIndices: number[] = [];\n    const wordExampleIndices: number[] = [];\n    for (let i = 0; i < labelIndices.length; ++i) {\n      if (vocab[labelIndices[i]] === BACKGROUND_NOISE_TAG) {\n        noiseExampleIndices.push(i);\n      } else {\n        wordExampleIndices.push(i);\n      }\n    }\n    if (noiseExampleIndices.length === 0) {\n      throw new Error(\n          `Cannot perform augmentation by mixing with noise when ` +\n          `there is no example with label ${BACKGROUND_NOISE_TAG}`);\n    }\n\n    const mixedXTensors: Array<tf.Tensor|Float32Array> = [];\n    const mixedLabelIndices: number[] = [];\n    for (const index of wordExampleIndices) {\n      const noiseIndex =  // Randomly sample from the noises, with replacement.\n          noiseExampleIndices[getRandomInteger(0, noiseExampleIndices.length)];\n      const signalTensor = isTypedArray ?\n          tf.tensor1d(xs[index] as Float32Array) :\n          xs[index] as tf.Tensor;\n      const noiseTensor = isTypedArray ?\n          tf.tensor1d(xs[noiseIndex] as Float32Array) :\n          xs[noiseIndex] as tf.Tensor;\n      const mixed: tf.Tensor =\n          tf.tidy(() => normalize(signalTensor.add(noiseTensor.mul(ratio))));\n      if (isTypedArray) {\n        mixedXTensors.push(mixed.dataSync() as Float32Array);\n      } else {\n        mixedXTensors.push(mixed);\n      }\n      mixedLabelIndices.push(labelIndices[index]);\n    }\n    console.log(\n        `Data augmentation: mixing noise: added ${mixedXTensors.length} ` +\n        `examples`);\n    mixedXTensors.forEach(tensor => xs.push(tensor as T));\n    labelIndices.push(...mixedLabelIndices);\n  }\n\n  private getSortedUniqueNumFrames(): number[] {\n    const numFramesSet = new Set<number>();\n    const vocab = this.getVocabulary();\n    for (let i = 0; i < vocab.length; ++i) {\n      const label = vocab[i];\n      const ids = this.label2Ids[label];\n      for (const id of ids) {\n        const spectrogram = this.examples[id].spectrogram;\n        const numFrames = spectrogram.data.length / spectrogram.frameSize;\n        numFramesSet.add(numFrames);\n      }\n    }\n    const uniqueNumFrames = [...numFramesSet];\n    uniqueNumFrames.sort();\n    return uniqueNumFrames;\n  }\n\n  /**\n   * Remove an example from the `Dataset`.\n   *\n   * @param uid The UID of the example to remove.\n   * @throws Error if the UID doesn't exist in the `Dataset`.\n   */\n  removeExample(uid: string): void {\n    if (!(uid in this.examples)) {\n      throw new Error(`Nonexistent example UID: ${uid}`);\n    }\n    const label = this.examples[uid].label;\n    delete this.examples[uid];\n    const index = this.label2Ids[label].indexOf(uid);\n    this.label2Ids[label].splice(index, 1);\n    if (this.label2Ids[label].length === 0) {\n      delete this.label2Ids[label];\n    }\n  }\n\n  /**\n   * Set the key frame index of a given example.\n   *\n   * @param uid The UID of the example of which the `keyFrameIndex` is to be\n   *   set.\n   * @param keyFrameIndex The desired value of the `keyFrameIndex`. Must\n   *   be >= 0, < the number of frames of the example, and an integer.\n   * @throws Error If the UID and/or the `keyFrameIndex` value is invalid.\n   */\n  setExampleKeyFrameIndex(uid: string, keyFrameIndex: number) {\n    if (!(uid in this.examples)) {\n      throw new Error(`Nonexistent example UID: ${uid}`);\n    }\n    const spectrogram = this.examples[uid].spectrogram;\n    const numFrames = spectrogram.data.length / spectrogram.frameSize;\n    tf.util.assert(\n        keyFrameIndex >= 0 && keyFrameIndex < numFrames &&\n            Number.isInteger(keyFrameIndex),\n        () => `Invalid keyFrameIndex: ${keyFrameIndex}. ` +\n            `Must be >= 0, < ${numFrames}, and an integer.`);\n    spectrogram.keyFrameIndex = keyFrameIndex;\n  }\n\n  /**\n   * Get the total number of `Example` currently held by the `Dataset`.\n   *\n   * @returns Total `Example` count.\n   */\n  size(): number {\n    return Object.keys(this.examples).length;\n  }\n\n  /**\n   * Get the total duration of the `Example` currently held by `Dataset`,\n   *\n   * in milliseconds.\n   *\n   * @return Total duration in milliseconds.\n   */\n  durationMillis(): number {\n    let durMillis = 0;\n    const DEFAULT_FRAME_DUR_MILLIS = 23.22;\n    for (const key in this.examples) {\n      const spectrogram = this.examples[key].spectrogram;\n      const frameDurMillis =\n          spectrogram.frameDurationMillis | DEFAULT_FRAME_DUR_MILLIS;\n      durMillis +=\n          spectrogram.data.length / spectrogram.frameSize * frameDurMillis;\n    }\n    return durMillis;\n  }\n\n  /**\n   * Query whether the `Dataset` is currently empty.\n   *\n   * I.e., holds zero examples.\n   *\n   * @returns Whether the `Dataset` is currently empty.\n   */\n  empty(): boolean {\n    return this.size() === 0;\n  }\n\n  /**\n   * Remove all `Example`s from the `Dataset`.\n   */\n  clear(): void {\n    this.examples = {};\n  }\n\n  /**\n   * Get the list of labels among all `Example`s the `Dataset` currently holds.\n   *\n   * @returns A sorted Array of labels, for the unique labels that belong to all\n   *   `Example`s currently held by the `Dataset`.\n   */\n  getVocabulary(): string[] {\n    const vocab = new Set<string>();\n    for (const uid in this.examples) {\n      const example = this.examples[uid];\n      vocab.add(example.label);\n    }\n    const sortedVocab = [...vocab];\n    sortedVocab.sort();\n    return sortedVocab;\n  }\n\n  /**\n   * Serialize the `Dataset`.\n   *\n   * The `Examples` are sorted in the following order:\n   *   - First, the labels in the vocabulary are sorted.\n   *   - Second, the `Example`s for every label are sorted by the order in\n   *     which they are added to this `Dataset`.\n   *\n   * @param wordLabels Optional word label(s) to serialize. If specified, only\n   *   the examples with labels matching the argument will be serialized. If\n   *   any specified word label does not exist in the vocabulary of this\n   *   dataset, an Error will be thrown.\n   * @returns A `ArrayBuffer` object amenable to transmission and storage.\n   */\n  serialize(wordLabels?: string|string[]): ArrayBuffer {\n    const vocab = this.getVocabulary();\n    tf.util.assert(!this.empty(), () => `Cannot serialize empty Dataset`);\n\n    if (wordLabels != null) {\n      if (!Array.isArray(wordLabels)) {\n        wordLabels = [wordLabels];\n      }\n      wordLabels.forEach(wordLabel => {\n        if (vocab.indexOf(wordLabel) === -1) {\n          throw new Error(\n              `Word label \"${wordLabel}\" does not exist in the ` +\n              `vocabulary of this dataset. The vocabulary is: ` +\n              `${JSON.stringify(vocab)}.`);\n        }\n      });\n    }\n\n    const manifest: ExampleSpec[] = [];\n    const buffers: ArrayBuffer[] = [];\n    for (const label of vocab) {\n      if (wordLabels != null && wordLabels.indexOf(label) === -1) {\n        continue;\n      }\n      const ids = this.label2Ids[label];\n      for (const id of ids) {\n        const artifact = serializeExample(this.examples[id]);\n        manifest.push(artifact.spec);\n        buffers.push(artifact.data);\n      }\n    }\n    return serializedExamples2ArrayBuffer(\n        {manifest, data: concatenateArrayBuffers(buffers)});\n  }\n}\n\n/** Serialize an `Example`. */\nexport function serializeExample(example: Example):\n    {spec: ExampleSpec, data: ArrayBuffer} {\n  const hasRawAudio = example.rawAudio != null;\n  const spec: ExampleSpec = {\n    label: example.label,\n    spectrogramNumFrames:\n        example.spectrogram.data.length / example.spectrogram.frameSize,\n    spectrogramFrameSize: example.spectrogram.frameSize,\n  };\n  if (example.spectrogram.keyFrameIndex != null) {\n    spec.spectrogramKeyFrameIndex = example.spectrogram.keyFrameIndex;\n  }\n\n  let data = example.spectrogram.data.buffer.slice(0);\n  if (hasRawAudio) {\n    spec.rawAudioNumSamples = example.rawAudio.data.length;\n    spec.rawAudioSampleRateHz = example.rawAudio.sampleRateHz;\n\n    // Account for the fact that the data are all float32.\n    data = concatenateArrayBuffers([data, example.rawAudio.data.buffer]);\n  }\n  return {spec, data};\n}\n\n/** Deserialize an `Example`. */\nexport function deserializeExample(\n    artifact: {spec: ExampleSpec, data: ArrayBuffer}): Example {\n  const spectrogram: SpectrogramData = {\n    frameSize: artifact.spec.spectrogramFrameSize,\n    data: new Float32Array(artifact.data.slice(\n        0,\n        4 * artifact.spec.spectrogramFrameSize *\n            artifact.spec.spectrogramNumFrames))\n  };\n  if (artifact.spec.spectrogramKeyFrameIndex != null) {\n    spectrogram.keyFrameIndex = artifact.spec.spectrogramKeyFrameIndex;\n  }\n  const ex: Example = {label: artifact.spec.label, spectrogram};\n  if (artifact.spec.rawAudioNumSamples != null) {\n    ex.rawAudio = {\n      sampleRateHz: artifact.spec.rawAudioSampleRateHz,\n      data: new Float32Array(artifact.data.slice(\n          4 * artifact.spec.spectrogramFrameSize *\n          artifact.spec.spectrogramNumFrames))\n    };\n  }\n  return ex;\n}\n\n/**\n * Encode intermediate serialization format as an ArrayBuffer.\n *\n * Format of the binary ArrayBuffer:\n *   1. An 8-byte descriptor (see above).\n *   2. A 4-byte version number as Uint32.\n *   3. A 4-byte number for the byte length of the JSON manifest.\n *   4. The encoded JSON manifest\n *   5. The binary data of the spectrograms, and raw audio (if any).\n *\n * @param serialized: Intermediate serialization format of a dataset.\n * @returns The binary conversion result as an ArrayBuffer.\n */\nfunction serializedExamples2ArrayBuffer(serialized: SerializedExamples):\n    ArrayBuffer {\n  const manifestBuffer =\n      string2ArrayBuffer(JSON.stringify(serialized.manifest));\n\n  const descriptorBuffer = string2ArrayBuffer(DATASET_SERIALIZATION_DESCRIPTOR);\n  const version = new Uint32Array([DATASET_SERIALIZATION_VERSION]);\n  const manifestLength = new Uint32Array([manifestBuffer.byteLength]);\n  const headerBuffer = concatenateArrayBuffers(\n      [descriptorBuffer, version.buffer, manifestLength.buffer]);\n\n  return concatenateArrayBuffers(\n      [headerBuffer, manifestBuffer, serialized.data]);\n}\n\n/** Decode an ArrayBuffer as intermediate serialization format. */\nexport function arrayBuffer2SerializedExamples(buffer: ArrayBuffer):\n    SerializedExamples {\n  tf.util.assert(buffer != null, () => 'Received null or undefined buffer');\n  // Check descriptor.\n  let offset = 0;\n  const descriptor = arrayBuffer2String(\n      buffer.slice(offset, DATASET_SERIALIZATION_DESCRIPTOR.length));\n  tf.util.assert(\n      descriptor === DATASET_SERIALIZATION_DESCRIPTOR,\n      () => `Deserialization error: Invalid descriptor`);\n  offset += DATASET_SERIALIZATION_DESCRIPTOR.length;\n  // Skip the version part for now. It may be used in the future.\n  offset += 4;\n\n  // Extract the length of the encoded manifest JSON as a Uint32.\n  const manifestLength = new Uint32Array(buffer, offset, 1);\n  offset += 4;\n  const manifestBeginByte = offset;\n  offset = manifestBeginByte + manifestLength[0];\n  const manifestBytes = buffer.slice(manifestBeginByte, offset);\n  const manifestString = arrayBuffer2String(manifestBytes);\n  const manifest = JSON.parse(manifestString);\n  const data = buffer.slice(offset);\n  return {manifest, data};\n}\n\n/**\n * Get valid windows in a long snippet.\n *\n * Each window is represented by an inclusive left index and an exclusive\n * right index.\n *\n * @param snippetLength Long of the entire snippet. Must be a positive\n *   integer.\n * @param focusIndex Optional. If `null` or `undefined`, an array of\n *   evenly-spaced windows will be generated. The array of windows will\n *   start from the first possible location (i.e., [0, windowLength]).\n *   If not `null` or `undefined`, must be an integer >= 0 and < snippetLength.\n * @param windowLength Length of each window. Must be a positive integer and\n *   <= snippetLength.\n * @param windowHop Hops between successsive windows. Must be a positive\n *   integer.\n * @returns An array of [beginIndex, endIndex] pairs.\n */\nexport function getValidWindows(\n    snippetLength: number, focusIndex: number, windowLength: number,\n    windowHop: number): Array<[number, number]> {\n  tf.util.assert(\n      Number.isInteger(snippetLength) && snippetLength > 0,\n      () =>\n          `snippetLength must be a positive integer, but got ${snippetLength}`);\n  if (focusIndex != null) {\n    tf.util.assert(\n        Number.isInteger(focusIndex) && focusIndex >= 0,\n        () =>\n            `focusIndex must be a non-negative integer, but got ${focusIndex}`);\n  }\n  tf.util.assert(\n      Number.isInteger(windowLength) && windowLength > 0,\n      () => `windowLength must be a positive integer, but got ${windowLength}`);\n  tf.util.assert(\n      Number.isInteger(windowHop) && windowHop > 0,\n      () => `windowHop must be a positive integer, but got ${windowHop}`);\n  tf.util.assert(\n      windowLength <= snippetLength,\n      () => `windowLength (${windowLength}) exceeds snippetLength ` +\n          `(${snippetLength})`);\n  tf.util.assert(\n      focusIndex < snippetLength,\n      () => `focusIndex (${focusIndex}) equals or exceeds snippetLength ` +\n          `(${snippetLength})`);\n\n  if (windowLength === snippetLength) {\n    return [[0, snippetLength]];\n  }\n\n  const windows: Array<[number, number]> = [];\n\n  if (focusIndex == null) {\n    // Deal with the special case of no focus frame:\n    // Output an array of evenly-spaced windows, starting from\n    // the first possible location.\n    let begin = 0;\n    while (begin + windowLength <= snippetLength) {\n      windows.push([begin, begin + windowLength]);\n      begin += windowHop;\n    }\n    return windows;\n  }\n\n  const leftHalf = Math.floor(windowLength / 2);\n  let left = focusIndex - leftHalf;\n  if (left < 0) {\n    left = 0;\n  } else if (left + windowLength > snippetLength) {\n    left = snippetLength - windowLength;\n  }\n\n  while (true) {\n    if (left - windowHop < 0 || focusIndex >= left - windowHop + windowLength) {\n      break;\n    }\n    left -= windowHop;\n  }\n\n  while (left + windowLength <= snippetLength) {\n    if (focusIndex < left) {\n      break;\n    }\n    windows.push([left, left + windowLength]);\n    left += windowHop;\n  }\n  return windows;\n}\n\n/**\n * Calculate an intensity profile from a spectrogram.\n *\n * The intensity at each time frame is caclulated by simply averaging all the\n * spectral values that belong to that time frame.\n *\n * @param spectrogram The input spectrogram.\n * @returns The temporal profile of the intensity as a 1D tf.Tensor of shape\n *   `[numFrames]`.\n */\nexport function spectrogram2IntensityCurve(spectrogram: SpectrogramData):\n    tf.Tensor {\n  return tf.tidy(() => {\n    const numFrames = spectrogram.data.length / spectrogram.frameSize;\n    const x = tf.tensor2d(spectrogram.data, [numFrames, spectrogram.frameSize]);\n    return x.mean(-1);\n  });\n}\n\n/**\n * Get the index to the maximum intensity frame.\n *\n * The intensity of each time frame is calculated as the arithmetic mean of\n * all the spectral values belonging to that time frame.\n *\n * @param spectrogram The input spectrogram.\n * @returns The index to the time frame containing the maximum intensity.\n */\nexport function getMaxIntensityFrameIndex(spectrogram: SpectrogramData):\n    tf.Scalar {\n  return tf.tidy(() => spectrogram2IntensityCurve(spectrogram).argMax());\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '0.4.1';\nexport {version};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs';\n\nimport {BrowserFftFeatureExtractor, SpectrogramCallback} from './browser_fft_extractor';\nimport {loadMetadataJson, normalize, normalizeFloat32Array} from './browser_fft_utils';\nimport {BACKGROUND_NOISE_TAG, Dataset} from './dataset';\nimport {concatenateFloat32Arrays} from './generic_utils';\nimport {balancedTrainValSplit} from './training_utils';\nimport {AudioDataAugmentationOptions, EvaluateConfig, EvaluateResult, Example, ExampleCollectionOptions, RecognizeConfig, RecognizerCallback, RecognizerParams, ROCCurve, SpectrogramData, SpeechCommandRecognizer, SpeechCommandRecognizerMetadata, SpeechCommandRecognizerResult, StreamingRecognitionConfig, TransferLearnConfig, TransferSpeechCommandRecognizer} from './types';\nimport {version} from './version';\n\nexport const UNKNOWN_TAG = '_unknown_';\n\n// Key to the local-storage item that holds a map from model name to word\n// list.\nexport const SAVED_MODEL_METADATA_KEY =\n    'tfjs-speech-commands-saved-model-metadata';\nexport const SAVE_PATH_PREFIX = 'indexeddb://tfjs-speech-commands-model/';\n\n// Export a variable for injection during unit testing.\n// tslint:disable-next-line:no-any\nexport let localStorageWrapper = {\n  localStorage: typeof window === 'undefined' ? null : window.localStorage\n};\n\nexport function getMajorAndMinorVersion(version: string) {\n  const versionItems = version.split('.');\n  return versionItems.slice(0, 2).join('.');\n}\n\n/**\n * Default window hop ratio used for extracting multiple\n * windows from a long spectrogram.\n */\nconst DEFAULT_WINDOW_HOP_RATIO = 0.25;\n\n/**\n * Speech-Command Recognizer using browser-native (WebAudio) spectral featutres.\n */\nexport class BrowserFftSpeechCommandRecognizer implements\n    SpeechCommandRecognizer {\n  static readonly VALID_VOCABULARY_NAMES: string[] = ['18w', 'directional4w'];\n  static readonly DEFAULT_VOCABULARY_NAME = '18w';\n\n  readonly MODEL_URL_PREFIX =\n      `https://storage.googleapis.com/tfjs-models/tfjs/speech-commands/v${\n          getMajorAndMinorVersion(version)}/browser_fft`;\n\n  private readonly SAMPLE_RATE_HZ = 44100;\n  private readonly FFT_SIZE = 1024;\n  private readonly DEFAULT_SUPPRESSION_TIME_MILLIS = 0;\n\n  model: tf.LayersModel;\n  modelWithEmbeddingOutput: tf.LayersModel;\n  readonly vocabulary: string;\n  readonly parameters: RecognizerParams;\n  protected words: string[];\n\n  protected streaming = false;\n\n  protected nonBatchInputShape: [number, number, number];\n  private elementsPerExample: number;\n  protected audioDataExtractor: BrowserFftFeatureExtractor;\n\n  private transferRecognizers:\n      {[name: string]: TransferBrowserFftSpeechCommandRecognizer} = {};\n\n  private modelArtifactsOrURL: tf.io.ModelArtifacts|string;\n  private metadataOrURL: SpeechCommandRecognizerMetadata|string;\n\n  // The second-last dense layer in the base model.\n  // To be used for unfreezing during fine-tuning.\n  protected secondLastBaseDenseLayer: tf.layers.Layer;\n\n  /**\n   * Constructor of BrowserFftSpeechCommandRecognizer.\n   *\n   * @param vocabulary An optional vocabulary specifier. Mutually exclusive\n   *   with `modelURL` and `metadataURL`.\n   * @param modelArtifactsOrURL An optional, custom model URL pointing to a\n   *     model.json, or modelArtifacts in the format of `tf.io.ModelArtifacts`.\n   *   file. Supported schemes: http://, https://, and node.js-only: file://.\n   *   Mutually exclusive with `vocabulary`. If provided, `metadatURL`\n   *   most also be provided.\n   * @param metadataOrURL A custom metadata URL pointing to a metadata.json\n   *   file. Or it can be a metadata JSON object itself. Must be provided\n   *   together with `modelArtifactsOrURL`.\n   */\n  constructor(\n      vocabulary?: string, modelArtifactsOrURL?: tf.io.ModelArtifacts|string,\n      metadataOrURL?: SpeechCommandRecognizerMetadata|string) {\n    // TODO(cais): Consolidate the fields into a single config object when\n    // upgrading to v1.0.\n    tf.util.assert(\n        modelArtifactsOrURL == null && metadataOrURL == null ||\n            modelArtifactsOrURL != null && metadataOrURL != null,\n        () => `modelURL and metadataURL must be both provided or ` +\n            `both not provided.`);\n    if (modelArtifactsOrURL == null) {\n      if (vocabulary == null) {\n        vocabulary = BrowserFftSpeechCommandRecognizer.DEFAULT_VOCABULARY_NAME;\n      } else {\n        tf.util.assert(\n            BrowserFftSpeechCommandRecognizer.VALID_VOCABULARY_NAMES.indexOf(\n                vocabulary) !== -1,\n            () => `Invalid vocabulary name: '${vocabulary}'`);\n      }\n      this.vocabulary = vocabulary;\n      this.modelArtifactsOrURL =\n          `${this.MODEL_URL_PREFIX}/${this.vocabulary}/model.json`;\n      this.metadataOrURL =\n          `${this.MODEL_URL_PREFIX}/${this.vocabulary}/metadata.json`;\n    } else {\n      tf.util.assert(\n          vocabulary == null,\n          () => `vocabulary name must be null or undefined when modelURL is ` +\n              `provided`);\n      this.modelArtifactsOrURL = modelArtifactsOrURL;\n      this.metadataOrURL = metadataOrURL;\n    }\n\n    this.parameters = {\n      sampleRateHz: this.SAMPLE_RATE_HZ,\n      fftSize: this.FFT_SIZE\n    };\n  }\n\n  /**\n   * Start streaming recognition.\n   *\n   * To stop the recognition, use `stopListening()`.\n   *\n   * Example: TODO(cais): Add exapmle code snippet.\n   *\n   * @param callback The callback invoked whenever a word is recognized\n   *   with a probability score greater than `config.probabilityThreshold`.\n   *   It has the signature:\n   *     (result: SpeechCommandRecognizerResult) => Promise<void>\n   *   wherein result has the two fields:\n   *   - scores: A Float32Array that contains the probability scores for all\n   *     the words.\n   *   - spectrogram: The spectrogram data, provided only if\n   *     `config.includeSpectrogram` is `true`.\n   * @param config The configurations for the streaming recognition to\n   *   be started.\n   *   The `modelName` field of `config` specifies the model to be used for\n   *   online recognition. If not specified, it defaults to the name of the\n   *   base model ('base'), i.e., the pretrained model not from transfer\n   *   learning. If the recognizer instance has one or more transfer-learning\n   *   models ready (as a result of calls to `collectTransferExample`\n   *   and `trainTransferModel`), you can let this call use that\n   *   model for prediction by specifying the corresponding `modelName`.\n   * @throws Error, if streaming recognition is already started or\n   *   if `config` contains invalid values.\n   */\n  async listen(\n      callback: RecognizerCallback,\n      config?: StreamingRecognitionConfig): Promise<void> {\n    if (this.streaming) {\n      throw new Error(\n          'Cannot start streaming again when streaming is ongoing.');\n    }\n\n    await this.ensureModelLoaded();\n\n    if (config == null) {\n      config = {};\n    }\n    let probabilityThreshold =\n        config.probabilityThreshold == null ? 0 : config.probabilityThreshold;\n    if (config.includeEmbedding) {\n      // Override probability threshold to 0 if includeEmbedding is true.\n      probabilityThreshold = 0;\n    }\n    tf.util.assert(\n        probabilityThreshold >= 0 && probabilityThreshold <= 1,\n        () => `Invalid probabilityThreshold value: ${probabilityThreshold}`);\n    let invokeCallbackOnNoiseAndUnknown =\n        config.invokeCallbackOnNoiseAndUnknown == null ?\n        false :\n        config.invokeCallbackOnNoiseAndUnknown;\n    if (config.includeEmbedding) {\n      // Override invokeCallbackOnNoiseAndUnknown threshold to true if\n      // includeEmbedding is true.\n      invokeCallbackOnNoiseAndUnknown = true;\n    }\n\n    if (config.suppressionTimeMillis < 0) {\n      throw new Error(\n          `suppressionTimeMillis is expected to be >= 0, ` +\n          `but got ${config.suppressionTimeMillis}`);\n    }\n\n    const overlapFactor =\n        config.overlapFactor == null ? 0.5 : config.overlapFactor;\n    tf.util.assert(\n        overlapFactor >= 0 && overlapFactor < 1,\n        () => `Expected overlapFactor to be >= 0 and < 1, but got ${\n            overlapFactor}`);\n\n    const spectrogramCallback: SpectrogramCallback =\n        async (x: tf.Tensor, timeData?: tf.Tensor) => {\n      const normalizedX = normalize(x);\n      let y: tf.Tensor;\n      let embedding: tf.Tensor;\n      if (config.includeEmbedding) {\n        await this.ensureModelWithEmbeddingOutputCreated();\n        [y, embedding] =\n            this.modelWithEmbeddingOutput.predict(normalizedX) as tf.Tensor[];\n      } else {\n        y = this.model.predict(normalizedX) as tf.Tensor;\n      }\n\n      const scores = await y.data() as Float32Array;\n      const maxIndexTensor = y.argMax(-1);\n      const maxIndex = (await maxIndexTensor.data())[0];\n      const maxScore = Math.max(...scores);\n      tf.dispose([y, maxIndexTensor, normalizedX]);\n\n      if (maxScore < probabilityThreshold) {\n        return false;\n      } else {\n        let spectrogram: SpectrogramData = undefined;\n        if (config.includeSpectrogram) {\n          spectrogram = {\n            data: await x.data() as Float32Array,\n            frameSize: this.nonBatchInputShape[1],\n          };\n        }\n\n        let wordDetected = true;\n        if (!invokeCallbackOnNoiseAndUnknown) {\n          // Skip background noise and unknown tokens.\n          if (this.words[maxIndex] === BACKGROUND_NOISE_TAG ||\n              this.words[maxIndex] === UNKNOWN_TAG) {\n            wordDetected = false;\n          }\n        }\n        if (wordDetected) {\n          callback({scores, spectrogram, embedding});\n        }\n        // Trigger suppression only if the word is neither unknown or\n        // background noise.\n        return wordDetected;\n      }\n    };\n\n    const suppressionTimeMillis = config.suppressionTimeMillis == null ?\n        this.DEFAULT_SUPPRESSION_TIME_MILLIS :\n        config.suppressionTimeMillis;\n    this.audioDataExtractor = new BrowserFftFeatureExtractor({\n      sampleRateHz: this.parameters.sampleRateHz,\n      numFramesPerSpectrogram: this.nonBatchInputShape[0],\n      columnTruncateLength: this.nonBatchInputShape[1],\n      suppressionTimeMillis,\n      spectrogramCallback,\n      overlapFactor\n    });\n\n    await this.audioDataExtractor.start(config.audioTrackConstraints);\n\n    this.streaming = true;\n  }\n\n  /**\n   * Load the underlying tf.LayersModel instance and associated metadata.\n   *\n   * If the model and the metadata are already loaded, do nothing.\n   */\n  async ensureModelLoaded() {\n    if (this.model != null) {\n      return;\n    }\n\n    await this.ensureMetadataLoaded();\n\n    let model: tf.LayersModel;\n    if (typeof this.modelArtifactsOrURL === 'string') {\n      model = await tf.loadLayersModel(this.modelArtifactsOrURL);\n    } else {\n      // this.modelArtifactsOrURL is an instance of `tf.io.ModelArtifacts`.\n      model = await tf.loadLayersModel(tf.io.fromMemory(\n          this.modelArtifactsOrURL.modelTopology,\n          this.modelArtifactsOrURL.weightSpecs,\n          this.modelArtifactsOrURL.weightData));\n    }\n\n    // Check the validity of the model's input shape.\n    if (model.inputs.length !== 1) {\n      throw new Error(\n          `Expected model to have 1 input, but got a model with ` +\n          `${model.inputs.length} inputs`);\n    }\n    if (model.inputs[0].shape.length !== 4) {\n      throw new Error(\n          `Expected model to have an input shape of rank 4, ` +\n          `but got an input shape of rank ${model.inputs[0].shape.length}`);\n    }\n    if (model.inputs[0].shape[3] !== 1) {\n      throw new Error(\n          `Expected model to have an input shape with 1 as the last ` +\n          `dimension, but got input shape` +\n          `${JSON.stringify(model.inputs[0].shape[3])}}`);\n    }\n    // Check the consistency between the word labels and the model's output\n    // shape.\n    const outputShape = model.outputShape as tf.Shape;\n    if (outputShape.length !== 2) {\n      throw new Error(\n          `Expected loaded model to have an output shape of rank 2,` +\n          `but received shape ${JSON.stringify(outputShape)}`);\n    }\n    if (outputShape[1] !== this.words.length) {\n      throw new Error(\n          `Mismatch between the last dimension of model's output shape ` +\n          `(${outputShape[1]}) and number of words ` +\n          `(${this.words.length}).`);\n    }\n\n    this.model = model;\n    this.freezeModel();\n\n    this.nonBatchInputShape =\n        model.inputs[0].shape.slice(1) as [number, number, number];\n    this.elementsPerExample = 1;\n    model.inputs[0].shape.slice(1).forEach(\n        dimSize => this.elementsPerExample *= dimSize);\n    this.warmUpModel();\n    const frameDurationMillis =\n        this.parameters.fftSize / this.parameters.sampleRateHz * 1e3;\n    const numFrames = model.inputs[0].shape[1];\n    this.parameters.spectrogramDurationMillis = numFrames * frameDurationMillis;\n  }\n\n  /**\n   * Construct a two-output model that includes the following outputs:\n   *\n   * 1. The same softmax probability output as the original model's output\n   * 2. The embedding, i.e., activation from the second-last dense layer of\n   *    the original model.\n   */\n  protected async ensureModelWithEmbeddingOutputCreated() {\n    if (this.modelWithEmbeddingOutput != null) {\n      return;\n    }\n    await this.ensureModelLoaded();\n\n    // Find the second last dense layer of the original model.\n    let secondLastDenseLayer: tf.layers.Layer;\n    for (let i = this.model.layers.length - 2; i >= 0; --i) {\n      if (this.model.layers[i].getClassName() === 'Dense') {\n        secondLastDenseLayer = this.model.layers[i];\n        break;\n      }\n    }\n    if (secondLastDenseLayer == null) {\n      throw new Error(\n          'Failed to find second last dense layer in the original model.');\n    }\n    this.modelWithEmbeddingOutput = tf.model({\n      inputs: this.model.inputs,\n      outputs: [\n        this.model.outputs[0], secondLastDenseLayer.output as tf.SymbolicTensor\n      ]\n    });\n  }\n\n  private warmUpModel() {\n    tf.tidy(() => {\n      const x = tf.zeros([1].concat(this.nonBatchInputShape));\n      for (let i = 0; i < 3; ++i) {\n        this.model.predict(x);\n      }\n    });\n  }\n\n  private async ensureMetadataLoaded() {\n    if (this.words != null) {\n      return;\n    }\n\n    const metadataJSON = typeof this.metadataOrURL === 'string' ?\n        await loadMetadataJson(this.metadataOrURL) :\n        this.metadataOrURL;\n\n    if (metadataJSON.wordLabels == null) {\n      // In some legacy formats, the field 'words', instead of 'wordLabels',\n      // was populated. This branch ensures backward compatibility with those\n      // formats.\n      // tslint:disable-next-line:no-any\n      const legacyWords = (metadataJSON as any)['words'] as string[];\n      if (legacyWords == null) {\n        throw new Error(\n            'Cannot find field \"words\" or \"wordLabels\" in metadata JSON file');\n      }\n      this.words = legacyWords;\n    } else {\n      this.words = metadataJSON.wordLabels;\n    }\n  }\n\n  /**\n   * Stop streaming recognition.\n   *\n   * @throws Error if there is not ongoing streaming recognition.\n   */\n  async stopListening(): Promise<void> {\n    if (!this.streaming) {\n      throw new Error('Cannot stop streaming when streaming is not ongoing.');\n    }\n    await this.audioDataExtractor.stop();\n    this.streaming = false;\n  }\n\n  /**\n   * Check if streaming recognition is ongoing.\n   */\n  isListening(): boolean {\n    return this.streaming;\n  }\n\n  /**\n   * Get the array of word labels.\n   *\n   * @throws Error If this model is called before the model is loaded.\n   */\n  wordLabels(): string[] {\n    return this.words;\n  }\n\n  /**\n   * Get the parameters of this instance of BrowserFftSpeechCommandRecognizer.\n   *\n   * @returns Parameters of this instance.\n   */\n  params(): RecognizerParams {\n    return this.parameters;\n  }\n\n  /**\n   * Get the input shape of the underlying tf.LayersModel.\n   *\n   * @returns The input shape.\n   */\n  modelInputShape(): tf.Shape {\n    if (this.model == null) {\n      throw new Error(\n          'Model has not been loaded yet. Load model by calling ' +\n          'ensureModelLoaded(), recognize(), or listen().');\n    }\n    return this.model.inputs[0].shape;\n  }\n\n  /**\n   * Run offline (non-streaming) recognition on a spectrogram.\n   *\n   * @param input Spectrogram. Either a `tf.Tensor` of a `Float32Array`.\n   *   - If a `tf.Tensor`, must be rank-4 and match the model's expected\n   *     input shape in 2nd dimension (# of spectrogram columns), the 3rd\n   *     dimension (# of frequency-domain points per column), and the 4th\n   *     dimension (always 1). The 1st dimension can be 1, for single-example\n   *     recogntion, or any value >1, for batched recognition.\n   *   - If a `Float32Array`, must have a length divisible by the number\n   *     of elements per spectrogram, i.e.,\n   *     (# of spectrogram columns) * (# of frequency-domain points per column).\n   * @param config Optional configuration object.\n   * @returns Result of the recognition, with the following field:\n   *   scores:\n   *   - A `Float32Array` if there is only one input exapmle.\n   *   - An `Array` of `Float32Array`, if there are multiple input examples.\n   */\n  async recognize(input?: tf.Tensor|Float32Array, config?: RecognizeConfig):\n      Promise<SpeechCommandRecognizerResult> {\n    if (config == null) {\n      config = {};\n    }\n\n    await this.ensureModelLoaded();\n\n    if (input == null) {\n      // If `input` is not provided, draw audio data from WebAudio and us it\n      // for recognition.\n      const spectrogramData = await this.recognizeOnline();\n      input = spectrogramData.data;\n    }\n\n    let numExamples: number;\n    let inputTensor: tf.Tensor;\n    let outTensor: tf.Tensor;\n    if (input instanceof tf.Tensor) {\n      // Check input shape.\n      this.checkInputTensorShape(input);\n      inputTensor = input;\n      numExamples = input.shape[0];\n    } else {\n      if (input.length % this.elementsPerExample) {\n        throw new Error(\n            `The length of the input Float32Array ${input.length} ` +\n            `is not divisible by the number of tensor elements per ` +\n            `per example expected by the model ${this.elementsPerExample}.`);\n      }\n\n      numExamples = input.length / this.elementsPerExample;\n      inputTensor = tf.tensor4d(input, [\n        numExamples\n      ].concat(this.nonBatchInputShape) as [number, number, number, number]);\n    }\n\n    const output: SpeechCommandRecognizerResult = {scores: null};\n    if (config.includeEmbedding) {\n      // Optional inclusion of embedding (internal activation).\n      await this.ensureModelWithEmbeddingOutputCreated();\n      const outAndEmbedding =\n          this.modelWithEmbeddingOutput.predict(inputTensor) as tf.Tensor[];\n      outTensor = outAndEmbedding[0];\n      output.embedding = outAndEmbedding[1];\n    } else {\n      outTensor = this.model.predict(inputTensor) as tf.Tensor;\n    }\n\n    if (numExamples === 1) {\n      output.scores = await outTensor.data() as Float32Array;\n    } else {\n      const unstacked = tf.unstack(outTensor);\n      const scorePromises = unstacked.map(item => item.data());\n      output.scores = await Promise.all(scorePromises) as Float32Array[];\n      tf.dispose(unstacked);\n    }\n\n    if (config.includeSpectrogram) {\n      output.spectrogram = {\n        data: (input instanceof tf.Tensor ? await input.data() : input) as\n            Float32Array,\n        frameSize: this.nonBatchInputShape[1],\n      };\n    }\n\n    tf.dispose(outTensor);\n    return output;\n  }\n\n  private async recognizeOnline(): Promise<SpectrogramData> {\n    return new Promise<SpectrogramData>((resolve, reject) => {\n      const spectrogramCallback: SpectrogramCallback = async (x: tf.Tensor) => {\n        const normalizedX = normalize(x);\n        await this.audioDataExtractor.stop();\n        resolve({\n          data: await normalizedX.data() as Float32Array,\n          frameSize: this.nonBatchInputShape[1],\n        });\n        normalizedX.dispose();\n        return false;\n      };\n      this.audioDataExtractor = new BrowserFftFeatureExtractor({\n        sampleRateHz: this.parameters.sampleRateHz,\n        numFramesPerSpectrogram: this.nonBatchInputShape[0],\n        columnTruncateLength: this.nonBatchInputShape[1],\n        suppressionTimeMillis: 0,\n        spectrogramCallback,\n        overlapFactor: 0\n      });\n      this.audioDataExtractor.start();\n    });\n  }\n\n  createTransfer(name: string): TransferSpeechCommandRecognizer {\n    if (this.model == null) {\n      throw new Error(\n          'Model has not been loaded yet. Load model by calling ' +\n          'ensureModelLoaded(), recognizer(), or listen().');\n    }\n    tf.util.assert(\n        name != null && typeof name === 'string' && name.length > 1,\n        () => `Expected the name for a transfer-learning recognized to be a ` +\n            `non-empty string, but got ${JSON.stringify(name)}`);\n    tf.util.assert(\n        this.transferRecognizers[name] == null,\n        () => `There is already a transfer-learning model named '${name}'`);\n    const transfer = new TransferBrowserFftSpeechCommandRecognizer(\n        name, this.parameters, this.model);\n    this.transferRecognizers[name] = transfer;\n    return transfer;\n  }\n\n  protected freezeModel(): void {\n    for (const layer of this.model.layers) {\n      layer.trainable = false;\n    }\n  }\n\n  private checkInputTensorShape(input: tf.Tensor) {\n    const expectedRank = this.model.inputs[0].shape.length;\n    if (input.shape.length !== expectedRank) {\n      throw new Error(\n          `Expected input Tensor to have rank ${expectedRank}, ` +\n          `but got rank ${input.shape.length} that differs `);\n    }\n    const nonBatchedShape = input.shape.slice(1);\n    const expectedNonBatchShape = this.model.inputs[0].shape.slice(1);\n    if (!tf.util.arraysEqual(nonBatchedShape, expectedNonBatchShape)) {\n      throw new Error(\n          `Expected input to have shape [null,${expectedNonBatchShape}], ` +\n          `but got shape [null,${nonBatchedShape}]`);\n    }\n  }\n}\n\n/**\n * A subclass of BrowserFftSpeechCommandRecognizer: Transfer-learned model.\n */\nclass TransferBrowserFftSpeechCommandRecognizer extends\n    BrowserFftSpeechCommandRecognizer implements\n        TransferSpeechCommandRecognizer {\n  private dataset: Dataset;\n  private transferHead: tf.Sequential;\n\n  /**\n   * Constructor of TransferBrowserFftSpeechCommandRecognizer.\n   *\n   * @param name Name of the transfer-learned recognizer. Must be a non-empty\n   *   string.\n   * @param parameters Parameters from the base recognizer.\n   * @param baseModel Model from the base recognizer.\n   */\n  constructor(\n      readonly name: string, readonly parameters: RecognizerParams,\n      readonly baseModel: tf.LayersModel) {\n    super();\n    tf.util.assert(\n        name != null && typeof name === 'string' && name.length > 0,\n        () => `The name of a transfer model must be a non-empty string, ` +\n            `but got ${JSON.stringify(name)}`);\n    this.nonBatchInputShape =\n        this.baseModel.inputs[0].shape.slice(1) as [number, number, number];\n    this.words = null;\n    this.dataset = new Dataset();\n  }\n\n  /**\n   * Collect an example for transfer learning via WebAudio.\n   *\n   * @param {string} word Name of the word. Must not overlap with any of the\n   *   words the base model is trained to recognize.\n   * @param {ExampleCollectionOptions}\n   * @returns {SpectrogramData} The spectrogram of the acquired the example.\n   * @throws Error, if word belongs to the set of words the base model is\n   *   trained to recognize.\n   */\n  async collectExample(word: string, options?: ExampleCollectionOptions):\n      Promise<SpectrogramData> {\n    tf.util.assert(\n        !this.streaming,\n        () => 'Cannot start collection of transfer-learning example because ' +\n            'a streaming recognition or transfer-learning example collection ' +\n            'is ongoing');\n    tf.util.assert(\n        word != null && typeof word === 'string' && word.length > 0,\n        () => `Must provide a non-empty string when collecting transfer-` +\n            `learning example`);\n\n    if (options == null) {\n      options = {};\n    }\n    if (options.durationMultiplier != null && options.durationSec != null) {\n      throw new Error(\n          `durationMultiplier and durationSec are mutually exclusive, ` +\n          `but are both specified.`);\n    }\n\n    let numFramesPerSpectrogram: number;\n    if (options.durationSec != null) {\n      tf.util.assert(\n          options.durationSec > 0,\n          () =>\n              `Expected durationSec to be > 0, but got ${options.durationSec}`);\n      const frameDurationSec =\n          this.parameters.fftSize / this.parameters.sampleRateHz;\n      numFramesPerSpectrogram =\n          Math.ceil(options.durationSec / frameDurationSec);\n    } else if (options.durationMultiplier != null) {\n      tf.util.assert(\n          options.durationMultiplier >= 1,\n          () => `Expected duration multiplier to be >= 1, ` +\n              `but got ${options.durationMultiplier}`);\n      numFramesPerSpectrogram =\n          Math.round(this.nonBatchInputShape[0] * options.durationMultiplier);\n    } else {\n      numFramesPerSpectrogram = this.nonBatchInputShape[0];\n    }\n\n    if (options.snippetDurationSec != null) {\n      tf.util.assert(\n          options.snippetDurationSec > 0,\n          () => `snippetDurationSec is expected to be > 0, but got ` +\n              `${options.snippetDurationSec}`);\n      tf.util.assert(\n          options.onSnippet != null,\n          () => `onSnippet must be provided if snippetDurationSec ` +\n              `is provided.`);\n    }\n    if (options.onSnippet != null) {\n      tf.util.assert(\n          options.snippetDurationSec != null,\n          () => `snippetDurationSec must be provided if onSnippet ` +\n              `is provided.`);\n    }\n    const frameDurationSec =\n        this.parameters.fftSize / this.parameters.sampleRateHz;\n    const totalDurationSec = frameDurationSec * numFramesPerSpectrogram;\n\n    this.streaming = true;\n    return new Promise<SpectrogramData>(resolve => {\n      const stepFactor = options.snippetDurationSec == null ?\n          1 :\n          options.snippetDurationSec / totalDurationSec;\n      const overlapFactor = 1 - stepFactor;\n      const callbackCountTarget = Math.round(1 / stepFactor);\n      let callbackCount = 0;\n      let lastIndex = -1;\n      const spectrogramSnippets: Float32Array[] = [];\n\n      const spectrogramCallback: SpectrogramCallback =\n          async (freqData: tf.Tensor, timeData?: tf.Tensor) => {\n        // TODO(cais): can we consolidate the logic in the two branches?\n        if (options.onSnippet == null) {\n          const normalizedX = normalize(freqData);\n          this.dataset.addExample({\n            label: word,\n            spectrogram: {\n              data: await normalizedX.data() as Float32Array,\n              frameSize: this.nonBatchInputShape[1],\n            },\n            rawAudio: options.includeRawAudio ? {\n              data: await timeData.data() as Float32Array,\n              sampleRateHz: this.audioDataExtractor.sampleRateHz\n            } :\n                                                undefined\n          });\n          normalizedX.dispose();\n          await this.audioDataExtractor.stop();\n          this.streaming = false;\n          this.collateTransferWords();\n          resolve({\n            data: await freqData.data() as Float32Array,\n            frameSize: this.nonBatchInputShape[1],\n          });\n        } else {\n          const data = await freqData.data() as Float32Array;\n          if (lastIndex === -1) {\n            lastIndex = data.length;\n          }\n          let i = lastIndex - 1;\n          while (data[i] !== 0 && i >= 0) {\n            i--;\n          }\n          const increment = lastIndex - i - 1;\n          lastIndex = i + 1;\n          const snippetData = data.slice(data.length - increment, data.length);\n          spectrogramSnippets.push(snippetData);\n\n          if (options.onSnippet != null) {\n            options.onSnippet(\n                {data: snippetData, frameSize: this.nonBatchInputShape[1]});\n          }\n\n          if (callbackCount++ === callbackCountTarget) {\n            await this.audioDataExtractor.stop();\n            this.streaming = false;\n            this.collateTransferWords();\n\n            const normalized = normalizeFloat32Array(\n                concatenateFloat32Arrays(spectrogramSnippets));\n            const finalSpectrogram: SpectrogramData = {\n              data: normalized,\n              frameSize: this.nonBatchInputShape[1]\n            };\n            this.dataset.addExample({\n              label: word,\n              spectrogram: finalSpectrogram,\n              rawAudio: options.includeRawAudio ? {\n                data: await timeData.data() as Float32Array,\n                sampleRateHz: this.audioDataExtractor.sampleRateHz\n              } :\n                                                  undefined\n            });\n            // TODO(cais): Fix 1-tensor memory leak.\n            resolve(finalSpectrogram);\n          }\n        }\n        return false;\n      };\n      this.audioDataExtractor = new BrowserFftFeatureExtractor({\n        sampleRateHz: this.parameters.sampleRateHz,\n        numFramesPerSpectrogram,\n        columnTruncateLength: this.nonBatchInputShape[1],\n        suppressionTimeMillis: 0,\n        spectrogramCallback,\n        overlapFactor,\n        includeRawAudio: options.includeRawAudio\n      });\n      this.audioDataExtractor.start(options.audioTrackConstraints);\n    });\n  }\n\n  /**\n   * Clear all transfer learning examples collected so far.\n   */\n  clearExamples(): void {\n    tf.util.assert(\n        this.words != null && this.words.length > 0 && !this.dataset.empty(),\n        () =>\n            `No transfer learning examples exist for model name ${this.name}`);\n    this.dataset.clear();\n    this.words = null;\n  }\n\n  /**\n   * Get counts of the word examples that have been collected for a\n   * transfer-learning model.\n   *\n   * @returns {{[word: string]: number}} A map from word name to number of\n   *   examples collected for that word so far.\n   */\n  countExamples(): {[word: string]: number} {\n    if (this.dataset.empty()) {\n      throw new Error(\n          `No examples have been collected for transfer-learning model ` +\n          `named '${this.name}' yet.`);\n    }\n    return this.dataset.getExampleCounts();\n  }\n\n  /**\n   * Get examples currently held by the transfer-learning recognizer.\n   *\n   * @param label Label requested.\n   * @returns An array of `Example`s, along with their UIDs.\n   */\n  getExamples(label: string): Array<{uid: string, example: Example}> {\n    return this.dataset.getExamples(label);\n  }\n\n  /** Set the key frame index of a given example. */\n  setExampleKeyFrameIndex(uid: string, keyFrameIndex: number): void {\n    this.dataset.setExampleKeyFrameIndex(uid, keyFrameIndex);\n  }\n\n  /**\n   * Remove an example from the current dataset.\n   *\n   * @param uid The UID of the example to remove.\n   */\n  removeExample(uid: string): void {\n    this.dataset.removeExample(uid);\n    this.collateTransferWords();\n  }\n\n  /**\n   * Check whether the underlying dataset is empty.\n   *\n   * @returns A boolean indicating whether the underlying dataset is empty.\n   */\n  isDatasetEmpty(): boolean {\n    return this.dataset.empty();\n  }\n\n  /**\n   * Load an array of serialized examples.\n   *\n   * @param serialized The examples in their serialized format.\n   * @param clearExisting Whether to clear the existing examples while\n   *   performing the loading (default: false).\n   */\n  loadExamples(serialized: ArrayBuffer, clearExisting = false): void {\n    const incomingDataset = new Dataset(serialized);\n    if (clearExisting) {\n      this.clearExamples();\n    }\n\n    const incomingVocab = incomingDataset.getVocabulary();\n    for (const label of incomingVocab) {\n      const examples = incomingDataset.getExamples(label);\n      for (const example of examples) {\n        this.dataset.addExample(example.example);\n      }\n    }\n\n    this.collateTransferWords();\n  }\n\n  /**\n   * Serialize the existing examples.\n   *\n   * @param wordLabels Optional word label(s) to serialize. If specified, only\n   *   the examples with labels matching the argument will be serialized. If\n   *   any specified word label does not exist in the vocabulary of this\n   *   transfer recognizer, an Error will be thrown.\n   * @returns An `ArrayBuffer` object amenable to transmission and storage.\n   */\n  serializeExamples(wordLabels?: string|string[]): ArrayBuffer {\n    return this.dataset.serialize(wordLabels);\n  }\n\n  /**\n   * Collect the vocabulary of this transfer-learned recognizer.\n   *\n   * The words are put in an alphabetically sorted order.\n   */\n  private collateTransferWords() {\n    this.words = this.dataset.getVocabulary();\n  }\n\n  /**\n   * Collect the transfer-learning data as `tf.Tensor`s.\n   *\n   * Used for training and evaluation when the amount of data is relatively\n   * small.\n   *\n   * @param windowHopRatio Ratio betwen hop length in number of frames and the\n   *   number of frames in a long spectrogram. Used during extraction\n   *   of multiple windows from the long spectrogram.\n   * @returns xs: The feature tensors (xs), a 4D tf.Tensor.\n   *          ys: The target tensors (ys), one-hot encoding, a 2D tf.Tensor.\n   */\n  private collectTransferDataAsTensors(\n      windowHopRatio?: number,\n      augmentationOptions?: AudioDataAugmentationOptions):\n      {xs: tf.Tensor, ys: tf.Tensor} {\n    const numFrames = this.nonBatchInputShape[0];\n    windowHopRatio = windowHopRatio || DEFAULT_WINDOW_HOP_RATIO;\n    const hopFrames = Math.round(windowHopRatio * numFrames);\n    const out = this.dataset.getData(\n                    null, {numFrames, hopFrames, ...augmentationOptions}) as\n        {xs: tf.Tensor4D, ys?: tf.Tensor2D};\n    return {xs: out.xs, ys: out.ys as tf.Tensor};\n  }\n\n  /**\n   * Same as `collectTransferDataAsTensors`, but returns `tf.data.Dataset`s.\n   *\n   * Used for training and evaluation when the amount of data is large.\n   *\n   * @param windowHopRatio Ratio betwen hop length in number of frames and the\n   *   number of frames in a long spectrogram. Used during extraction\n   *   of multiple windows from the long spectrogram.\n   * @param validationSplit The validation split to be used for splitting\n   *   the raw data between the `tf.data.Dataset` objects for training and\n   *   validation.\n   * @param batchSize Batch size used for the `tf.data.Dataset.batch()` call\n   *   during the creation of the dataset objects.\n   * @return Two `tf.data.Dataset` objects, one for training and one for\n   *   validation. Each of the objects may be directly fed into\n   *   `this.model.fitDataset`.\n   */\n  private collectTransferDataAsTfDataset(\n      windowHopRatio?: number, validationSplit = 0.15, batchSize = 32,\n      augmentationOptions?: AudioDataAugmentationOptions):\n      [tf.data.Dataset<{}>, tf.data.Dataset<{}>] {\n    const numFrames = this.nonBatchInputShape[0];\n    windowHopRatio = windowHopRatio || DEFAULT_WINDOW_HOP_RATIO;\n    const hopFrames = Math.round(windowHopRatio * numFrames);\n    return this.dataset.getData(null, {\n      numFrames,\n      hopFrames,\n      getDataset: true,\n      datasetBatchSize: batchSize,\n      datasetValidationSplit: validationSplit,\n      ...augmentationOptions\n    }) as [tf.data.Dataset<{}>, tf.data.Dataset<{}>];\n    // TODO(cais): See if we can tighten the typing.\n  }\n\n  /**\n   * Train the transfer-learning model.\n   *\n   * The last dense layer of the base model is replaced with new softmax dense\n   * layer.\n   *\n   * It is assume that at least one category of data has been collected (using\n   * multiple calls to the `collectTransferExample` method).\n   *\n   * @param config {TransferLearnConfig} Optional configurations fot the\n   *   training of the transfer-learning model.\n   * @returns {tf.History} A history object with the loss and accuracy values\n   *   from the training of the transfer-learning model.\n   * @throws Error, if `modelName` is invalid or if not sufficient training\n   *   examples have been collected yet.\n   */\n  async train(config?: TransferLearnConfig):\n      Promise<tf.History|[tf.History, tf.History]> {\n    tf.util.assert(\n        this.words != null && this.words.length > 0,\n        () =>\n            `Cannot train transfer-learning model '${this.name}' because no ` +\n            `transfer learning example has been collected.`);\n    tf.util.assert(\n        this.words.length > 1,\n        () => `Cannot train transfer-learning model '${\n                  this.name}' because only ` +\n            `1 word label ('${JSON.stringify(this.words)}') ` +\n            `has been collected for transfer learning. Requires at least 2.`);\n    if (config.fineTuningEpochs != null) {\n      tf.util.assert(\n          config.fineTuningEpochs >= 0 &&\n              Number.isInteger(config.fineTuningEpochs),\n          () => `If specified, fineTuningEpochs must be a non-negative ` +\n              `integer, but received ${config.fineTuningEpochs}`);\n    }\n\n    if (config == null) {\n      config = {};\n    }\n\n    if (this.model == null) {\n      this.createTransferModelFromBaseModel();\n    }\n\n    // This layer needs to be frozen for the initial phase of the\n    // transfer learning. During subsequent fine-tuning (if any), it will\n    // be unfrozen.\n    this.secondLastBaseDenseLayer.trainable = false;\n\n    // Compile model for training.\n    this.model.compile({\n      loss: 'categoricalCrossentropy',\n      optimizer: config.optimizer || 'sgd',\n      metrics: ['acc']\n    });\n\n    // Use `tf.data.Dataset` objects for training of the total duration of\n    // the recordings exceeds 60 seconds. Otherwise, use `tf.Tensor` objects.\n    const datasetDurationMillisThreshold =\n        config.fitDatasetDurationMillisThreshold == null ?\n        60e3 :\n        config.fitDatasetDurationMillisThreshold;\n    if (this.dataset.durationMillis() > datasetDurationMillisThreshold) {\n      console.log(\n          `Detected large dataset: total duration = ` +\n          `${this.dataset.durationMillis()} ms > ` +\n          `${datasetDurationMillisThreshold} ms. ` +\n          `Training transfer model using fitDataset() instead of fit()`);\n      return this.trainOnDataset(config);\n    } else {\n      return this.trainOnTensors(config);\n    }\n  }\n\n  /** Helper function for training on tf.data.Dataset objects. */\n  private async trainOnDataset(config?: TransferLearnConfig):\n      Promise<tf.History|[tf.History, tf.History]> {\n    tf.util.assert(config.epochs > 0, () => `Invalid config.epochs`);\n    // Train transfer-learning model using fitDataset\n\n    const batchSize = config.batchSize == null ? 32 : config.batchSize;\n    const windowHopRatio = config.windowHopRatio || DEFAULT_WINDOW_HOP_RATIO;\n    const [trainDataset, valDataset] = this.collectTransferDataAsTfDataset(\n        windowHopRatio, config.validationSplit, batchSize,\n        {augmentByMixingNoiseRatio: config.augmentByMixingNoiseRatio});\n    const t0 = tf.util.now();\n    const history = await this.model.fitDataset(trainDataset, {\n      epochs: config.epochs,\n      validationData: config.validationSplit > 0 ? valDataset : null,\n      callbacks: config.callback == null ? null : [config.callback]\n    });\n    console.log(`fitDataset() took ${(tf.util.now() - t0).toFixed(2)} ms`);\n\n    if (config.fineTuningEpochs != null && config.fineTuningEpochs > 0) {\n      // Perform fine-tuning.\n      const t0 = tf.util.now();\n      const fineTuningHistory = await this.fineTuningUsingTfDatasets(\n          config, trainDataset, valDataset);\n      console.log(\n          `fitDataset() (fine-tuning) took ` +\n          `${(tf.util.now() - t0).toFixed(2)} ms`);\n      return [history, fineTuningHistory];\n    } else {\n      return history;\n    }\n  }\n\n  /** Helper function for training on tf.Tensor objects. */\n  private async trainOnTensors(config?: TransferLearnConfig):\n      Promise<tf.History|[tf.History, tf.History]> {\n    // Prepare the data.\n    const windowHopRatio = config.windowHopRatio || DEFAULT_WINDOW_HOP_RATIO;\n    const {xs, ys} = this.collectTransferDataAsTensors(\n        windowHopRatio,\n        {augmentByMixingNoiseRatio: config.augmentByMixingNoiseRatio});\n    console.log(\n        `Training data: xs.shape = ${xs.shape}, ys.shape = ${ys.shape}`);\n\n    let trainXs: tf.Tensor;\n    let trainYs: tf.Tensor;\n    let valData: [tf.Tensor, tf.Tensor];\n    try {\n      // TODO(cais): The balanced split may need to be pushed down to the\n      //   level of the Dataset class to avoid leaks between train and val\n      //   splits.\n      if (config.validationSplit != null) {\n        const splits = balancedTrainValSplit(xs, ys, config.validationSplit);\n        trainXs = splits.trainXs;\n        trainYs = splits.trainYs;\n        valData = [splits.valXs, splits.valYs];\n      } else {\n        trainXs = xs;\n        trainYs = ys;\n      }\n\n      const history = await this.model.fit(trainXs, trainYs, {\n        epochs: config.epochs == null ? 20 : config.epochs,\n        validationData: valData,\n        batchSize: config.batchSize,\n        callbacks: config.callback == null ? null : [config.callback]\n      });\n\n      if (config.fineTuningEpochs != null && config.fineTuningEpochs > 0) {\n        // Fine tuning: unfreeze the second-last dense layer of the base\n        // model.\n        const fineTuningHistory = await this.fineTuningUsingTensors(\n            config, trainXs, trainYs, valData);\n        return [history, fineTuningHistory];\n      } else {\n        return history;\n      }\n    } finally {\n      tf.dispose([xs, ys, trainXs, trainYs, valData]);\n    }\n  }\n\n  private async fineTuningUsingTfDatasets(\n      config: TransferLearnConfig, trainDataset: tf.data.Dataset<{}>,\n      valDataset: tf.data.Dataset<{}>): Promise<tf.History> {\n    const originalTrainableValue = this.secondLastBaseDenseLayer.trainable;\n    this.secondLastBaseDenseLayer.trainable = true;\n\n    // Recompile model after unfreezing layer.\n    const fineTuningOptimizer: string|tf.Optimizer =\n        config.fineTuningOptimizer == null ? 'sgd' : config.fineTuningOptimizer;\n    this.model.compile({\n      loss: 'categoricalCrossentropy',\n      optimizer: fineTuningOptimizer,\n      metrics: ['acc']\n    });\n\n    const fineTuningHistory = await this.model.fitDataset(trainDataset, {\n      epochs: config.fineTuningEpochs,\n      validationData: valDataset,\n      callbacks: config.callback == null ? null : [config.callback]\n    });\n    // Set the trainable attribute of the fine-tuning layer to its\n    // previous value.\n    this.secondLastBaseDenseLayer.trainable = originalTrainableValue;\n    return fineTuningHistory;\n  }\n\n  private async fineTuningUsingTensors(\n      config: TransferLearnConfig, trainXs: tf.Tensor, trainYs: tf.Tensor,\n      valData: [tf.Tensor, tf.Tensor]): Promise<tf.History> {\n    const originalTrainableValue = this.secondLastBaseDenseLayer.trainable;\n    this.secondLastBaseDenseLayer.trainable = true;\n\n    // Recompile model after unfreezing layer.\n    const fineTuningOptimizer: string|tf.Optimizer =\n        config.fineTuningOptimizer == null ? 'sgd' : config.fineTuningOptimizer;\n    this.model.compile({\n      loss: 'categoricalCrossentropy',\n      optimizer: fineTuningOptimizer,\n      metrics: ['acc']\n    });\n\n    const fineTuningHistory = await this.model.fit(trainXs, trainYs, {\n      epochs: config.fineTuningEpochs,\n      validationData: valData,\n      batchSize: config.batchSize,\n      callbacks: config.fineTuningCallback == null ? null :\n                                                     [config.fineTuningCallback]\n    });\n    // Set the trainable attribute of the fine-tuning layer to its\n    // previous value.\n    this.secondLastBaseDenseLayer.trainable = originalTrainableValue;\n    return fineTuningHistory;\n  }\n\n  /**\n   * Perform evaluation of the model using the examples that the model\n   * has loaded.\n   *\n   * @param config Configuration object for the evaluation.\n   * @returns A Promise of the result of evaluation.\n   */\n  async evaluate(config: EvaluateConfig): Promise<EvaluateResult> {\n    tf.util.assert(\n        config.wordProbThresholds != null &&\n            config.wordProbThresholds.length > 0,\n        () => `Received null or empty wordProbThresholds`);\n\n    // TODO(cais): Maybe relax this requirement.\n    const NOISE_CLASS_INDEX = 0;\n    tf.util.assert(\n        this.words[NOISE_CLASS_INDEX] === BACKGROUND_NOISE_TAG,\n        () => `Cannot perform evaluation when the first tag is not ` +\n            `${BACKGROUND_NOISE_TAG}`);\n\n    return tf.tidy(() => {\n      const rocCurve: ROCCurve = [];\n      let auc = 0;\n      const {xs, ys} = this.collectTransferDataAsTensors(config.windowHopRatio);\n      const indices = ys.argMax(-1).dataSync();\n      const probs = this.model.predict(xs) as tf.Tensor;\n\n      // To calcaulte ROC, we collapse all word probabilites into a single\n      // positive class, while _background_noise_ is treated as the\n      // negative class.\n      const maxWordProbs =\n          probs.slice([0, 1], [probs.shape[0], probs.shape[1] - 1]).max(-1);\n      const total = probs.shape[0];\n\n      // Calculate ROC curve.\n      for (let i = 0; i < config.wordProbThresholds.length; ++i) {\n        const probThreshold = config.wordProbThresholds[i];\n        const isWord =\n            maxWordProbs.greater(tf.scalar(probThreshold)).dataSync();\n\n        let negatives = 0;\n        let positives = 0;\n        let falsePositives = 0;\n        let truePositives = 0;\n        for (let i = 0; i < total; ++i) {\n          if (indices[i] === NOISE_CLASS_INDEX) {\n            negatives++;\n            if (isWord[i]) {\n              falsePositives++;\n            }\n          } else {\n            positives++;\n            if (isWord[i]) {\n              truePositives++;\n            }\n          }\n        }\n\n        // TODO(cais): Calculate per-hour false-positive rate.\n        const fpr = falsePositives / negatives;\n        const tpr = truePositives / positives;\n\n        rocCurve.push({probThreshold, fpr, tpr});\n        console.log(\n            `ROC thresh=${probThreshold}: ` +\n            `fpr=${fpr.toFixed(4)}, tpr=${tpr.toFixed(4)}`);\n\n        if (i > 0) {\n          // Accumulate to AUC.\n          auc += Math.abs((rocCurve[i - 1].fpr - rocCurve[i].fpr)) *\n              (rocCurve[i - 1].tpr + rocCurve[i].tpr) / 2;\n        }\n      }\n      return {rocCurve, auc};\n    });\n  }\n\n  /**\n   * Create an instance of tf.LayersModel for transfer learning.\n   *\n   * The top dense layer of the base model is replaced with a new softmax\n   * dense layer.\n   */\n  private createTransferModelFromBaseModel(): void {\n    tf.util.assert(\n        this.words != null,\n        () =>\n            `No word example is available for tranfer-learning model of name ` +\n            this.name);\n\n    // Find the second last dense layer.\n    const layers = this.baseModel.layers;\n    let layerIndex = layers.length - 2;\n    while (layerIndex >= 0) {\n      if (layers[layerIndex].getClassName().toLowerCase() === 'dense') {\n        break;\n      }\n      layerIndex--;\n    }\n    if (layerIndex < 0) {\n      throw new Error('Cannot find a hidden dense layer in the base model.');\n    }\n    this.secondLastBaseDenseLayer = layers[layerIndex];\n    const truncatedBaseOutput =\n        this.secondLastBaseDenseLayer.output as tf.SymbolicTensor;\n\n    this.transferHead = tf.sequential();\n    this.transferHead.add(tf.layers.dense({\n      units: this.words.length,\n      activation: 'softmax',\n      inputShape: truncatedBaseOutput.shape.slice(1),\n      name: 'NewHeadDense'\n    }));\n    const transferOutput =\n        this.transferHead.apply(truncatedBaseOutput) as tf.SymbolicTensor;\n    this.model =\n        tf.model({inputs: this.baseModel.inputs, outputs: transferOutput});\n  }\n\n  /**\n   * Get the input shape of the underlying tf.LayersModel.\n   *\n   * @returns The input shape.\n   */\n  modelInputShape(): tf.Shape {\n    return this.baseModel.inputs[0].shape;\n  }\n\n  getMetadata(): SpeechCommandRecognizerMetadata {\n    return {\n      tfjsSpeechCommandsVersion: version,\n      modelName: this.name,\n      timeStamp: new Date().toISOString(),\n      wordLabels: this.wordLabels()\n    };\n  }\n\n  async save(handlerOrURL?: string|tf.io.IOHandler): Promise<tf.io.SaveResult> {\n    const isCustomPath = handlerOrURL != null;\n    handlerOrURL = handlerOrURL || getCanonicalSavePath(this.name);\n\n    if (!isCustomPath) {\n      // First, save the words and other metadata.\n      const metadataMapStr =\n          localStorageWrapper.localStorage.getItem(SAVED_MODEL_METADATA_KEY);\n      const metadataMap =\n          metadataMapStr == null ? {} : JSON.parse(metadataMapStr);\n      metadataMap[this.name] = this.getMetadata();\n      localStorageWrapper.localStorage.setItem(\n          SAVED_MODEL_METADATA_KEY, JSON.stringify(metadataMap));\n    }\n    console.log(`Saving model to ${handlerOrURL}`);\n    return this.model.save(handlerOrURL);\n  }\n\n  async load(handlerOrURL?: string|tf.io.IOHandler): Promise<void> {\n    const isCustomPath = handlerOrURL != null;\n    handlerOrURL = handlerOrURL || getCanonicalSavePath(this.name);\n\n    if (!isCustomPath) {\n      // First, load the words and other metadata.\n      const metadataMap = JSON.parse(\n          localStorageWrapper.localStorage.getItem(SAVED_MODEL_METADATA_KEY));\n      if (metadataMap == null || metadataMap[this.name] == null) {\n        throw new Error(\n            `Cannot find metadata for transfer model named ${this.name}\"`);\n      }\n      this.words = metadataMap[this.name].wordLabels;\n      console.log(\n          `Loaded word list for model named ${this.name}: ${this.words}`);\n    }\n    this.model = await tf.loadLayersModel(handlerOrURL);\n    console.log(`Loaded model from ${handlerOrURL}:`);\n    this.model.summary();\n  }\n\n  /**\n   * Overridden method to prevent creating a nested transfer-learning\n   * recognizer.\n   *\n   * @param name\n   */\n  createTransfer(name: string): TransferBrowserFftSpeechCommandRecognizer {\n    throw new Error(\n        'Creating transfer-learned recognizer from a transfer-learned ' +\n        'recognizer is not supported.');\n  }\n}\n\nfunction getCanonicalSavePath(name: string): string {\n  return `${SAVE_PATH_PREFIX}${name}`;\n}\n\n/**\n * List the model that are currently saved locally in the browser.\n *\n * @returns An array of transfer-learned speech-commands models\n *   that are currently saved in the browser locally.\n */\nexport async function listSavedTransferModels(): Promise<string[]> {\n  const models = await tf.io.listModels();\n  const keys = [];\n  for (const key in models) {\n    if (key.startsWith(SAVE_PATH_PREFIX)) {\n      keys.push(key.slice(SAVE_PATH_PREFIX.length));\n    }\n  }\n  return keys;\n}\n\n/**\n * Delete a locally-saved, transfer-learned speech-commands model.\n *\n * @param name The name of the transfer-learned model to be deleted.\n */\nexport async function deleteSavedTransferModel(name: string): Promise<void> {\n  // Delete the words from local storage.\n  let metadataMap = JSON.parse(\n      localStorageWrapper.localStorage.getItem(SAVED_MODEL_METADATA_KEY));\n  if (metadataMap == null) {\n    metadataMap = {};\n  }\n  if (metadataMap[name] != null) {\n    delete metadataMap[name];\n  }\n  localStorageWrapper.localStorage.setItem(\n      SAVED_MODEL_METADATA_KEY, JSON.stringify(metadataMap));\n  await tf.io.removeModel(getCanonicalSavePath(name));\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs';\n\nimport {BrowserFftSpeechCommandRecognizer} from './browser_fft_recognizer';\nimport {playRawAudio} from './browser_fft_utils';\nimport {concatenateFloat32Arrays} from './generic_utils';\nimport {FFT_TYPE, SpeechCommandRecognizer, SpeechCommandRecognizerMetadata} from './types';\n\n/**\n * Create an instance of speech-command recognizer.\n *\n * @param fftType Type of FFT. The currently availble option(s):\n *   - BROWSER_FFT: Obtains audio spectrograms using browser's native Fourier\n *     transform.\n * @param vocabulary The vocabulary of the model to load. Possible options:\n *   - '18w' (default): The 18-word vocaulbary, consisting of:\n *     'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven',\n *     'eight', 'nine', 'up', 'down', 'left', 'right', 'go', 'stop',\n *     'yes', and 'no', in addition to '_background_noise_' and '_unknown_'.\n *   - 'directional4w': The four directional words: 'up', 'down', 'left', and\n *     'right', in addition to '_background_noise_' and '_unknown_'.\n *   Choosing a smaller vocabulary leads to better accuracy on the words of\n *   interest and a slightly smaller model size.\n * @param customModelArtifactsOrURL A custom model URL pointing to a model.json\n *     file, or a set of modelArtifacts in `tf.io.ModelArtifacts` format.\n *   Supported schemes: http://, https://, and node.js-only: file://.\n *   Mutually exclusive with `vocabulary`. If provided, `customMetadatURL`\n *   most also be provided.\n * @param customMetadataOrURL A custom metadata URL pointing to a metadata.json\n *   file. Must be provided together with `customModelURL`, or a metadata\n *   object.\n * @returns An instance of SpeechCommandRecognizer.\n * @throws Error on invalid value of `fftType`.\n */\nexport function create(\n    fftType: FFT_TYPE, vocabulary?: string,\n    customModelArtifactsOrURL?: tf.io.ModelArtifacts|string,\n    customMetadataOrURL?: SpeechCommandRecognizerMetadata|\n    string): SpeechCommandRecognizer {\n  tf.util.assert(\n      customModelArtifactsOrURL == null && customMetadataOrURL == null ||\n          customModelArtifactsOrURL != null && customMetadataOrURL != null,\n      () => `customModelURL and customMetadataURL must be both provided or ` +\n          `both not provided.`);\n  if (customModelArtifactsOrURL != null) {\n    tf.util.assert(\n        vocabulary == null,\n        () => `vocabulary name must be null or undefined when modelURL ` +\n            `is provided.`);\n  }\n\n  if (fftType === 'BROWSER_FFT') {\n    return new BrowserFftSpeechCommandRecognizer(\n        vocabulary, customModelArtifactsOrURL, customMetadataOrURL);\n  } else if (fftType === 'SOFT_FFT') {\n    throw new Error(\n        'SOFT_FFT SpeechCommandRecognizer has not been implemented yet.');\n  } else {\n    throw new Error(`Invalid fftType: '${fftType}'`);\n  }\n}\n\nconst utils = {\n  concatenateFloat32Arrays,\n  playRawAudio\n};\n\nexport {BACKGROUND_NOISE_TAG, Dataset, GetDataConfig as GetSpectrogramsAsTensorsConfig, getMaxIntensityFrameIndex, spectrogram2IntensityCurve, SpectrogramAndTargetsTfDataset} from './dataset';\nexport {AudioDataAugmentationOptions, Example, FFT_TYPE, RawAudioData, RecognizerParams, SpectrogramData, SpeechCommandRecognizer, SpeechCommandRecognizerMetadata, SpeechCommandRecognizerResult, StreamingRecognitionConfig, TransferLearnConfig, TransferSpeechCommandRecognizer} from './types';\nexport {deleteSavedTransferModel, listSavedTransferModels, UNKNOWN_TAG} from './browser_fft_recognizer';\nexport {utils};\nexport {version} from './version';\n"],"names":["loadMetadataJson","url","HTTP_SCHEME","HTTPS_SCHEME","FILE_SCHEME","indexOf","fetch","_c","json","fs","require","readFile","promisify","_b","_a","JSON","parse","slice","length","encoding","Error","EPSILON","normalize","x","tf.backend","epsilon","tf.tidy","mean","variance","sub","div","sqrt","add","normalizeFloat32Array","meanVal","arraySync","stdVal","Math","yArray","Array","from","map","y","Float32Array","getAudioContextConstructor","window","AudioContext","webkitAudioContext","getAudioMediaStream","audioTrackConstraints","navigator","mediaDevices","getUserMedia","audio","video","playRawAudio","rawAudio","onEnded","audioContext","arrayBuffer","createBuffer","data","sampleRateHz","getChannelData","set","source","createBufferSource","buffer","connect","destination","start","onended","config","spectrogramCallback","numFramesPerSpectrogram","suppressionTimeMillis","this","numFrames","fftSize","frameDurationMillis","columnTruncateLength","overlapFactor","includeRawAudio","tf.util","assert","_this","audioContextConstructor","BrowserFftFeatureExtractor","frameIntervalTask","stream","sampleRate","console","warn","streamSource","createMediaStreamSource","analyser","createAnalyser","smoothingTimeConstant","freqDataQueue","freqData","timeDataQueue","timeData","period","max","round","tracker","Tracker","setInterval","onAudioFrame","bind","getFloatFrequencyData","Infinity","push","getFloatTimeDomainData","shift","tick","flattenQueue","freqDataTensor","getInputTensorFromFrequencyData","timeDataTensor","suppress","tf.dispose","clearInterval","disconnect","close","getTracks","stop","params","queue","frameSize","forEach","i","shape","vals","sizeFromShape","tf.tensor","suppressionPeriod","suppressionTime","counter","suppressionOnset","concatenateArrayBuffers","buffers","totalByteLength","byteLength","temp","Uint8Array","offset","concatenateFloat32Arrays","xs","totalLength","concatenated","index","string2ArrayBuffer","str","strUTF8","unescape","encodeURIComponent","buf","charCodeAt","arrayBuffer2String","decodeURIComponent","escape","String","fromCharCode","getUID","s4","floor","random","toString","substring","getRandomInteger","min","balancedTrainValSplit","ys","valSplit","classIndices","argMax","dataSync","indicesByClasses","classIndex","numClasses","trainIndices","valIndices","shuffle","classIndices_1","cutoff","j","trainXs","tf.gather","trainYs","valXs","valYs","balancedTrainValSplitNumArrays","isXsFloat32Array","isArray","classIndices_2","trainIndices_1","tslib_1.__values","valIndices_1","trainIndices_2","valIndices_2","DATASET_SERIALIZATION_DESCRIPTOR","DATASET_SERIALIZATION_VERSION","BACKGROUND_NOISE_TAG","serialized","examples","label2Ids","artifacts","arrayBuffer2SerializedExamples","manifest","spec","byteLen","spectrogramNumFrames","spectrogramFrameSize","rawAudioNumSamples","addExample","deserializeExample","Dataset","example","label","stringify","uid","dataset","vocab","getVocabulary","vocab_1","word","getExamples","examples_1","counts","output","id","size","hopFrames","sortedUniqueNumFrames","getSortedUniqueNumFrames","Number","isInteger","toNormalize","uniqueFrameSize","xTensors","xArrays","labelIndices","currentLabel","ids","spectrogram","snippetLength","focusIndex","keyFrameIndex","getMaxIntensityFrameIndex","snippet","tf.tensor3d","windows","getValidWindows","window_1","windowedSnippet","getDataset","windows_1","ids_1","augmentByMixingNoiseRatio","augmentByMixingNoise","batchSize","datasetBatchSize","valSplit_1","datasetValidationSplit","zippedXandYArrays","xArray","item","yArrays","xTrain","tf.data","array","yTrain","tf.oneHot","squeeze","trainDataset","zip","batch","prefetch","xVal","yVal","valDataset","zipped_1","xTensor","targets","tf.tensor1d","asType","undefined","tf.stack","ratio","isTypedArray","noiseExampleIndices","wordExampleIndices","mixedXTensors","mixedLabelIndices","noiseIndex","signalTensor","noiseTensor","mixed","mul","wordExampleIndices_1","log","tensor","numFramesSet","Set","ids_2","uniqueNumFrames","sort","splice","Object","keys","durMillis","key","frameDurMillis","sortedVocab","wordLabels","empty","wordLabel","vocab_2","ids_3","artifact","serializeExample","serializedExamples2ArrayBuffer","hasRawAudio","spectrogramKeyFrameIndex","rawAudioSampleRateHz","ex","manifestBuffer","descriptorBuffer","version","Uint32Array","manifestLength","descriptor","manifestBeginByte","manifestString","windowLength","windowHop","begin","leftHalf","left","spectrogram2IntensityCurve","tf.tensor2d","UNKNOWN_TAG","SAVED_MODEL_METADATA_KEY","SAVE_PATH_PREFIX","localStorageWrapper","localStorage","getMajorAndMinorVersion","split","join","DEFAULT_WINDOW_HOP_RATIO","vocabulary","modelArtifactsOrURL","metadataOrURL","BrowserFftSpeechCommandRecognizer","DEFAULT_VOCABULARY_NAME","VALID_VOCABULARY_NAMES","MODEL_URL_PREFIX","parameters","SAMPLE_RATE_HZ","FFT_SIZE","callback","streaming","ensureModelLoaded","probabilityThreshold","includeEmbedding","invokeCallbackOnNoiseAndUnknown","normalizedX","ensureModelWithEmbeddingOutputCreated","embedding","model","predict","scores","maxIndexTensor","maxIndex","maxScore","includeSpectrogram","nonBatchInputShape","wordDetected","words","DEFAULT_SUPPRESSION_TIME_MILLIS","audioDataExtractor","ensureMetadataLoaded","tf.loadLayersModel","tf.io","fromMemory","modelTopology","weightSpecs","weightData","inputs","outputShape","freezeModel","elementsPerExample","dimSize","warmUpModel","spectrogramDurationMillis","modelWithEmbeddingOutput","layers","getClassName","secondLastDenseLayer","tf.model","outputs","tf.zeros","concat","metadataJSON","legacyWords","input","_f","recognizeOnline","spectrogramData","tf.Tensor","checkInputTensorShape","inputTensor","numExamples","tf.tensor4d","outAndEmbedding","outTensor","unstacked","tf.unstack","scorePromises","Promise","all","_e","_d","resolve","reject","dispose","name","transferRecognizers","transfer","TransferBrowserFftSpeechCommandRecognizer","trainable","expectedRank","nonBatchedShape","expectedNonBatchShape","arraysEqual","baseModel","_super","tslib_1.__extends","options","durationMultiplier","durationSec","frameDurationSec_1","ceil","snippetDurationSec","onSnippet","frameDurationSec","totalDurationSec","stepFactor","callbackCountTarget","callbackCount","lastIndex","spectrogramSnippets","_p","collateTransferWords","_g","_h","increment","snippetData","normalized","finalSpectrogram","_k","_j","_o","_m","_l","clear","getExampleCounts","setExampleKeyFrameIndex","removeExample","clearExisting","incomingDataset","clearExamples","incomingVocab","incomingVocab_1","serialize","windowHopRatio","augmentationOptions","out","getData","validationSplit","fineTuningEpochs","createTransferModelFromBaseModel","secondLastBaseDenseLayer","compile","loss","optimizer","metrics","datasetDurationMillisThreshold","fitDatasetDurationMillisThreshold","durationMillis","trainOnDataset","trainOnTensors","epochs","tslib_1.__read","collectTransferDataAsTfDataset","t0","now","fitDataset","validationData","callbacks","history","toFixed","t0_1","fineTuningUsingTfDatasets","fineTuningHistory","collectTransferDataAsTensors","splits","valData","fit","history_1","fineTuningUsingTensors","originalTrainableValue","fineTuningOptimizer","fineTuningCallback","wordProbThresholds","NOISE_CLASS_INDEX","rocCurve","auc","indices","probs","maxWordProbs","total","probThreshold","isWord","greater","tf.scalar","negatives","positives","falsePositives","truePositives","i_1","fpr","tpr","abs","layerIndex","toLowerCase","truncatedBaseOutput","transferHead","tf.sequential","tf.layers","dense","units","activation","inputShape","transferOutput","apply","tfjsSpeechCommandsVersion","modelName","timeStamp","Date","toISOString","handlerOrURL","isCustomPath","getCanonicalSavePath","metadataMapStr","getItem","metadataMap","getMetadata","setItem","save","summary","listSavedTransferModels","listModels","models","startsWith","deleteSavedTransferModel","removeModel","create","fftType","customModelArtifactsOrURL","customMetadataOrURL","utils"],"mappings":";;;;;;;;;;;;;;;;iqFAsBsBA,iBAAiBC,sIAE/BC,EAAc,UACdC,EAAe,WACfC,EAAc,UACa,IAA7BH,EAAII,QAAQH,IAAoD,IAA9BD,EAAII,QAAQF,YACzBG,MAAML,WACd,SADEM,SACaC,eAC9B,SADeD,wBAEuB,IAA7BN,EAAII,QAAQD,UAEfK,EAAKC,QAAQ,MACbC,EAAWC,UAAUH,EAAGE,UAEvBE,GAAAC,EAAAC,MAAKC,SACFL,EAASV,EAAIgB,MAAMb,EAAYc,SAAUC,SAAU,mBAD7D,SAAON,WACHN,mBAEJ,MAAM,IAAIa,MACN,2CAA2CnB,iFAMnD,IAAIoB,QAAkB,cAWNC,UAAUC,GAIxB,OAHe,MAAXF,UACFA,QAAUG,UAAaC,WAElBC,KAAQ,WACP,IAAAZ,aAACa,SAAMC,aAEb,OAAOL,EAAEM,IAAIF,GAAMG,IAAIF,EAASG,OAAOC,IAAIX,qBAY/BY,sBAAsBV,GACpC,GAAIA,EAAEL,OAAS,EACb,MAAM,IAAIE,MACN,+DAKN,OAHe,MAAXC,UACFA,QAAUG,UAAaC,WAElBC,KAAQ,WACP,IAAAZ,uBAACa,SAAMC,aACPM,EAAUP,EAAKQ,YACfC,EAASC,KAAKN,KAAKH,EAASO,aAC5BG,EAASC,MAAMC,KAAKjB,GAAGkB,IAAI,SAAAC,GAAK,OAACA,EAAIR,IAAYE,EAASf,WAChE,OAAO,IAAIsB,aAAaL,KAI5B,SAAgBM,6BAEd,OAAQC,OAAeC,cAAiBD,OAAeE,4BAGnCC,oBAClBC,sFACF,SAAOC,UAAUC,aAAaC,cAC5BC,MAAgC,MAAzBJ,GAAuCA,EAC9CK,OAAO,kBASKC,aACZC,EAAwBC,GAC1B,IAGMC,EAA6B,IAD9Bb,OAAeC,cAAiBD,OAAeE,oBAE9CY,EACFD,EAAaE,aAAa,EAAGJ,EAASK,KAAK3C,OAAQsC,EAASM,cAC3CH,EAAYI,eAAe,GACnCC,IAAIR,EAASK,MAC1B,IAAMI,EAASP,EAAaQ,qBAC5BD,EAAOE,OAASR,EAChBM,EAAOG,QAAQV,EAAaW,aAC5BJ,EAAOK,QACPL,EAAOM,QAAU,WACA,MAAXd,GACFA,KCxCN,0CAyCE,WAAYe,GAAZ,WACE,GAAc,MAAVA,EACF,MAAM,IAAIpD,MACN,uFAIN,GAAkC,MAA9BoD,EAAOC,oBACT,MAAM,IAAIrD,MAAM,mDAGlB,KAAMoD,EAAOE,wBAA0B,GACrC,MAAM,IAAItD,MACN,6CACGoD,EAAOE,yBAGhB,GAAIF,EAAOG,sBAAwB,EACjC,MAAM,IAAIvD,MACN,sDACWoD,EAAOG,uBAkBxB,GAhBAC,KAAKD,sBAAwBH,EAAOG,sBAEpCC,KAAKH,oBAAsBD,EAAOC,oBAClCG,KAAKC,UAAYL,EAAOE,wBACxBE,KAAKd,aAAeU,EAAOV,cAAgB,MAC3Cc,KAAKE,QAAUN,EAAOM,SAAW,KACjCF,KAAKG,oBAAsBH,KAAKE,QAAUF,KAAKd,aAAe,IAC9Dc,KAAKI,qBAAuBR,EAAOQ,sBAAwBJ,KAAKE,QAChEF,KAAKK,cAAgBT,EAAOS,cAC5BL,KAAKM,gBAAkBV,EAAOU,gBAE9BC,KAAQC,OACJR,KAAKK,eAAiB,GAAKL,KAAKK,cAAgB,EAChD,WAAM,MAAA,sDACSI,EAAKJ,gBAEpBL,KAAKI,qBAAuBJ,KAAKE,QACnC,MAAM,IAAI1D,MACN,wBAAwBwD,KAAKI,0CACjBJ,KAAKE,cAGvBF,KAAKU,wBAA0B1C,6BAoGnC,OAjGQ2C,kBAAN,SAAYtC,uHAEV,GAA8B,MAA1B2B,KAAKY,kBACP,MAAM,IAAIpE,MACN,2DAGQ,OAAdN,EAAA8D,QAAoB5B,oBAAoBC,kBAAxCnC,EAAK2E,OAAS5E,SAEd+D,KAAKlB,aAAe,IAAIkB,KAAKU,wBACzBV,KAAKlB,aAAagC,aAAed,KAAKd,cACxC6B,QAAQC,KACJ,wCACahB,KAAKd,0BACPc,KAAKlB,aAAagC,YAE7BG,EAAejB,KAAKlB,aAAaoC,wBAAwBlB,KAAKa,QACpEb,KAAKmB,SAAWnB,KAAKlB,aAAasC,iBAClCpB,KAAKmB,SAASjB,QAAyB,EAAfF,KAAKE,QAC7BF,KAAKmB,SAASE,sBAAwB,EACtCJ,EAAazB,QAAQQ,KAAKmB,UAE1BnB,KAAKsB,iBACLtB,KAAKuB,SAAW,IAAIxD,aAAaiC,KAAKE,SAClCF,KAAKM,kBACPN,KAAKwB,iBACLxB,KAAKyB,SAAW,IAAI1D,aAAaiC,KAAKE,UAElCwB,EACFjE,KAAKkE,IAAI,EAAGlE,KAAKmE,MAAM5B,KAAKC,WAAa,EAAID,KAAKK,iBACtDL,KAAK6B,QAAU,IAAIC,QACfJ,EACAjE,KAAKmE,MAAM5B,KAAKD,sBAAwBC,KAAKG,sBACjDH,KAAKY,kBAAoBmB,YACrB/B,KAAKgC,aAAaC,KAAKjC,MAAOA,KAAKE,QAAUF,KAAKd,aAAe,eAGzDyB,yBAAd,iIAEE,OADAX,KAAKmB,SAASe,sBAAsBlC,KAAKuB,UACrCvB,KAAKuB,SAAS,MAAQY,EAAAA,OAI1BnC,KAAKsB,cAAcc,KAAKpC,KAAKuB,SAASlF,MAAM,EAAG2D,KAAKI,uBAChDJ,KAAKM,kBACPN,KAAKmB,SAASkB,uBAAuBrC,KAAKyB,UAC1CzB,KAAKwB,cAAcY,KAAKpC,KAAKyB,SAASpF,UAEpC2D,KAAKsB,cAAchF,OAAS0D,KAAKC,WAEnCD,KAAKsB,cAAcgB,QAEFtC,KAAK6B,QAAQU,QAExBhB,EAAWiB,aAAaxC,KAAKsB,eAC7BmB,EAAiBC,gCACnBnB,GAAW,EAAGvB,KAAKC,UAAWD,KAAKI,qBAAsB,IACzDuC,SACA3C,KAAKM,kBACDmB,EAAWe,aAAaxC,KAAKwB,eACnCmB,EAAiBD,gCACbjB,GAAW,EAAGzB,KAAKC,UAAYD,KAAKE,cAGhCF,KAAKH,oBAAoB4C,EAAgBE,mBAA/CzG,UAEF8D,KAAK6B,QAAQe,WAEfC,SAAYJ,EAAgBE,qCAI1BhC,iBAAN,8FACE,GAA8B,MAA1BX,KAAKY,kBACP,MAAM,IAAIpE,MACN,sEAENsG,cAAc9C,KAAKY,mBACnBZ,KAAKY,kBAAoB,KACzBZ,KAAKmB,SAAS4B,aACd/C,KAAKlB,aAAakE,QACC,MAAfhD,KAAKa,QAAkBb,KAAKa,OAAOoC,YAAY3G,OAAS,GAC1D0D,KAAKa,OAAOoC,YAAY,GAAGC,gBAI/BvC,sBAAA,SAAUwC,GACR,MAAM,IAAI3G,MACN,mEAGNmE,wBAAA,WACE,MAAM,IAAInE,MACN,wJAMQgG,aAAaY,GAC3B,IAAMC,EAAYD,EAAM,GAAG9G,OACrBiF,EAAW,IAAIxD,aAAaqF,EAAM9G,OAAS+G,GAEjD,OADAD,EAAME,QAAQ,SAACrE,EAAMsE,GAAM,OAAAhC,EAASnC,IAAIH,EAAMsE,EAAIF,KAC3C9B,WAGOmB,gCACZnB,EAAwBiC,GAC1B,IAAMC,EAAO,IAAI1F,aAAawC,KAAQmD,cAAcF,IAGpD,OADAC,EAAKrE,IAAImC,EAAUkC,EAAKnH,OAASiF,EAASjF,QACnCqH,OAAUF,EAAMD,GAOzB,uBAaE,WAAY9B,EAAgBkC,GAA5B,WACE5D,KAAK0B,OAASA,EACd1B,KAAK6D,gBAAuC,MAArBD,EAA4B,EAAIA,EACvD5D,KAAK8D,QAAU,EAEfvD,KAAQC,OACJR,KAAK0B,OAAS,EACd,WAAM,MAAA,2CAA2CjB,EAAKiB,SAsB9D,OAdEI,iBAAA,WAKE,OAJA9B,KAAK8D,UACe9D,KAAK8D,QAAU9D,KAAK0B,QAAW,IACrB,MAAzB1B,KAAK+D,kBACL/D,KAAK8D,QAAU9D,KAAK+D,iBAAmB/D,KAAK6D,kBAOnD/B,qBAAA,WACE9B,KAAK+D,iBAAmB/D,KAAK8D,uBCtTjBE,wBAAwBC,GACtC,IAAIC,EAAkB,EACtBD,EAAQX,QAAQ,SAAC/D,GACf2E,GAAmB3E,EAAO4E,aAG5B,IAAMC,EAAO,IAAIC,WAAWH,GACxBI,EAAS,EAKb,OAJAL,EAAQX,QAAQ,SAAC/D,GACf6E,EAAKhF,IAAI,IAAIiF,WAAW9E,GAAS+E,GACjCA,GAAU/E,EAAO4E,aAEZC,EAAK7E,gBASEgF,yBAAyBC,GACvC,IAAIC,EAAc,EAClBD,EAAGlB,QAAQ,SAAA3G,GAAK,OAAA8H,GAAe9H,EAAEL,SACjC,IAAMoI,EAAe,IAAI3G,aAAa0G,GAClCE,EAAQ,EAKZ,OAJAH,EAAGlB,QAAQ,SAAA3G,GACT+H,EAAatF,IAAIzC,EAAGgI,GACpBA,GAAShI,EAAEL,SAENoI,WAIOE,mBAAmBC,GACjC,GAAW,MAAPA,EACF,MAAM,IAAIrI,MAAM,oCAMlB,IAFA,IAAMsI,EAAUC,SAASC,mBAAmBH,IACtCI,EAAM,IAAIZ,WAAWS,EAAQxI,QAC1BiH,EAAI,EAAGA,EAAIuB,EAAQxI,SAAUiH,EACpC0B,EAAI1B,GAAKuB,EAAQI,WAAW3B,GAE9B,OAAO0B,EAAI1F,gBAIG4F,mBAAmB5F,GACjC,GAAc,MAAVA,EACF,MAAM,IAAI/C,MAAM,oCAElB,IAAMyI,EAAM,IAAIZ,WAAW9E,GAC3B,OAAO6F,mBAAmBC,OAAOC,OAAOC,mBAAPD,gBAAuBL,MAI1D,SAAgBO,SACd,SAASC,IACP,OAAOhI,KAAKiI,MAA4B,OAArB,EAAIjI,KAAKkI,WAAqBC,SAAS,IAAIC,UAAU,GAE1E,OAAOJ,IAAOA,IAAO,IAAMA,IAAO,IAAMA,IAAO,IAAMA,IAAO,IAAMA,IAC9DA,IAAOA,aAGGK,iBAAiBC,EAAapE,GAC5C,OAAOlE,KAAKiI,OAAO/D,EAAMoE,GAAOtI,KAAKkI,UAAYI,WCnDnCC,sBACZxB,EAAeyB,EAAeC,GAWhC,OALA3F,KAAQC,OACJ0F,EAAW,GAAKA,EAAW,EAC3B,WAAM,MAAA,wDACSA,IAEZpJ,KAAQ,WAIb,IAHA,IAAMqJ,EAAeF,EAAGG,QAAQ,GAAGC,WAE7BC,KACG/C,EAAI,EAAGA,EAAI4C,EAAa7J,SAAUiH,EAAG,CAC5C,IAAMgD,EAAaJ,EAAa5C,GACI,MAAhC+C,EAAiBC,KACnBD,EAAiBC,OAEnBD,EAAiBC,GAAYnE,KAAKmB,GAEpC,IAAMiD,EAAaF,EAAiBhK,OAE9BmK,KACAC,KAGNJ,EAAiBzI,IAAI,SAAAsI,GAAgB,OAAA5F,KAAQoG,QAAQR,KACrD,IAAS5C,EAAI,EAAGA,EAAIiD,IAAcjD,EAGhC,IAFA,IAAMqD,EAAeN,EAAiB/C,GAChCsD,EAASpJ,KAAKmE,MAAMgF,EAAatK,QAAU,EAAI4J,IAC5CY,EAAI,EAAGA,EAAIF,EAAatK,SAAUwK,EACrCA,EAAID,EACNJ,EAAarE,KAAKwE,EAAaE,IAE/BJ,EAAWtE,KAAKwE,EAAaE,IASnC,OAAQC,QAJQC,OAAUxC,EAAIiC,GAIbQ,QAHDD,OAAUf,EAAIQ,GAGJS,MAFZF,OAAUxC,EAAIkC,GAEKS,MADnBH,OAAUf,EAAIS,MAQhC,SAAgBU,+BACZ5C,EAA+ByB,EAAcC,uBAM/C3F,KAAQC,OACJ0F,EAAW,GAAKA,EAAW,EAC3B,WAAM,MAAA,wDACSA,IAMnB,IALA,IAAMmB,GAAoB1J,MAAM2J,QAAQ9C,EAAG,IAErC2B,EAAeF,EAEfK,KACG/C,EAAI,EAAGA,EAAI4C,EAAa7J,SAAUiH,EAAG,CAC5C,IAAMgD,EAAaJ,EAAa5C,GACI,MAAhC+C,EAAiBC,KACnBD,EAAiBC,OAEnBD,EAAiBC,GAAYnE,KAAKmB,GAEpC,IAAMiD,EAAaF,EAAiBhK,OAE9BmK,KACAC,KAGNJ,EAAiBzI,IAAI,SAAAsI,GAAgB,OAAA5F,KAAQoG,QAAQR,KACrD,IAAS5C,EAAI,EAAGA,EAAIiD,IAAcjD,EAGhC,IAFA,IAAMgE,EAAejB,EAAiB/C,GAChCsD,EAASpJ,KAAKmE,MAAM2F,EAAajL,QAAU,EAAI4J,IAC5CY,EAAI,EAAGA,EAAIS,EAAajL,SAAUwK,EACrCA,EAAID,EACNJ,EAAarE,KAAKmF,EAAaT,IAE/BJ,EAAWtE,KAAKmF,EAAaT,IAKnC,GAAIO,EAAkB,CACpB,IAAMN,KACAE,KACAC,KACAC,SACN,IAAoB,IAAAK,EAAAC,SAAAhB,iCAAc,CAA7B,IAAM9B,UACToC,EAAQ3E,KAAKoC,EAAGG,IAChBsC,EAAQ7E,KAAK6D,EAAGtB,0GAElB,IAAoB,IAAA+C,EAAAD,SAAAf,iCAAY,CAArB/B,UACTuC,EAAM9E,KAAKoC,EAAGG,IACdwC,EAAM/E,KAAK6D,EAAGtB,sGAEhB,OAAQoC,UAASE,UAASC,QAAOC,SAE3BJ,KACAE,KACAC,KACAC,SACN,IAAoB,IAAAQ,EAAAF,SAAAhB,iCAAc,CAAvB9B,UACToC,EAAQ3E,KAAKoC,EAAGG,IAChBsC,EAAQ7E,KAAK6D,EAAGtB,0GAElB,IAAoB,IAAAiD,EAAAH,SAAAf,iCAAY,CAArB/B,UACTuC,EAAM9E,KAAKoC,EAAGG,IACdwC,EAAM/E,KAAK6D,EAAGtB,sGAEhB,OAAQoC,UAASE,UAASC,QAAOC,SCvI9B,IAAMU,iCAAmC,WAOnCC,8BAAgC,EAyDhCC,qBAAuB,wCAuGlC,WAAYC,GAGV,GAFAhI,KAAKiI,YACLjI,KAAKkI,aACa,MAAdF,EAIF,IAFA,IAAMG,EAAYC,+BAA+BJ,GAC7C1D,EAAS,EACJf,EAAI,EAAGA,EAAI4E,EAAUE,SAAS/L,SAAUiH,EAAG,CAClD,IAAM+E,EAAOH,EAAUE,SAAS9E,GAC5BgF,EAAUD,EAAKE,qBAAuBF,EAAKG,qBAChB,MAA3BH,EAAKI,qBACPH,GAAWD,EAAKI,oBAElBH,GAAW,EACXvI,KAAK2I,WAAWC,oBACXN,OAAMrJ,KAAMkJ,EAAUlJ,KAAK5C,MAAMiI,EAAQA,EAASiE,MACvDjE,GAAUiE,GA0hBlB,OA9gBEM,uBAAA,SAAWC,GACTvI,KAAQC,OAAkB,MAAXsI,EAAiB,WAAM,MAAA,kCACtCvI,KAAQC,OACa,MAAjBsI,EAAQC,OAAiBD,EAAQC,MAAMzM,OAAS,EAChD,WAAM,MAAA,oDACSH,KAAK6M,UAAUF,EAAQC,SAC1C,IAAME,EAAMzD,SAMZ,OALAxF,KAAKiI,SAASgB,GAAOH,EACfA,EAAQC,SAAS/I,KAAKkI,YAC1BlI,KAAKkI,UAAUY,EAAQC,WAEzB/I,KAAKkI,UAAUY,EAAQC,OAAO3G,KAAK6G,GAC5BA,GAQTJ,kBAAA,SAAMK,eACJ3I,KAAQC,OACJ0I,IAAYlJ,KAAM,WAAM,MAAA,uCAC5B,IAAMmJ,EAAQD,EAAQE,oBACtB,IAAmB,IAAAC,EAAA5B,SAAA0B,iCAAO,CAArB,IAAMG,UACHrB,EAAWiB,EAAQK,YAAYD,OACrC,IAAsB,IAAAE,YAAA/B,SAAAQ,kCAAU,CAA3B,IAAMa,UACT9I,KAAK2I,WAAWG,EAAQA,gNAU9BD,6BAAA,WACE,IAAMY,KACN,IAAK,IAAMR,KAAOjJ,KAAKiI,SAAU,CAC/B,IAAMa,EAAU9I,KAAKiI,SAASgB,GACxBH,EAAQC,SAASU,IACrBA,EAAOX,EAAQC,OAAS,GAE1BU,EAAOX,EAAQC,SAEjB,OAAOU,GAYTZ,wBAAA,SAAYE,GAAZ,WACExI,KAAQC,OACK,MAATuI,EACA,WACI,MAAA,0CAA0C5M,KAAK6M,UAAUD,KACjExI,KAAQC,OACJuI,KAAS/I,KAAKkI,UACd,WAAM,MAAA,wBAAwBa,0BAClC,IAAMW,KAIN,OAHA1J,KAAKkI,UAAUa,GAAOzF,QAAQ,SAAAqG,GAC5BD,EAAOtH,MAAM6G,IAAKU,EAAIb,QAASrI,EAAKwH,SAAS0B,OAExCD,GA8BTb,oBAAA,SAAQE,EAAgBnJ,GAAxB,WAIEW,KAAQC,OACJR,KAAK4J,OAAS,EACd,WACI,MAAA,oEACR,IAAMT,EAAQnJ,KAAKoJ,gBACN,MAATL,EACFxI,KAAQC,QACsB,IAA1B2I,EAAM1N,QAAQsN,GACd,WAAM,MAAA,SAASA,gCACP5M,KAAK6M,UAAUG,SAI3B5I,KAAQC,OACJ2I,EAAM7M,OAAS,EACf,WAAM,MAAA,kGACqC6M,EAAM7M,kBAGzC,MAAVsD,IACFA,MAKF,IACIK,EACA4J,EAFEC,EAAwB9J,KAAK+J,2BAGE,IAAjCD,EAAsBxN,QACxB2D,EAAgC,MAApBL,EAAOK,UAAoB6J,EAAsB,GACtBlK,EAAOK,UAC9C4J,EAAgC,MAApBjK,EAAOiK,UAAoB,EAAIjK,EAAOiK,YAElD5J,EAAYL,EAAOK,UACnBM,KAAQC,OACS,MAAbP,GAAqB+J,OAAOC,UAAUhK,IAAcA,EAAY,EAChE,WAAM,MAAA,aACI6J,EAAsBxN,oCACrBmE,EAAKmJ,2FAEpBrJ,KAAQC,OACJP,GAAa6J,EAAsB,GACnC,WAAM,MAAA,cAAc7J,sCACZ6J,EAAsB,4CAGlCD,EAAYjK,EAAOiK,UACnBtJ,KAAQC,OACS,MAAbqJ,GAAqBG,OAAOC,UAAUJ,IAAcA,EAAY,EAChE,WAAM,MAAA,aACIC,EAAsBxN,oCACrBmE,EAAKmJ,4FAKtB,IAAMM,EAAkC,MAApBtK,EAAOlD,WAA2BkD,EAAOlD,UAE7D,OAAOI,KAAQ,WAMb,YADIqN,EAJAC,KACAC,KAEAC,KAEK/G,EAAI,EAAGA,EAAI4F,EAAM7M,SAAUiH,EAAG,CACrC,IAAMgH,EAAepB,EAAM5F,GAC3B,GAAa,MAATwF,GAAiBwB,IAAiBxB,EAAtC,CAGA,IAAMyB,EAAM/J,EAAKyH,UAAUqC,cAChBZ,WAEHc,EADUhK,EAAKwH,SAAS0B,GACFc,YACtBpH,EAAYoH,EAAYpH,UACP,MAAnB8G,EACFA,EAAkB9G,EAElB9C,KAAQC,OACJ6C,IAAc8G,EACd,WAAM,MAAA,2BACE9G,SAAgB8G,QAG9B,IAAMO,EAAgBD,EAAYxL,KAAK3C,OAAS+G,EAC5CsH,EAAa,KACbJ,IAAiBxC,uBACnB4C,EAA0C,MAA7BF,EAAYG,cACrBC,0BAA0BJ,GAAapE,WAAW,GAClDoE,EAAYG,eAIlB,IAAME,EACFC,SAAYN,EAAYxL,MAAOyL,EAAerH,EAAW,IACvD2H,EACFC,gBAAgBP,EAAeC,EAAY1K,EAAW4J,cAC/CqB,GACT,IAAMC,EAAkBrO,KAAQ,WAC9B,IAAM4M,EAASoB,EAAQzO,OAClB6O,EAAO,GAAI,EAAG,IAAKA,EAAO,GAAKA,EAAO,IAAK,GAAI,IACpD,OAAOhB,EAAcxN,UAAUgN,GAAUA,IAEvC9J,EAAOwL,WAGTf,EAAQjI,KAAK+I,EAAgB9E,YAE7B+D,EAAShI,KAAK+I,GAEH,MAATpC,GACFuB,EAAalI,KAAKmB,QAdtB,IAAqB,IAAA8H,YAAA5D,SAAAuD,gJAiBrBnI,QAAWiI,QA3Cb,IAAiB,IAAAQ,YAAA7D,SAAA+C,kJA+CqB,MAApC5K,EAAO2L,2BACT9K,EAAK+K,qBACD5L,EAAOwL,WAAaf,EACAD,EACpBE,EAAc1K,EAAO2L,2BAG3B,IAAM5E,EAA4B,MAAlB/G,EAAO+G,SAAyB/G,EAAO+G,QACvD,GAAI/G,EAAOwL,WAAY,CACrB,IAAMK,EACyB,MAA3B7L,EAAO8L,iBAA2B,GAAK9L,EAAO8L,iBAG5CC,EAA4C,MAAjC/L,EAAOgM,uBACpB,IACAhM,EAAOgM,uBACXrL,KAAQC,OACJmL,EAAW,GAAKA,EAAW,EAC3B,WAAM,MAAA,qCAAqCA,IAE/C,IAAME,EACFxB,EAAQxM,IAAI,SAACiO,EAAQvI,GAAM,OAACuI,EAAQxB,EAAa/G,MACrDhD,KAAQoG,QACJkF,GACJxB,EAAUwB,EAAkBhO,IAAI,SAAAkO,GAAQ,OAAAA,EAAK,KAC7C,IAAMC,EAAUH,EAAkBhO,IAAI,SAAAkO,GAAQ,OAAAA,EAAK,KAC7C9P,wCAAC8K,YAASE,YAASC,UAAOC,UAO1B8E,EACFC,KAAQC,MAAMpF,GAAgBlJ,IAAI,SAAAlB,GAAK,OAAAoO,SAAYpO,GACjDsD,EAAWkK,EAAiB,MAE5BiC,EAASF,KAAQC,MAAMlF,GAASpJ,IAClC,SAAAC,GAAK,OAAAuO,QAAWvO,GAAIqL,EAAM7M,QAAQgQ,SAAS,MAE3CC,EAAeL,KAAQM,KAAKhI,GAAIyH,EAAQhG,GAAImG,IAC5CzF,IAEF4F,EAAeA,EAAa5F,QAAQ0D,EAAQ/N,SAE9CiQ,EAAeA,EAAaE,MAAMhB,GAAWiB,SAAS,GAEtD,IAAMC,EACFT,KAAQC,MAAMjF,GAAcrJ,IAAI,SAAAlB,GAAK,OAAAoO,SAAYpO,GAC/CsD,EAAWkK,EAAiB,MAE5ByC,EAAOV,KAAQC,MAAMhF,GAAOtJ,IAC9B,SAAAC,GAAK,OAAAuO,QAAWvO,GAAIqL,EAAM7M,QAAQgQ,SAAS,MAC3CO,EAAaX,KAAQM,KAAKhI,GAAImI,EAAM1G,GAAI2G,IAK5C,OAAQL,EAJRM,EAAaA,EAAWJ,MAAMhB,GAAWiB,SAAS,IAMlD,GAAI/F,EAAS,CAEX,IAAMmG,KACN1C,EAAS9G,QAAQ,SAACyJ,EAASxJ,GACzBuJ,EAAO1K,MAAMzF,EAAGoQ,EAASjP,EAAGwM,EAAa/G,OAE3ChD,KAAQoG,QAAQmG,GAChB1C,EAAW0C,EAAOjP,IAAI,SAAAkO,GAAQ,OAAAA,EAAKpP,IACnC2N,EAAewC,EAAOjP,IAAI,SAAAkO,GAAQ,OAAAA,EAAKjO,IAGzC,IAAMkP,EAAmB,MAATjE,EACZsD,OAAUY,SAAY3C,EAAc,SAAUnB,EAAM7M,QAC/C4Q,OAAO,gBACZC,EACJ,OACE3I,GAAI4I,MAAShD,GACbnE,GAAI+G,MAMJnE,iCAAR,SACIrE,EAAS8F,EAAwB+C,WACnC,GAAU,MAAN7I,GAA4B,IAAdA,EAAGlI,OACnB,MAAM,IAAIE,MACN,6DAON,IALA,IAAM8Q,EAAe9I,EAAG,aAAczG,aAEhCoL,EAAQnJ,KAAKoJ,gBACbmE,KACAC,KACGjK,EAAI,EAAGA,EAAI+G,EAAahO,SAAUiH,EACrC4F,EAAMmB,EAAa/G,MAAQwE,qBAC7BwF,EAAoBnL,KAAKmB,GAEzBiK,EAAmBpL,KAAKmB,GAG5B,GAAmC,IAA/BgK,EAAoBjR,OACtB,MAAM,IAAIE,MACN,wFACkCuL,sBAGxC,IAAM0F,KACAC,gBACK/I,GACT,IAAMgJ,EACFJ,EAAoBzH,iBAAiB,EAAGyH,EAAoBjR,SAC1DsR,EAAeN,EACjBL,SAAYzI,EAAGG,IACfH,EAAGG,GACDkJ,EAAcP,EAChBL,SAAYzI,EAAGmJ,IACfnJ,EAAGmJ,GACDG,EACFhR,KAAQ,WAAM,OAAAJ,UAAUkR,EAAaxQ,IAAIyQ,EAAYE,IAAIV,OACzDC,EACFG,EAAcrL,KAAK0L,EAAMzH,YAEzBoH,EAAcrL,KAAK0L,GAErBJ,EAAkBtL,KAAKkI,EAAa3F,SAhBtC,IAAoB,IAAAqJ,EAAAvG,SAAA+F,+IAkBpBzM,QAAQkN,IACJ,0CAA0CR,EAAcnR,oBAE5DmR,EAAcnK,QAAQ,SAAA4K,GAAU,OAAA1J,EAAGpC,KAAK8L,KACxC5D,EAAalI,WAAbkI,WAAqBoD,KAGf7E,qCAAR,WAGE,YAFMsF,EAAe,IAAIC,IACnBjF,EAAQnJ,KAAKoJ,gBACV7F,EAAI,EAAGA,EAAI4F,EAAM7M,SAAUiH,EAAG,CACrC,IAAMwF,EAAQI,EAAM5F,GACdiH,EAAMxK,KAAKkI,UAAUa,OAC3B,IAAiB,IAAAsF,YAAA5G,SAAA+C,kCAAK,CAAjB,IAAMb,UACHc,EAAczK,KAAKiI,SAAS0B,GAAIc,YAChCxK,EAAYwK,EAAYxL,KAAK3C,OAASmO,EAAYpH,UACxD8K,EAAa/Q,IAAI6C,sGAGrB,IAAMqO,WAAsBH,GAE5B,OADAG,EAAgBC,OACTD,GASTzF,0BAAA,SAAcI,GACZ,KAAMA,KAAOjJ,KAAKiI,UAChB,MAAM,IAAIzL,MAAM,4BAA4ByM,GAE9C,IAAMF,EAAQ/I,KAAKiI,SAASgB,GAAKF,aAC1B/I,KAAKiI,SAASgB,GACrB,IAAMtE,EAAQ3E,KAAKkI,UAAUa,GAAOtN,QAAQwN,GAC5CjJ,KAAKkI,UAAUa,GAAOyF,OAAO7J,EAAO,GACC,IAAjC3E,KAAKkI,UAAUa,GAAOzM,eACjB0D,KAAKkI,UAAUa,IAa1BF,oCAAA,SAAwBI,EAAa2B,GACnC,KAAM3B,KAAOjJ,KAAKiI,UAChB,MAAM,IAAIzL,MAAM,4BAA4ByM,GAE9C,IAAMwB,EAAczK,KAAKiI,SAASgB,GAAKwB,YACjCxK,EAAYwK,EAAYxL,KAAK3C,OAASmO,EAAYpH,UACxD9C,KAAQC,OACJoK,GAAiB,GAAKA,EAAgB3K,GAClC+J,OAAOC,UAAUW,GACrB,WAAM,MAAA,0BAA0BA,uBACT3K,wBAC3BwK,EAAYG,cAAgBA,GAQ9B/B,iBAAA,WACE,OAAO4F,OAAOC,KAAK1O,KAAKiI,UAAU3L,QAUpCuM,2BAAA,WACE,IAAI8F,EAAY,EAEhB,IAAK,IAAMC,KAAO5O,KAAKiI,SAAU,CAC/B,IAAMwC,EAAczK,KAAKiI,SAAS2G,GAAKnE,YACjCoE,EAHyB,MAI3BpE,EAAYtK,oBAChBwO,GACIlE,EAAYxL,KAAK3C,OAASmO,EAAYpH,UAAYwL,EAExD,OAAOF,GAUT9F,kBAAA,WACE,OAAuB,IAAhB7I,KAAK4J,QAMdf,kBAAA,WACE7I,KAAKiI,aASPY,0BAAA,WACE,IAAMM,EAAQ,IAAIiF,IAClB,IAAK,IAAMnF,KAAOjJ,KAAKiI,SAAU,CAC/B,IAAMa,EAAU9I,KAAKiI,SAASgB,GAC9BE,EAAM/L,IAAI0L,EAAQC,OAEpB,IAAM+F,WAAkB3F,GAExB,OADA2F,EAAYP,OACLO,GAiBTjG,sBAAA,SAAUkG,eACF5F,EAAQnJ,KAAKoJ,gBACnB7I,KAAQC,QAAQR,KAAKgP,QAAS,WAAM,MAAA,mCAElB,MAAdD,IACGpR,MAAM2J,QAAQyH,KACjBA,GAAcA,IAEhBA,EAAWzL,QAAQ,SAAA2L,GACjB,IAAkC,IAA9B9F,EAAM1N,QAAQwT,GAChB,MAAM,IAAIzS,MACN,eAAeyS,4EAEZ9S,KAAK6M,UAAUG,WAK5B,IAAMd,KACApE,SACN,IAAoB,IAAAiL,EAAAzH,SAAA0B,iCAAO,CAAtB,IAAMJ,UACT,GAAkB,MAAdgG,IAAqD,IAA/BA,EAAWtT,QAAQsN,GAA7C,CAGA,IAAMyB,EAAMxK,KAAKkI,UAAUa,OAC3B,IAAiB,IAAAoG,YAAA1H,SAAA+C,kCAAK,CAAjB,IAAMb,UACHyF,EAAWC,iBAAiBrP,KAAKiI,SAAS0B,IAChDtB,EAASjG,KAAKgN,EAAS9G,MACvBrE,EAAQ7B,KAAKgN,EAASnQ,4MAG1B,OAAOqQ,gCACFjH,WAAUpJ,KAAM+E,wBAAwBC,oBAKjCoL,iBAAiBvG,GAE/B,IAAMyG,EAAkC,MAApBzG,EAAQlK,SACtB0J,GACJS,MAAOD,EAAQC,MACfP,qBACIM,EAAQ2B,YAAYxL,KAAK3C,OAASwM,EAAQ2B,YAAYpH,UAC1DoF,qBAAsBK,EAAQ2B,YAAYpH,WAEH,MAArCyF,EAAQ2B,YAAYG,gBACtBtC,EAAKkH,yBAA2B1G,EAAQ2B,YAAYG,eAGtD,IAAI3L,EAAO6J,EAAQ2B,YAAYxL,KAAKM,OAAOlD,MAAM,GAQjD,OAPIkT,IACFjH,EAAKI,mBAAqBI,EAAQlK,SAASK,KAAK3C,OAChDgM,EAAKmH,qBAAuB3G,EAAQlK,SAASM,aAG7CD,EAAO+E,yBAAyB/E,EAAM6J,EAAQlK,SAASK,KAAKM,WAEtD+I,OAAMrJ,iBAIA2J,mBACZwG,GACF,IAAM3E,GACJpH,UAAW+L,EAAS9G,KAAKG,qBACzBxJ,KAAM,IAAIlB,aAAaqR,EAASnQ,KAAK5C,MACjC,EACA,EAAI+S,EAAS9G,KAAKG,qBACd2G,EAAS9G,KAAKE,wBAEsB,MAA1C4G,EAAS9G,KAAKkH,2BAChB/E,EAAYG,cAAgBwE,EAAS9G,KAAKkH,0BAE5C,IAAME,GAAe3G,MAAOqG,EAAS9G,KAAKS,MAAO0B,eASjD,OARwC,MAApC2E,EAAS9G,KAAKI,qBAChBgH,EAAG9Q,UACDM,aAAckQ,EAAS9G,KAAKmH,qBAC5BxQ,KAAM,IAAIlB,aAAaqR,EAASnQ,KAAK5C,MACjC,EAAI+S,EAAS9G,KAAKG,qBAClB2G,EAAS9G,KAAKE,yBAGfkH,EAgBT,SAASJ,+BAA+BtH,GAEtC,IAAM2H,EACF/K,mBAAmBzI,KAAK6M,UAAUhB,EAAWK,WAE3CuH,EAAmBhL,mBAAmBiD,kCACtCgI,EAAU,IAAIC,aAAahI,gCAC3BiI,EAAiB,IAAID,aAAaH,EAAexL,aAIvD,OAAOH,yBAHcA,yBAChB4L,EAAkBC,EAAQtQ,OAAQwQ,EAAexQ,SAGnCoQ,EAAgB3H,EAAW/I,gBAIhCmJ,+BAA+B7I,GAE7CgB,KAAQC,OAAiB,MAAVjB,EAAgB,WAAM,MAAA,sCAErC,IAAI+E,EAAS,EACP0L,EAAa7K,mBACf5F,EAAOlD,MAAMiI,EAAQuD,iCAAiCvL,SAC1DiE,KAAQC,OACJwP,IAAenI,iCACf,WAAM,MAAA,8CACVvD,GAAUuD,iCAAiCvL,OAE3CgI,GAAU,EAGV,IAAMyL,EAAiB,IAAID,YAAYvQ,EAAQ+E,EAAQ,GAEjD2L,EADN3L,GAAU,EAEVA,EAAS2L,EAAoBF,EAAe,GAC5C,IACMG,EAAiB/K,mBADD5F,EAAOlD,MAAM4T,EAAmB3L,IAItD,OAAQ+D,SAFSlM,KAAKC,MAAM8T,GAEVjR,KADLM,EAAOlD,MAAMiI,IAsB5B,SAAgB2G,gBACZP,EAAuBC,EAAoBwF,EAC3CC,GA0BF,GAzBA7P,KAAQC,OACJwJ,OAAOC,UAAUS,IAAkBA,EAAgB,EACnD,WACI,MAAA,qDAAqDA,IAC3C,MAAdC,GACFpK,KAAQC,OACJwJ,OAAOC,UAAUU,IAAeA,GAAc,EAC9C,WACI,MAAA,sDAAsDA,IAEhEpK,KAAQC,OACJwJ,OAAOC,UAAUkG,IAAiBA,EAAe,EACjD,WAAM,MAAA,oDAAoDA,IAC9D5P,KAAQC,OACJwJ,OAAOC,UAAUmG,IAAcA,EAAY,EAC3C,WAAM,MAAA,iDAAiDA,IAC3D7P,KAAQC,OACJ2P,GAAgBzF,EAChB,WAAM,MAAA,iBAAiByF,8BACfzF,QACZnK,KAAQC,OACJmK,EAAaD,EACb,WAAM,MAAA,eAAeC,wCACbD,QAERyF,IAAiBzF,EACnB,QAAS,EAAGA,IAGd,IAAMM,KAEN,GAAkB,MAAdL,EAAoB,CAKtB,IADA,IAAI0F,EAAQ,EACLA,EAAQF,GAAgBzF,GAC7BM,EAAQ5I,MAAMiO,EAAOA,EAAQF,IAC7BE,GAASD,EAEX,OAAOpF,EAGT,IAAMsF,EAAW7S,KAAKiI,MAAMyK,EAAe,GACvCI,EAAO5F,EAAa2F,EAOxB,IANIC,EAAO,EACTA,EAAO,EACEA,EAAOJ,EAAezF,IAC/B6F,EAAO7F,EAAgByF,KAInBI,EAAOH,EAAY,GAAKzF,GAAc4F,EAAOH,EAAYD,IAG7DI,GAAQH,EAGV,KAAOG,EAAOJ,GAAgBzF,KACxBC,EAAa4F,IAGjBvF,EAAQ5I,MAAMmO,EAAMA,EAAOJ,IAC3BI,GAAQH,EAEV,OAAOpF,WAaOwF,2BAA2B/F,GAEzC,OAAO3N,KAAQ,WACb,IAAMmD,EAAYwK,EAAYxL,KAAK3C,OAASmO,EAAYpH,UAExD,OADUoN,SAAYhG,EAAYxL,MAAOgB,EAAWwK,EAAYpH,YACvDtG,MAAM,cAaH8N,0BAA0BJ,GAExC,OAAO3N,KAAQ,WAAM,OAAA0T,2BAA2B/F,GAAarE,eC18BzDyJ,QAAU,QCwBHa,YAAc,YAIdC,yBACT,4CACSC,iBAAmB,0CAIrBC,qBACTC,aAAgC,oBAAX7S,OAAyB,KAAOA,OAAO6S,uBAG9CC,wBAAwBlB,GAEtC,OADqBA,EAAQmB,MAAM,KACf3U,MAAM,EAAG,GAAG4U,KAAK,KAOvC,IAAMC,yBAA2B,iDAsD/B,WACIC,EAAqBC,EACrBC,GA9CKrR,sBACL,oEACI+Q,wBAAwBlB,wBAEf7P,oBAAiB,MACjBA,cAAW,KACXA,qCAAkC,EAQzCA,gBAAY,EAMdA,4BA6BNO,KAAQC,OACmB,MAAvB4Q,GAAgD,MAAjBC,GACJ,MAAvBD,GAAgD,MAAjBC,EACnC,WAAM,MAAA,yEAEiB,MAAvBD,GACgB,MAAdD,EACFA,EAAaG,EAAkCC,wBAE/ChR,KAAQC,QAEiB,IADrB8Q,EAAkCE,uBAAuB/V,QACrD0V,GACJ,WAAM,MAAA,6BAA6BA,QAEzCnR,KAAKmR,WAAaA,EAClBnR,KAAKoR,oBACEpR,KAAKyR,qBAAoBzR,KAAKmR,yBACrCnR,KAAKqR,cACErR,KAAKyR,qBAAoBzR,KAAKmR,8BAErC5Q,KAAQC,OACU,MAAd2Q,EACA,WAAM,MAAA,wEAEVnR,KAAKoR,oBAAsBA,EAC3BpR,KAAKqR,cAAgBA,GAGvBrR,KAAK0R,YACHxS,aAAcc,KAAK2R,eACnBzR,QAASF,KAAK4R,UAkepB,OAlcQN,mBAAN,SACIO,EACAjS,kIACF,GAAII,KAAK8R,UACP,MAAM,IAAItV,MACN,2DAGN,SAAMwD,KAAK+R,4BAwBX,GAxBA7V,SAEc,MAAV0D,IACFA,MAEEoS,EAC+B,MAA/BpS,EAAOoS,qBAA+B,EAAIpS,EAAOoS,qBACjDpS,EAAOqS,mBAETD,EAAuB,GAEzBzR,KAAQC,OACJwR,GAAwB,GAAKA,GAAwB,EACrD,WAAM,MAAA,uCAAuCA,IAC7CE,EAC0C,MAA1CtS,EAAOsS,iCAEPtS,EAAOsS,gCACPtS,EAAOqS,mBAGTC,GAAkC,GAGhCtS,EAAOG,sBAAwB,EACjC,MAAM,IAAIvD,MACN,yDACWoD,EAAOG,uBAqExB,OAlEMM,EACsB,MAAxBT,EAAOS,cAAwB,GAAMT,EAAOS,cAChDE,KAAQC,OACJH,GAAiB,GAAKA,EAAgB,EACtC,WAAM,MAAA,sDACFA,IAEFR,EACF,SAAOlD,EAAc8E,2IACjB0Q,EAAczV,UAAUC,GAG1BiD,EAAOqS,oBACHjS,KAAKoS,6DAAXzW,SACAM,qDAAC6B,OAAGuU,oBAGJvU,EAAIkC,KAAKsS,MAAMC,QAAQJ,oBAGV,SAAMrU,EAAEmB,eAEL,OAFZuT,EAAS7W,aACT8W,EAAiB3U,EAAEsI,QAAQ,IACMnH,sBAAjCyT,EAAY/W,SAA6B,GACzCgX,EAAWlV,KAAKkE,UAALlE,cAAY+U,IAC7B3P,SAAY/E,EAAG2U,EAAgBN,IAE3BQ,EAAWX,MACN,uBAEHvH,OAA+B0C,EAC/BvN,EAAOgT,4BAEKjW,EAAEsC,sBAAd/C,OAAMP,SACNO,YAAW8D,KAAK6S,mBAAmB,GAFrCpI,qBAmBF,OAbIqI,GAAe,EACdZ,GAEClS,KAAK+S,MAAML,KAAc3K,sBACzB/H,KAAK+S,MAAML,KAAchC,cAC3BoC,GAAe,GAGfA,GACFjB,GAAUW,SAAQ/H,cAAa4H,iBAI1BS,SAIL/S,EAAwD,MAAhCH,EAAOG,sBACjCC,KAAKgT,gCACLpT,EAAOG,sBACXC,KAAKiT,mBAAqB,IAAItS,4BAC5BzB,aAAcc,KAAK0R,WAAWxS,aAC9BY,wBAAyBE,KAAK6S,mBAAmB,GACjDzS,qBAAsBJ,KAAK6S,mBAAmB,GAC9C9S,wBACAF,sBACAQ,qBAGIL,KAAKiT,mBAAmBvT,MAAME,EAAOvB,sCAA3CnC,SAEA8D,KAAK8R,WAAY,YAQbR,8BAAN,wIACE,OAAkB,MAAdtR,KAAKsS,aAIHtS,KAAKkT,sCAAXhX,SAGwC,iBAA7B8D,KAAKoR,6BACA+B,gBAAmBnT,KAAKoR,oCAAtCkB,EAAQpW,sBAGA,SAAMiX,gBAAmBC,GAAMC,WACnCrT,KAAKoR,oBAAoBkC,cACzBtT,KAAKoR,oBAAoBmC,YACzBvT,KAAKoR,oBAAoBoC,qBAH7BlB,EAAQpW,0BAOV,GAA4B,IAAxBoW,EAAMmB,OAAOnX,OACf,MAAM,IAAIE,MACN,wDACG8V,EAAMmB,OAAOnX,kBAEtB,GAAqC,IAAjCgW,EAAMmB,OAAO,GAAGjQ,MAAMlH,OACxB,MAAM,IAAIE,MACN,mFACkC8V,EAAMmB,OAAO,GAAGjQ,MAAMlH,QAE9D,GAAiC,IAA7BgW,EAAMmB,OAAO,GAAGjQ,MAAM,GACxB,MAAM,IAAIhH,MACN,0FAEGL,KAAK6M,UAAUsJ,EAAMmB,OAAO,GAAGjQ,MAAM,SAK9C,GAA2B,KADrBkQ,EAAcpB,EAAMoB,aACVpX,OACd,MAAM,IAAIE,MACN,8EACsBL,KAAK6M,UAAU0K,IAE3C,GAAIA,EAAY,KAAO1T,KAAK+S,MAAMzW,OAChC,MAAM,IAAIE,MACN,gEACIkX,EAAY,6BACZ1T,KAAK+S,MAAMzW,oBAGrB0D,KAAKsS,MAAQA,EACbtS,KAAK2T,cAEL3T,KAAK6S,mBACDP,EAAMmB,OAAO,GAAGjQ,MAAMnH,MAAM,GAChC2D,KAAK4T,mBAAqB,EAC1BtB,EAAMmB,OAAO,GAAGjQ,MAAMnH,MAAM,GAAGiH,QAC3B,SAAAuQ,GAAW,OAAApT,EAAKmT,oBAAsBC,IAC1C7T,KAAK8T,cACC3T,EACFH,KAAK0R,WAAWxR,QAAUF,KAAK0R,WAAWxS,aAAe,IACvDe,EAAYqS,EAAMmB,OAAO,GAAGjQ,MAAM,GACxCxD,KAAK0R,WAAWqC,0BAA4B9T,EAAYE,YAU1CmR,kDAAhB,6HACE,OAAqC,MAAjCtR,KAAKgU,gCAGHhU,KAAK+R,4BAIX,IAJA7V,SAISqH,EAAIvD,KAAKsS,MAAM2B,OAAO3X,OAAS,EAAGiH,GAAK,IAAKA,EACnD,GAA4C,UAAxCvD,KAAKsS,MAAM2B,OAAO1Q,GAAG2Q,eAA4B,CACnDC,EAAuBnU,KAAKsS,MAAM2B,OAAO1Q,GACzC,MAGJ,GAA4B,MAAxB4Q,EACF,MAAM,IAAI3X,MACN,wEAENwD,KAAKgU,yBAA2BI,OAC9BX,OAAQzT,KAAKsS,MAAMmB,OACnBY,SACErU,KAAKsS,MAAM+B,QAAQ,GAAIF,EAAqBzK,oBAK1C4H,wBAAR,WAAA,WACExU,KAAQ,WAEN,IADA,IAAMH,EAAI2X,OAAU,GAAGC,OAAO9T,EAAKoS,qBAC1BtP,EAAI,EAAGA,EAAI,IAAKA,EACvB9C,EAAK6R,MAAMC,QAAQ5V,MAKX2U,iCAAd,+HACE,OAAkB,MAAdtR,KAAK+S,UAI0C,iBAAvB/S,KAAKqR,uBACvBjW,iBAAiB4E,KAAKqR,8BAA5BnV,EAAAD,sBACAC,EAAA8D,KAAKqR,+BAET,GAA+B,OAJzBmD,KAIWzF,WAAoB,CAMnC,GAAmB,OADb0F,EAAeD,EAA4B,OAE/C,MAAM,IAAIhY,MACN,mEAENwD,KAAK+S,MAAQ0B,OAEbzU,KAAK+S,MAAQyB,EAAazF,2BASxBuC,0BAAN,qHACE,IAAKtR,KAAK8R,UACR,MAAM,IAAItV,MAAM,wDAElB,SAAMwD,KAAKiT,mBAAmB/P,sBAA9BhH,SACA8D,KAAK8R,WAAY,YAMnBR,wBAAA,WACE,OAAOtR,KAAK8R,WAQdR,uBAAA,WACE,OAAOtR,KAAK+S,OAQdzB,mBAAA,WACE,OAAOtR,KAAK0R,YAQdJ,4BAAA,WACE,GAAkB,MAAdtR,KAAKsS,MACP,MAAM,IAAI9V,MACN,uGAGN,OAAOwD,KAAKsS,MAAMmB,OAAO,GAAGjQ,OAqBxB8N,sBAAN,SAAgBoD,EAAgC9U,2IAM9C,OAJc,MAAVA,IACFA,SAGII,KAAK+R,mCAAX4C,SAEa,MAATD,WAG4B1U,KAAK4U,0BAA7BC,EAAkBF,SACxBD,EAAQG,EAAgB5V,sBAM1B,GAAIyV,aAAiBI,OAEnB9U,KAAK+U,sBAAsBL,GAC3BM,EAAcN,EACdO,EAAcP,EAAMlR,MAAM,OACrB,CACL,GAAIkR,EAAMpY,OAAS0D,KAAK4T,mBACtB,MAAM,IAAIpX,MACN,wCAAwCkY,EAAMpY,mGAET0D,KAAK4T,wBAGhDqB,EAAcP,EAAMpY,OAAS0D,KAAK4T,mBAClCoB,EAAcE,SAAYR,GACxBO,GACAV,OAAOvU,KAAK6S,4BAGVnJ,GAAyC8I,OAAQ,MACnD5S,EAAOqS,oBAEHjS,KAAKoS,6DAAXuC,SACMQ,EACFnV,KAAKgU,yBAAyBzB,QAAQyC,GAC1CI,EAAYD,EAAgB,GAC5BzL,EAAO2I,UAAY8C,EAAgB,gBAEnCC,EAAYpV,KAAKsS,MAAMC,QAAQyC,2BAGb,IAAhBC,SACF/Y,EAAAwN,KAAsB0L,EAAUnW,uBAAhC/C,EAAOsW,OAASmC,uBAIA,OAFVU,EAAYC,QAAWF,GACvBG,EAAgBF,EAAUxX,IAAI,SAAAkO,GAAQ,OAAAA,EAAK9M,SACjDhD,EAAAyN,KAAsB8L,QAAQC,IAAIF,WAAlCtZ,EAAOuW,OAASmC,SAChB9R,QAAWwS,6BAGTzV,EAAOgT,oBACTjX,EAAA+N,OACSgL,aAAiBI,UAAkBJ,EAAMzV,sCAAZyW,EAAAf,wBAAqBe,EAAAhB,qBAD3D/Y,EAAO8O,aACLkL,SAEAA,YAAW3V,KAAK6S,mBAAmB,yBAKvC,OADAhQ,QAAWuS,MACJ1L,SAGK4H,4BAAd,yGACE,SAAO,IAAIkE,QAAyB,SAACI,EAASC,GAW5CpV,EAAKwS,mBAAqB,IAAItS,4BAC5BzB,aAAcuB,EAAKiR,WAAWxS,aAC9BY,wBAAyBW,EAAKoS,mBAAmB,GACjDzS,qBAAsBK,EAAKoS,mBAAmB,GAC9C9S,sBAAuB,EACvBF,oBAf+C,SAAOlD,oHAEtD,OADMwV,EAAczV,UAAUC,MACxBqD,KAAKiT,mBAAmB/P,eAEtB,OAFRvH,SACAO,EAAA0Z,UACczD,EAAYlT,eAI1B,OALA/C,iBACED,OAAMN,SACNM,YAAW+D,KAAK6S,mBAAmB,QAErCV,EAAY2D,cACL,SAQPzV,cAAe,IAEjBI,EAAKwS,mBAAmBvT,gBAI5B4R,2BAAA,SAAeyE,GACb,GAAkB,MAAd/V,KAAKsS,MACP,MAAM,IAAI9V,MACN,wGAGN+D,KAAQC,OACI,MAARuV,GAAgC,iBAATA,GAAqBA,EAAKzZ,OAAS,EAC1D,WAAM,MAAA,0FAC2BH,KAAK6M,UAAU+M,KACpDxV,KAAQC,OAC8B,MAAlCR,KAAKgW,oBAAoBD,GACzB,WAAM,MAAA,qDAAqDA,QAC/D,IAAME,EAAW,IAAIC,0CACjBH,EAAM/V,KAAK0R,WAAY1R,KAAKsS,OAEhC,OADAtS,KAAKgW,oBAAoBD,GAAQE,EAC1BA,GAGC3E,wBAAV,uBACE,IAAoB,IAAArV,EAAAwL,SAAAzH,KAAKsS,MAAM2B,sCAAQ,SAC/BkC,WAAY,sGAId7E,kCAAR,SAA8BoD,GAC5B,IAAM0B,EAAepW,KAAKsS,MAAMmB,OAAO,GAAGjQ,MAAMlH,OAChD,GAAIoY,EAAMlR,MAAMlH,SAAW8Z,EACzB,MAAM,IAAI5Z,MACN,sCAAsC4Z,oBACtB1B,EAAMlR,MAAMlH,yBAElC,IAAM+Z,EAAkB3B,EAAMlR,MAAMnH,MAAM,GACpCia,EAAwBtW,KAAKsS,MAAMmB,OAAO,GAAGjQ,MAAMnH,MAAM,GAC/D,IAAKkE,KAAQgW,YAAYF,EAAiBC,GACxC,MAAM,IAAI9Z,MACN,sCAAsC8Z,4BACfD,QAjjBf/E,0BAAoC,MAAO,iBAC3CA,0BAA0B,iEAskB1C,WACayE,EAAuBrE,EACvB8E,GAFb,MAGEC,0BAFWhW,OAAAsV,EAAuBtV,aAAAiR,EACvBjR,YAAA+V,EAEXjW,KAAQC,OACI,MAARuV,GAAgC,iBAATA,GAAqBA,EAAKzZ,OAAS,EAC1D,WAAM,MAAA,oEACSH,KAAK6M,UAAU+M,KAClCtV,EAAKoS,mBACDpS,EAAK+V,UAAU/C,OAAO,GAAGjQ,MAAMnH,MAAM,GACzCoE,EAAKsS,MAAQ,KACbtS,EAAKyI,QAAU,IAAIL,UA+tBvB,OAvvBI6N,eAqCIR,2BAAN,SAAqB5M,EAAcqN,yGAejC,GAbApW,KAAQC,QACHR,KAAK8R,UACN,WAAM,MAAA,4IAGVvR,KAAQC,OACI,MAAR8I,GAAgC,iBAATA,GAAqBA,EAAKhN,OAAS,EAC1D,WAAM,MAAA,8EAGK,MAAXqa,IACFA,MAEgC,MAA9BA,EAAQC,oBAAqD,MAAvBD,EAAQE,YAChD,MAAM,IAAIra,MACN,sFA8CN,OAzC2B,MAAvBma,EAAQE,aACVtW,KAAQC,OACJmW,EAAQE,YAAc,EACtB,WACI,MAAA,2CAA2CF,EAAQE,cACrDC,EACF9W,KAAK0R,WAAWxR,QAAUF,KAAK0R,WAAWxS,aAC9CY,EACIrC,KAAKsZ,KAAKJ,EAAQE,YAAcC,IACG,MAA9BH,EAAQC,oBACjBrW,KAAQC,OACJmW,EAAQC,oBAAsB,EAC9B,WAAM,MAAA,oDACSD,EAAQC,qBAC3B9W,EACIrC,KAAKmE,MAAM5B,KAAK6S,mBAAmB,GAAK8D,EAAQC,qBAEpD9W,EAA0BE,KAAK6S,mBAAmB,GAGlB,MAA9B8D,EAAQK,qBACVzW,KAAQC,OACJmW,EAAQK,mBAAqB,EAC7B,WAAM,MAAA,qDACCL,EAAQK,qBACnBzW,KAAQC,OACiB,MAArBmW,EAAQM,UACR,WAAM,MAAA,mEAGa,MAArBN,EAAQM,WACV1W,KAAQC,OAC0B,MAA9BmW,EAAQK,mBACR,WAAM,MAAA,kEAGNE,EACFlX,KAAK0R,WAAWxR,QAAUF,KAAK0R,WAAWxS,aACxCiY,EAAmBD,EAAmBpX,EAE5CE,KAAK8R,WAAY,KACV,IAAI0D,QAAyB,SAAAI,GAClC,IAAMwB,EAA2C,MAA9BT,EAAQK,mBACvB,EACAL,EAAQK,mBAAqBG,EAC3B9W,EAAgB,EAAI+W,EACpBC,EAAsB5Z,KAAKmE,MAAM,EAAIwV,GACvCE,EAAgB,EAChBC,GAAa,EACXC,KAwEN/W,EAAKwS,mBAAqB,IAAItS,4BAC5BzB,aAAcuB,EAAKiR,WAAWxS,aAC9BY,0BACAM,qBAAsBK,EAAKoS,mBAAmB,GAC9C9S,sBAAuB,EACvBF,oBA1EE,SAAO0B,EAAqBE,6JAEL,MAArBkV,EAAQM,iBACJ9E,EAAczV,UAAU6E,GAC9BtF,GAAAC,EAAA8D,KAAKkJ,SAAQP,cACXI,MAAOO,WAEO6I,EAAYlT,uBAD1BtD,eACEga,OAAM8B,SACN9B,YAAW3V,KAAK6S,mBAAmB,MAE3B8D,EAAQrW,yBACJmB,EAASxC,6BAArB0V,OAAM8C,SACN9C,eAAc3U,KAAKiT,mBAAmB/T,aAFJwW,iBAIAA,OAAAvI,mBAGtC,OAbAlR,YAMEN,kBAMFwW,EAAY2D,aACN9V,KAAKiT,mBAAmB/P,eAItB,OAJRuU,SACAzX,KAAK8R,WAAY,EACjB9R,KAAK0X,uBACLC,EAAA/B,UACcrU,EAAStC,sBADvB0Y,iBACEC,OAAMH,SACNG,YAAW5X,KAAK6S,mBAAmB,sBAGxB,SAAMtR,EAAStC,eAK5B,IALMA,EAAOwY,UACM,IAAfF,IACFA,EAAYtY,EAAK3C,QAEfiH,EAAIgU,EAAY,EACD,IAAZtY,EAAKsE,IAAYA,GAAK,GAC3BA,WAEIsU,EAAYN,EAAYhU,EAAI,EAClCgU,EAAYhU,EAAI,EACVuU,EAAc7Y,EAAK5C,MAAM4C,EAAK3C,OAASub,EAAW5Y,EAAK3C,QAC7Dkb,EAAoBpV,KAAK0V,GAEA,MAArBnB,EAAQM,WACVN,EAAQM,WACHhY,KAAM6Y,EAAazU,UAAWrD,KAAK6S,mBAAmB,KAGzDyE,MAAoBD,YAChBrX,KAAKiT,mBAAmB/P,sBAA9BuU,SACAzX,KAAK8R,WAAY,EACjB9R,KAAK0X,uBAECK,EAAa1a,sBACfkH,yBAAyBiT,IACvBQ,GACJ/Y,KAAM8Y,EACN1U,UAAWrD,KAAK6S,mBAAmB,IAErCoF,GAAAC,EAAAlY,KAAKkJ,SAAQP,cACXI,MAAOO,EACPmB,YAAauN,GACHrB,EAAQrW,yBACJmB,EAASxC,+BAArBkZ,OAAMV,SACNU,eAAcnY,KAAKiT,mBAAmB/T,aAFJkZ,mBAIAA,OAAAjL,qBAPtC8K,YAGEI,kBAOFzC,EAAQoC,sBAGZ,UAAO,SAQP3X,gBACAC,gBAAiBqW,EAAQrW,kBAE3BG,EAAKwS,mBAAmBvT,MAAMiX,EAAQtY,+BAO1C6X,0BAAA,WAAA,WACE3V,KAAQC,OACU,MAAdR,KAAK+S,OAAiB/S,KAAK+S,MAAMzW,OAAS,IAAM0D,KAAKkJ,QAAQ8F,QAC7D,WACI,MAAA,sDAAsDvO,EAAKsV,OACnE/V,KAAKkJ,QAAQoP,QACbtY,KAAK+S,MAAQ,MAUfmD,0BAAA,WACE,GAAIlW,KAAKkJ,QAAQ8F,QACf,MAAM,IAAIxS,MACN,sEACUwD,KAAK+V,eAErB,OAAO/V,KAAKkJ,QAAQqP,oBAStBrC,wBAAA,SAAYnN,GACV,OAAO/I,KAAKkJ,QAAQK,YAAYR,IAIlCmN,oCAAA,SAAwBjN,EAAa2B,GACnC5K,KAAKkJ,QAAQsP,wBAAwBvP,EAAK2B,IAQ5CsL,0BAAA,SAAcjN,GACZjJ,KAAKkJ,QAAQuP,cAAcxP,GAC3BjJ,KAAK0X,wBAQPxB,2BAAA,WACE,OAAOlW,KAAKkJ,QAAQ8F,SAUtBkH,yBAAA,SAAalO,EAAyB0Q,4BAAAA,MACpC,IAAMC,EAAkB,IAAI9P,QAAQb,GAChC0Q,GACF1Y,KAAK4Y,gBAGP,IAAMC,EAAgBF,EAAgBvP,oBACtC,IAAoB,IAAA0P,EAAArR,SAAAoR,iCAAe,CAA9B,IAAM9P,UACHd,EAAW0Q,EAAgBpP,YAAYR,OAC7C,IAAsB,IAAAS,YAAA/B,SAAAQ,kCAAU,CAA3B,IAAMa,UACT9I,KAAKkJ,QAAQP,WAAWG,EAAQA,8MAIpC9I,KAAK0X,wBAYPxB,8BAAA,SAAkBnH,GAChB,OAAO/O,KAAKkJ,QAAQ6P,UAAUhK,IAQxBmH,iCAAR,WACElW,KAAK+S,MAAQ/S,KAAKkJ,QAAQE,iBAepB8M,yCAAR,SACI8C,EACAC,GAEF,IAAMhZ,EAAYD,KAAK6S,mBAAmB,GAC1CmG,EAAiBA,GAAkB9H,yBACnC,IAAMrH,EAAYpM,KAAKmE,MAAMoX,EAAiB/Y,GACxCiZ,EAAMlZ,KAAKkJ,QAAQiQ,QACT,eAAOlZ,YAAW4J,aAAcoP,IAEhD,OAAQzU,GAAI0U,EAAI1U,GAAIyB,GAAIiT,EAAIjT,KAoBtBiQ,2CAAR,SACI8C,EAAyBI,EAAwB3N,EACjDwN,gBADyBG,oBAAwB3N,MAGnD,IAAMxL,EAAYD,KAAK6S,mBAAmB,GAC1CmG,EAAiBA,GAAkB9H,yBACnC,IAAMrH,EAAYpM,KAAKmE,MAAMoX,EAAiB/Y,GAC9C,OAAOD,KAAKkJ,QAAQiQ,QAAQ,eAC1BlZ,YACA4J,YACAuB,YAAY,EACZM,iBAAkBD,EAClBG,uBAAwBwN,GACrBH,KAqBD/C,kBAAN,SAAYtW,mGA+CV,OA7CAW,KAAQC,OACU,MAAdR,KAAK+S,OAAiB/S,KAAK+S,MAAMzW,OAAS,EAC1C,WACI,MAAA,yCAAyCmE,EAAKsV,oEAEtDxV,KAAQC,OACJR,KAAK+S,MAAMzW,OAAS,EACpB,WAAM,MAAA,yCACImE,EAAKsV,sCACO5Z,KAAK6M,UAAUvI,EAAKsS,6EAEf,MAA3BnT,EAAOyZ,kBACT9Y,KAAQC,OACJZ,EAAOyZ,kBAAoB,GACvBrP,OAAOC,UAAUrK,EAAOyZ,kBAC5B,WAAM,MAAA,+EACuBzZ,EAAOyZ,mBAG5B,MAAVzZ,IACFA,MAGgB,MAAdI,KAAKsS,OACPtS,KAAKsZ,mCAMPtZ,KAAKuZ,yBAAyBpD,WAAY,EAG1CnW,KAAKsS,MAAMkH,SACTC,KAAM,0BACNC,UAAW9Z,EAAO8Z,WAAa,MAC/BC,SAAU,SAKNC,EAC0C,MAA5Cha,EAAOia,kCACP,IACAja,EAAOia,kCACP7Z,KAAKkJ,QAAQ4Q,iBAAmBF,GAClC7Y,QAAQkN,IACJ,4CACGjO,KAAKkJ,QAAQ4Q,0BACbF,yEAEA5Z,KAAK+Z,eAAena,QAEpBI,KAAKga,eAAepa,SAKjBsW,2BAAd,SAA6BtW,mIAWX,OAThBW,KAAQC,OAAOZ,EAAOqa,OAAS,EAAG,WAAM,MAAA,0BAGlCxO,EAAgC,MAApB7L,EAAO6L,UAAoB,GAAK7L,EAAO6L,UACnDuN,EAAiBpZ,EAAOoZ,gBAAkB9H,yBAC1ChV,EAAAge,OAA6Bla,KAAKma,+BACpCnB,EAAgBpZ,EAAOwZ,gBAAiB3N,GACvCF,0BAA2B3L,EAAO2L,+BAFhCgB,OAAcM,OAGfuN,EAAK7Z,KAAQ8Z,SACGra,KAAKsS,MAAMgI,WAAW/N,GAC1C0N,OAAQra,EAAOqa,OACfM,eAAgB3a,EAAOwZ,gBAAkB,EAAIvM,EAAa,KAC1D2N,UAA8B,MAAnB5a,EAAOiS,SAAmB,MAAQjS,EAAOiS,2BAHhD4I,EAAUxe,SAKhB8E,QAAQkN,IAAI,sBAAsB1N,KAAQ8Z,MAAQD,GAAIM,QAAQ,UAE/B,MAA3B9a,EAAOyZ,kBAA4BzZ,EAAOyZ,iBAAmB,GAEzDsB,EAAKpa,KAAQ8Z,SACara,KAAK4a,0BACjChb,EAAQ2M,EAAcM,kBAI1B,OALMgO,EAAoB5e,SAE1B8E,QAAQkN,IACJ,oCACI1N,KAAQ8Z,MAAQM,GAAID,QAAQ,cAC5BD,EAASI,WAEjB,SAAOJ,SAKGvE,2BAAd,SAA6BtW,qIAGrBoZ,EAAiBpZ,EAAOoZ,gBAAkB9H,yBAC1ChV,EAAW8D,KAAK8a,6BAClB9B,GACCzN,0BAA2B3L,EAAO2L,4BAFhC/G,OAAIyB,OAGXlF,QAAQkN,IACJ,6BAA6BzJ,EAAGhB,sBAAqByC,EAAGzC,wBAmB1C,6BAVc,MAA1B5D,EAAOwZ,iBACH2B,EAAS/U,sBAAsBxB,EAAIyB,EAAIrG,EAAOwZ,iBACpDrS,EAAUgU,EAAOhU,QACjBE,EAAU8T,EAAO9T,QACjB+T,GAAWD,EAAO7T,MAAO6T,EAAO5T,SAEhCJ,EAAUvC,EACVyC,EAAUhB,MAGUjG,KAAKsS,MAAM2I,IAAIlU,EAASE,GAC5CgT,OAAyB,MAAjBra,EAAOqa,OAAiB,GAAKra,EAAOqa,OAC5CM,eAAgBS,EAChBvP,UAAW7L,EAAO6L,UAClB+O,UAA8B,MAAnB5a,EAAOiS,SAAmB,MAAQjS,EAAOiS,2BAJhDqJ,EAAUjf,SAOe,MAA3B2D,EAAOyZ,kBAA4BzZ,EAAOyZ,iBAAmB,KAG/BrZ,KAAKmb,uBACjCvb,EAAQmH,EAASE,EAAS+T,iBAC9B,OAFMH,EAAoB5e,aAElBif,EAASL,WAEjB,SAAOK,oCAGTrY,SAAY2B,EAAIyB,EAAIc,EAASE,EAAS+T,+BAI5B9E,sCAAd,SACItW,EAA6B2M,EAC7BM,uHAawB,OAZpBuO,EAAyBpb,KAAKuZ,yBAAyBpD,UAC7DnW,KAAKuZ,yBAAyBpD,WAAY,EAGpCkF,EAC4B,MAA9Bzb,EAAOyb,oBAA8B,MAAQzb,EAAOyb,oBACxDrb,KAAKsS,MAAMkH,SACTC,KAAM,0BACNC,UAAW2B,EACX1B,SAAU,YAGoB3Z,KAAKsS,MAAMgI,WAAW/N,GACpD0N,OAAQra,EAAOyZ,iBACfkB,eAAgB1N,EAChB2N,UAA8B,MAAnB5a,EAAOiS,SAAmB,MAAQjS,EAAOiS,oBAKtD,OARMgJ,EAAoB3e,SAO1B8D,KAAKuZ,yBAAyBpD,UAAYiF,KACnCP,SAGK3E,mCAAd,SACItW,EAA6BmH,EAAoBE,EACjD+T,uHAawB,OAZpBI,EAAyBpb,KAAKuZ,yBAAyBpD,UAC7DnW,KAAKuZ,yBAAyBpD,WAAY,EAGpCkF,EAC4B,MAA9Bzb,EAAOyb,oBAA8B,MAAQzb,EAAOyb,oBACxDrb,KAAKsS,MAAMkH,SACTC,KAAM,0BACNC,UAAW2B,EACX1B,SAAU,YAGoB3Z,KAAKsS,MAAM2I,IAAIlU,EAASE,GACtDgT,OAAQra,EAAOyZ,iBACfkB,eAAgBS,EAChBvP,UAAW7L,EAAO6L,UAClB+O,UAAwC,MAA7B5a,EAAO0b,mBAA6B,MACC1b,EAAO0b,8BAKzD,OAVMT,EAAoB3e,SAS1B8D,KAAKuZ,yBAAyBpD,UAAYiF,KACnCP,SAUH3E,qBAAN,SAAetW,mGAab,OAZAW,KAAQC,OACyB,MAA7BZ,EAAO2b,oBACH3b,EAAO2b,mBAAmBjf,OAAS,EACvC,WAAM,MAAA,8CAGJkf,EAAoB,EAC1Bjb,KAAQC,OACJR,KAAK+S,MAAMyI,KAAuBzT,qBAClC,WAAM,MAAA,uDACCA,0BAEJjL,KAAQ,WAeb,IAdA,IAAM2e,KACFC,EAAM,EACJxf,mDAACsI,OACDmX,OAAavV,QAAQ,GAAGC,WACxBuV,EAAQnb,EAAK6R,MAAMC,QAAQ/N,GAK3BqX,EACFD,EAAMvf,OAAO,EAAG,IAAKuf,EAAMpY,MAAM,GAAIoY,EAAMpY,MAAM,GAAK,IAAI7B,KAAK,GAC7Dma,EAAQF,EAAMpY,MAAM,GAGjBD,EAAI,EAAGA,EAAI3D,EAAO2b,mBAAmBjf,SAAUiH,EAAG,CASzD,IARA,IAAMwY,EAAgBnc,EAAO2b,mBAAmBhY,GAC1CyY,EACFH,EAAaI,QAAQC,OAAUH,IAAgB1V,WAE/C8V,EAAY,EACZC,EAAY,EACZC,EAAiB,EACjBC,EAAgB,EACXC,EAAI,EAAGA,EAAIT,IAASS,EACvBZ,EAAQY,KAAOf,GACjBW,IACIH,EAAOO,IACTF,MAGFD,IACIJ,EAAOO,IACTD,KAMN,IAAME,EAAMH,EAAiBF,EACvBM,EAAMH,EAAgBF,EAE5BX,EAASrZ,MAAM2Z,gBAAeS,MAAKC,QACnC1b,QAAQkN,IACJ,cAAc8N,WACPS,EAAI9B,QAAQ,YAAW+B,EAAI/B,QAAQ,IAE1CnX,EAAI,IAENmY,GAAOje,KAAKif,IAAKjB,EAASlY,EAAI,GAAGiZ,IAAMf,EAASlY,GAAGiZ,MAC9Cf,EAASlY,EAAI,GAAGkZ,IAAMhB,EAASlY,GAAGkZ,KAAO,GAGlD,OAAQhB,WAAUC,eAUdxF,6CAAR,WAAA,WACE3V,KAAQC,OACU,MAAdR,KAAK+S,MACL,WACI,MAAA,mEACAtS,EAAKsV,OAKb,IAFA,IAAM9B,EAASjU,KAAKwW,UAAUvC,OAC1B0I,EAAa1I,EAAO3X,OAAS,EAC1BqgB,GAAc,GACqC,UAApD1I,EAAO0I,GAAYzI,eAAe0I,eAGtCD,IAEF,GAAIA,EAAa,EACf,MAAM,IAAIngB,MAAM,uDAElBwD,KAAKuZ,yBAA2BtF,EAAO0I,GACvC,IAAME,EACF7c,KAAKuZ,yBAAyB7P,OAElC1J,KAAK8c,aAAeC,aACpB/c,KAAK8c,aAAa1f,IAAI4f,OAAUC,OAC9BC,MAAOld,KAAK+S,MAAMzW,OAClB6gB,WAAY,UACZC,WAAYP,EAAoBrZ,MAAMnH,MAAM,GAC5C0Z,KAAM,kBAER,IAAMsH,EACFrd,KAAK8c,aAAaQ,MAAMT,GAC5B7c,KAAKsS,MACD8B,OAAUX,OAAQzT,KAAKwW,UAAU/C,OAAQY,QAASgJ,KAQxDnH,4BAAA,WACE,OAAOlW,KAAKwW,UAAU/C,OAAO,GAAGjQ,OAGlC0S,wBAAA,WACE,OACEqH,0BAA2B1N,QAC3B2N,UAAWxd,KAAK+V,KAChB0H,WAAW,IAAIC,MAAOC,cACtB5O,WAAY/O,KAAK+O,eAIfmH,iBAAN,SAAW0H,gGAeT,OAdMC,EAA+B,MAAhBD,EACrBA,EAAeA,GAAgBE,qBAAqB9d,KAAK+V,MAEpD8H,IAEGE,EACFlN,oBAAoBC,aAAakN,QAAQrN,2BACvCsN,EACgB,MAAlBF,KAA8B5hB,KAAKC,MAAM2hB,IACjC/d,KAAK+V,MAAQ/V,KAAKke,cAC9BrN,oBAAoBC,aAAaqN,QAC7BxN,yBAA0BxU,KAAK6M,UAAUiV,KAE/Cld,QAAQkN,IAAI,mBAAmB2P,MACxB5d,KAAKsS,MAAM8L,KAAKR,SAGnB1H,iBAAN,SAAW0H,uHAIT,GAHMC,EAA+B,MAAhBD,EACrBA,EAAeA,GAAgBE,qBAAqB9d,KAAK+V,OAEpD8H,EAAc,CAIjB,GAAmB,OAFbI,EAAc9hB,KAAKC,MACrByU,oBAAoBC,aAAakN,QAAQrN,6BACQ,MAA1BsN,EAAYje,KAAK+V,MAC1C,MAAM,IAAIvZ,MACN,iDAAiDwD,KAAK+V,UAE5D/V,KAAK+S,MAAQkL,EAAYje,KAAK+V,MAAMhH,WACpChO,QAAQkN,IACJ,oCAAoCjO,KAAK+V,UAAS/V,KAAK+S,OAEhD,OAAb7W,EAAA8D,QAAmBmT,gBAAmByK,kBAAtC1hB,EAAKoW,MAAQrW,SACb8E,QAAQkN,IAAI,qBAAqB2P,OACjC5d,KAAKsS,MAAM+L,oBASbnI,2BAAA,SAAeH,GACb,MAAM,IAAIvZ,MACN,iGApvBJ8U,mCAyvBJ,SAASwM,qBAAqB/H,GAC5B,MAAO,GAAGnF,iBAAmBmF,EAS/B,SAAsBuI,8IACL,SAAMlL,GAAMmL,qBAE3B,IAAW3P,KAFL4P,EAAStiB,SACTwS,KACY8P,EACZ5P,EAAI6P,WAAW7N,mBACjBlC,EAAKtM,KAAKwM,EAAIvS,MAAMuU,iBAAiBtU,SAGzC,SAAOoS,iBAQagQ,yBAAyB3I,mHAY7C,OARmB,OAFfkI,EAAc9hB,KAAKC,MACnByU,oBAAoBC,aAAakN,QAAQrN,8BAE3CsN,MAEuB,MAArBA,EAAYlI,WACPkI,EAAYlI,GAErBlF,oBAAoBC,aAAaqN,QAC7BxN,yBAA0BxU,KAAK6M,UAAUiV,OACvC7K,GAAMuL,YAAYb,qBAAqB/H,mBAA7C7Z,2BCh2Cc0iB,OACZC,EAAmB1N,EACnB2N,EACAC,GAcF,GAZAxe,KAAQC,OACyB,MAA7Bse,GAA4D,MAAvBC,GACJ,MAA7BD,GAA4D,MAAvBC,EACzC,WAAM,MAAA,qFAEuB,MAA7BD,GACFve,KAAQC,OACU,MAAd2Q,EACA,WAAM,MAAA,yEAII,gBAAZ0N,EACF,OAAO,IAAIvN,kCACPH,EAAY2N,EAA2BC,GACtC,KAAgB,aAAZF,EACH,IAAIriB,MACN,kEAEE,IAAIA,MAAM,qBAAqBqiB,OAIzC,IAAMG,OACJza,kDACA5F"}