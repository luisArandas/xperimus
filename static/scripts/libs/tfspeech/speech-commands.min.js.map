{"version":3,"file":"speech-commands.min.js","sources":["../src/browser_fft_utils.ts","../src/browser_fft_extractor.ts","../src/generic_utils.ts","../src/dataset.ts","../src/training_utils.ts","../src/version.ts","../src/browser_fft_recognizer.ts","../src/index.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs';\nimport {promisify} from 'util';\n\nimport {RawAudioData} from './types';\n\nexport async function loadMetadataJson(url: string):\n    Promise<{wordLabels: string[]}> {\n  const HTTP_SCHEME = 'http://';\n  const HTTPS_SCHEME = 'https://';\n  const FILE_SCHEME = 'file://';\n  if (url.indexOf(HTTP_SCHEME) === 0 || url.indexOf(HTTPS_SCHEME) === 0) {\n    const response = await fetch(url);\n    const parsed = await response.json();\n    return parsed;\n  } else if (url.indexOf(FILE_SCHEME) === 0) {\n    // tslint:disable-next-line:no-require-imports\n    const fs = require('fs');\n    const readFile = promisify(fs.readFile);\n\n    return JSON.parse(\n        await readFile(url.slice(FILE_SCHEME.length), {encoding: 'utf-8'}));\n  } else {\n    throw new Error(\n        `Unsupported URL scheme in metadata URL: ${url}. ` +\n        `Supported schemes are: http://, https://, and ` +\n        `(node.js-only) file://`);\n  }\n}\n\nlet EPSILON: number = null;\n\n/**\n * Normalize the input into zero mean and unit standard deviation.\n *\n * This function is safe against divison-by-zero: In case the standard\n * deviation is zero, the output will be all-zero.\n *\n * @param x Input tensor.\n * @param y Output normalized tensor.\n */\nexport function normalize(x: tf.Tensor): tf.Tensor {\n  if (EPSILON == null) {\n    EPSILON = tf.backend().epsilon();\n  }\n  return tf.tidy(() => {\n    const {mean, variance} = tf.moments(x);\n    // Add an EPSILON to the denominator to prevent division-by-zero.\n    return x.sub(mean).div(variance.sqrt().add(EPSILON));\n  });\n}\n\n/**\n * Z-Normalize the elements of a Float32Array.\n *\n * Subtract the mean and divide the result by the standard deviation.\n *\n * @param x The Float32Array to normalize.\n * @return Noramlzied Float32Array.\n */\nexport function normalizeFloat32Array(x: Float32Array): Float32Array {\n  if (x.length < 2) {\n    throw new Error(\n        'Cannot normalize a Float32Array with fewer than 2 elements.');\n  }\n  if (EPSILON == null) {\n    EPSILON = tf.backend().epsilon();\n  }\n  return tf.tidy(() => {\n    const {mean, variance} = tf.moments(tf.tensor1d(x));\n    const meanVal = mean.arraySync() as number;\n    const stdVal = Math.sqrt(variance.arraySync() as number);\n    const yArray = Array.from(x).map(y => (y - meanVal) / (stdVal + EPSILON));\n    return new Float32Array(yArray);\n  });\n}\n\nexport function getAudioContextConstructor(): AudioContext {\n  // tslint:disable-next-line:no-any\n  return (window as any).AudioContext || (window as any).webkitAudioContext;\n}\n\nexport async function getAudioMediaStream(\n    audioTrackConstraints?: MediaTrackConstraints): Promise<MediaStream> {\n  return navigator.mediaDevices.getUserMedia({\n    audio: audioTrackConstraints == null ? true : audioTrackConstraints,\n    video: false\n  });\n}\n\n/**\n * Play raw audio waveform\n * @param rawAudio Raw audio data, including the waveform and the sampling rate.\n * @param onEnded Callback function to execute when the playing ends.\n */\nexport function playRawAudio(\n    rawAudio: RawAudioData, onEnded: () => void|Promise<void>): void {\n  const audioContextConstructor =\n      // tslint:disable-next-line:no-any\n      (window as any).AudioContext || (window as any).webkitAudioContext;\n  const audioContext: AudioContext = new audioContextConstructor();\n  const arrayBuffer =\n      audioContext.createBuffer(1, rawAudio.data.length, rawAudio.sampleRateHz);\n  const nowBuffering = arrayBuffer.getChannelData(0);\n  nowBuffering.set(rawAudio.data);\n  const source = audioContext.createBufferSource();\n  source.buffer = arrayBuffer;\n  source.connect(audioContext.destination);\n  source.start();\n  source.onended = () => {\n    if (onEnded != null) {\n      onEnded();\n    }\n  };\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Audio FFT Feature Extractor based on Browser-Native FFT.\n */\n\nimport * as tf from '@tensorflow/tfjs';\n\nimport {getAudioContextConstructor, getAudioMediaStream} from './browser_fft_utils';\nimport {FeatureExtractor, RecognizerParams} from './types';\n\nexport type SpectrogramCallback = (freqData: tf.Tensor, timeData?: tf.Tensor) =>\n    Promise<boolean>;\n\n/**\n * Configurations for constructing BrowserFftFeatureExtractor.\n */\nexport interface BrowserFftFeatureExtractorConfig extends RecognizerParams {\n  /**\n   * Number of audio frames (i.e., frequency columns) per spectrogram.\n   */\n  numFramesPerSpectrogram: number;\n\n  /**\n   * Suppression period in milliseconds.\n   *\n   * How much time to rest (not call the spectrogramCallback) every time\n   * a word with probability score above threshold is recognized.\n   */\n  suppressionTimeMillis: number;\n\n  /**\n   * A callback that is invoked every time a full spectrogram becomes\n   * available.\n   *\n   * `x` is a single-example tf.Tensor instance that includes the batch\n   * dimension.\n   * The return value is assumed to be whether a flag for whether the\n   * suppression period should initiate, e.g., when a word is recognized.\n   */\n  spectrogramCallback: SpectrogramCallback;\n\n  /**\n   * Truncate each spectrogram column at how many frequency points.\n   *\n   * If `null` or `undefined`, will do no truncation.\n   */\n  columnTruncateLength?: number;\n\n  /**\n   * Overlap factor. Must be >=0 and <1.\n   * For example, if the model takes a frame length of 1000 ms,\n   * and if overlap factor is 0.4, there will be a 400ms\n   * overlap between two successive frames, i.e., frames\n   * will be taken every 600 ms.\n   */\n  overlapFactor: number;\n\n  /**\n   * Whether to collect the raw time-domain audio waveform in addition to the\n   * spectrogram.\n   *\n   * Default: `false`.\n   */\n  includeRawAudio?: boolean;\n}\n\n/**\n * Audio feature extractor based on Browser-native FFT.\n *\n * Uses AudioContext and analyser node.\n */\nexport class BrowserFftFeatureExtractor implements FeatureExtractor {\n  // Number of frames (i.e., columns) per spectrogram used for classification.\n  readonly numFrames: number;\n\n  // Audio sampling rate in Hz.\n  readonly sampleRateHz: number;\n\n  // The FFT length for each spectrogram column.\n  readonly fftSize: number;\n\n  // Truncation length for spectrogram columns.\n  readonly columnTruncateLength: number;\n\n  // Overlapping factor: the ratio between the temporal spacing between\n  // consecutive spectrograms and the length of each individual spectrogram.\n  readonly overlapFactor: number;\n  readonly includeRawAudio: boolean;\n\n  private readonly spectrogramCallback: SpectrogramCallback;\n\n  private stream: MediaStream;\n  // tslint:disable-next-line:no-any\n  private audioContextConstructor: any;\n  private audioContext: AudioContext;\n  private analyser: AnalyserNode;\n  private tracker: Tracker;\n  private freqData: Float32Array;\n  private timeData: Float32Array;\n  private freqDataQueue: Float32Array[];\n  private timeDataQueue: Float32Array[];\n  // tslint:disable-next-line:no-any\n  private frameIntervalTask: any;\n  private frameDurationMillis: number;\n\n  private suppressionTimeMillis: number;\n\n  /**\n   * Constructor of BrowserFftFeatureExtractor.\n   *\n   * @param config Required configuration object.\n   */\n  constructor(config: BrowserFftFeatureExtractorConfig) {\n    if (config == null) {\n      throw new Error(\n          `Required configuration object is missing for ` +\n          `BrowserFftFeatureExtractor constructor`);\n    }\n\n    if (config.spectrogramCallback == null) {\n      throw new Error(`spectrogramCallback cannot be null or undefined`);\n    }\n\n    if (!(config.numFramesPerSpectrogram > 0)) {\n      throw new Error(\n          `Invalid value in numFramesPerSpectrogram: ` +\n          `${config.numFramesPerSpectrogram}`);\n    }\n\n    if (config.suppressionTimeMillis < 0) {\n      throw new Error(\n          `Expected suppressionTimeMillis to be >= 0, ` +\n          `but got ${config.suppressionTimeMillis}`);\n    }\n    this.suppressionTimeMillis = config.suppressionTimeMillis;\n\n    this.spectrogramCallback = config.spectrogramCallback;\n    this.numFrames = config.numFramesPerSpectrogram;\n    this.sampleRateHz = config.sampleRateHz || 44100;\n    this.fftSize = config.fftSize || 1024;\n    this.frameDurationMillis = this.fftSize / this.sampleRateHz * 1e3;\n    this.columnTruncateLength = config.columnTruncateLength || this.fftSize;\n    this.overlapFactor = config.overlapFactor;\n    this.includeRawAudio = config.includeRawAudio;\n\n    tf.util.assert(\n        this.overlapFactor >= 0 && this.overlapFactor < 1,\n        () => `Expected overlapFactor to be >= 0 and < 1, ` +\n            `but got ${this.overlapFactor}`);\n\n    if (this.columnTruncateLength > this.fftSize) {\n      throw new Error(\n          `columnTruncateLength ${this.columnTruncateLength} exceeds ` +\n          `fftSize (${this.fftSize}).`);\n    }\n\n    this.audioContextConstructor = getAudioContextConstructor();\n  }\n\n  async start(audioTrackConstraints?: MediaTrackConstraints):\n      Promise<Float32Array[]|void> {\n    if (this.frameIntervalTask != null) {\n      throw new Error(\n          'Cannot start already-started BrowserFftFeatureExtractor');\n    }\n\n    this.stream = await getAudioMediaStream(audioTrackConstraints);\n\n    this.audioContext = new this.audioContextConstructor() as AudioContext;\n    if (this.audioContext.sampleRate !== this.sampleRateHz) {\n      console.warn(\n          `Mismatch in sampling rate: ` +\n          `Expected: ${this.sampleRateHz}; ` +\n          `Actual: ${this.audioContext.sampleRate}`);\n    }\n    const streamSource = this.audioContext.createMediaStreamSource(this.stream);\n    this.analyser = this.audioContext.createAnalyser();\n    this.analyser.fftSize = this.fftSize * 2;\n    this.analyser.smoothingTimeConstant = 0.0;\n    streamSource.connect(this.analyser);\n    // Reset the queue.\n    this.freqDataQueue = [];\n    this.freqData = new Float32Array(this.fftSize);\n    if (this.includeRawAudio) {\n      this.timeDataQueue = [];\n      this.timeData = new Float32Array(this.fftSize);\n    }\n    const period =\n        Math.max(1, Math.round(this.numFrames * (1 - this.overlapFactor)));\n    this.tracker = new Tracker(\n        period,\n        Math.round(this.suppressionTimeMillis / this.frameDurationMillis));\n    this.frameIntervalTask = setInterval(\n        this.onAudioFrame.bind(this), this.fftSize / this.sampleRateHz * 1e3);\n  }\n\n  private async onAudioFrame() {\n    this.analyser.getFloatFrequencyData(this.freqData);\n    if (this.freqData[0] === -Infinity) {\n      return;\n    }\n\n    this.freqDataQueue.push(this.freqData.slice(0, this.columnTruncateLength));\n    if (this.includeRawAudio) {\n      this.analyser.getFloatTimeDomainData(this.timeData);\n      this.timeDataQueue.push(this.timeData.slice());\n    }\n    if (this.freqDataQueue.length > this.numFrames) {\n      // Drop the oldest frame (least recent).\n      this.freqDataQueue.shift();\n    }\n    const shouldFire = this.tracker.tick();\n    if (shouldFire) {\n      const freqData = flattenQueue(this.freqDataQueue);\n      const freqDataTensor = getInputTensorFromFrequencyData(\n          freqData, [1, this.numFrames, this.columnTruncateLength, 1]);\n      let timeDataTensor: tf.Tensor;\n      if (this.includeRawAudio) {\n        const timeData = flattenQueue(this.timeDataQueue);\n        timeDataTensor = getInputTensorFromFrequencyData(\n            timeData, [1, this.numFrames * this.fftSize]);\n      }\n      const shouldRest =\n          await this.spectrogramCallback(freqDataTensor, timeDataTensor);\n      if (shouldRest) {\n        this.tracker.suppress();\n      }\n      tf.dispose([freqDataTensor, timeDataTensor]);\n    }\n  }\n\n  async stop(): Promise<void> {\n    if (this.frameIntervalTask == null) {\n      throw new Error(\n          'Cannot stop because there is no ongoing streaming activity.');\n    }\n    clearInterval(this.frameIntervalTask);\n    this.frameIntervalTask = null;\n    this.analyser.disconnect();\n    this.audioContext.close();\n    if (this.stream != null && this.stream.getTracks().length > 0) {\n      this.stream.getTracks()[0].stop();\n    }\n  }\n\n  setConfig(params: RecognizerParams) {\n    throw new Error(\n        'setConfig() is not implemented for BrowserFftFeatureExtractor.');\n  }\n\n  getFeatures(): Float32Array[] {\n    throw new Error(\n        'getFeatures() is not implemented for ' +\n        'BrowserFftFeatureExtractor. Use the spectrogramCallback ' +\n        'field of the constructor config instead.');\n  }\n}\n\nexport function flattenQueue(queue: Float32Array[]): Float32Array {\n  const frameSize = queue[0].length;\n  const freqData = new Float32Array(queue.length * frameSize);\n  queue.forEach((data, i) => freqData.set(data, i * frameSize));\n  return freqData;\n}\n\nexport function getInputTensorFromFrequencyData(\n    freqData: Float32Array, shape: number[]): tf.Tensor {\n  const vals = new Float32Array(tf.util.sizeFromShape(shape));\n  // If the data is less than the output shape, the rest is padded with zeros.\n  vals.set(freqData, vals.length - freqData.length);\n  return tf.tensor(vals, shape);\n}\n\n/**\n * A class that manages the firing of events based on periods\n * and suppression time.\n */\nexport class Tracker {\n  readonly period: number;\n  readonly suppressionTime: number;\n\n  private counter: number;\n  private suppressionOnset: number;\n\n  /**\n   * Constructor of Tracker.\n   *\n   * @param period The event-firing period, in number of frames.\n   * @param suppressionPeriod The suppression period, in number of frames.\n   */\n  constructor(period: number, suppressionPeriod: number) {\n    this.period = period;\n    this.suppressionTime = suppressionPeriod == null ? 0 : suppressionPeriod;\n    this.counter = 0;\n\n    tf.util.assert(\n        this.period > 0,\n        () => `Expected period to be positive, but got ${this.period}`);\n  }\n\n  /**\n   * Mark a frame.\n   *\n   * @returns Whether the event should be fired at the current frame.\n   */\n  tick(): boolean {\n    this.counter++;\n    const shouldFire = (this.counter % this.period === 0) &&\n        (this.suppressionOnset == null ||\n         this.counter - this.suppressionOnset > this.suppressionTime);\n    return shouldFire;\n  }\n\n  /**\n   * Order the beginning of a supression period.\n   */\n  suppress() {\n    this.suppressionOnset = this.counter;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers A number of array buffers to concatenate.\n * @returns Result of concatenating `buffers` in order.\n */\nexport function concatenateArrayBuffers(buffers: ArrayBuffer[]): ArrayBuffer {\n  let totalByteLength = 0;\n  buffers.forEach((buffer: ArrayBuffer) => {\n    totalByteLength += buffer.byteLength;\n  });\n\n  const temp = new Uint8Array(totalByteLength);\n  let offset = 0;\n  buffers.forEach((buffer: ArrayBuffer) => {\n    temp.set(new Uint8Array(buffer), offset);\n    offset += buffer.byteLength;\n  });\n  return temp.buffer;\n}\n\n/**\n * Concatenate Float32Arrays.\n *\n * @param xs Float32Arrays to concatenate.\n * @return The result of the concatenation.\n */\nexport function concatenateFloat32Arrays(xs: Float32Array[]): Float32Array {\n  let totalLength = 0;\n  xs.forEach(x => totalLength += x.length);\n  const concatenated = new Float32Array(totalLength);\n  let index = 0;\n  xs.forEach(x => {\n    concatenated.set(x, index);\n    index += x.length;\n  });\n  return concatenated;\n}\n\n/** Encode a string as an ArrayBuffer. */\nexport function string2ArrayBuffer(str: string): ArrayBuffer {\n  if (str == null) {\n    throw new Error('Received null or undefind string');\n  }\n  // NOTE(cais): This implementation is inefficient in terms of memory.\n  // But it works for UTF-8 strings. Just don't use on for very long strings.\n  const strUTF8 = unescape(encodeURIComponent(str));\n  const buf = new Uint8Array(strUTF8.length);\n  for (let i = 0; i < strUTF8.length; ++i) {\n    buf[i] = strUTF8.charCodeAt(i);\n  }\n  return buf.buffer;\n}\n\n/** Decode an ArrayBuffer as a string. */\nexport function arrayBuffer2String(buffer: ArrayBuffer): string {\n  if (buffer == null) {\n    throw new Error('Received null or undefind buffer');\n  }\n  const buf = new Uint8Array(buffer);\n  return decodeURIComponent(escape(String.fromCharCode(...buf)));\n}\n\n/** Generate a pseudo-random UID. */\nexport function getUID(): string {\n  function s4() {\n    return Math.floor((1 + Math.random()) * 0x10000).toString(16).substring(1);\n  }\n  return s4() + s4() + '-' + s4() + '-' + s4() + '-' + s4() + '-' + s4() +\n      s4() + s4();\n}\n\nexport function getRandomInteger(min: number, max: number): number {\n  return Math.floor((max - min) * Math.random()) + min;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs';\nimport {normalize} from './browser_fft_utils';\nimport {arrayBuffer2String, concatenateArrayBuffers, getRandomInteger, getUID, string2ArrayBuffer} from './generic_utils';\nimport {balancedTrainValSplitNumArrays} from './training_utils';\nimport {AudioDataAugmentationOptions, Example, SpectrogramData} from './types';\n\n// Descriptor for serialized dataset files: stands for:\n//   TensorFlow.js Speech-Commands Dataset.\n// DO NOT EVER CHANGE THIS!\nexport const DATASET_SERIALIZATION_DESCRIPTOR = 'TFJSSCDS';\n\n// A version number for the serialization. Since this needs\n// to be encoded within a length-1 Uint8 array, it must be\n//   1. an positive integer.\n//   2. monotonically increasing over its change history.\n// Item 1 is checked by unit tests.\nexport const DATASET_SERIALIZATION_VERSION = 1;\n\n/**\n * Specification for an `Example` (see above).\n *\n * Used for serialization of `Example`.\n */\nexport interface ExampleSpec {\n  /** A label for the example. */\n  label: string;\n\n  /** Number of frames in the spectrogram. */\n  spectrogramNumFrames: number;\n\n  /** The length of each frame in the spectrogram. */\n  spectrogramFrameSize: number;\n\n  /** The key frame index of the spectrogram. */\n  spectrogramKeyFrameIndex?: number;\n\n  /** Number of samples in the raw PCM-format audio (if any). */\n  rawAudioNumSamples?: number;\n\n  /** Sampling rate of the raw audio (if any). */\n  rawAudioSampleRateHz?: number;\n}\n\n/**\n * Serialized Dataset, containing a number of `Example`s in their\n * serialized format.\n *\n * This format consists of a plain-old JSON object as the manifest,\n * along with a flattened binary `ArrayBuffer`. The format facilitates\n * storage and transmission.\n */\nexport interface SerializedExamples {\n  /**\n   * Specifications of the serialized `Example`s, serialized as a string.\n   */\n  manifest: ExampleSpec[];\n\n  /**\n   * Serialized binary data from the `Example`s.\n   *\n   * Including the spectrograms and the raw audio (if any).\n   *\n   * For example, assuming `manifest.length` is `N`, the format of the\n   * `ArrayBuffer` is as follows:\n   *\n   *   [spectrogramData1, rawAudio1 (if any),\n   *    spectrogramData2, rawAudio2 (if any),\n   *    ...\n   *    spectrogramDataN, rawAudioN (if any)]\n   */\n  data: ArrayBuffer;\n}\n\nexport const BACKGROUND_NOISE_TAG = '_background_noise_';\n\n/**\n * Configuration for getting spectrograms as tensors.\n */\nexport interface GetDataConfig extends AudioDataAugmentationOptions {\n  /**\n   * Number of frames.\n   *\n   * This must be smaller than or equal to the # of frames of each\n   * example held by the dataset.\n   *\n   * If the # of frames of an example is greater than this number,\n   * the following heuristics will be used to extra >= 1 examples\n   * of length numFrames from the original example:\n   *\n   *   - If the label of the example is `BAKCGROUND_NOISE_TAG`,\n   *     the example will be splitted into multiple examples using the\n   *     `hopFrames` parameter (see below).\n   *   - If the label of the example is not `BACKGROUND_NOISE_TAG`,\n   *     the example will be splitted into multiple examples that\n   *     all contain the maximum-intensity frame using the `hopFrames`\n   *     parameter.\n   */\n  numFrames?: number;\n\n  /**\n   * Hop length in number of frames.\n   *\n   * Used when splitting a long example into multiple shorter ones.\n   *\n   * Must be provided if any such long examples exist.\n   */\n  hopFrames?: number;\n\n  /**\n   * Whether the spectrogram of each example will be normalized.\n   *\n   * Normalization means:\n   * - Subtracting the mean, and\n   * - Dividing the result by the standard deviation.\n   *\n   * Default: `true`.\n   */\n  normalize?: boolean;\n\n  /**\n   * Whether the examples will be shuffled prior to merged into\n   * `tf.Tensor`s.\n   *\n   * Default: `true`.\n   */\n  shuffle?: boolean;\n\n  /**\n   * Whether to obtain a `tf.data.Datasaet` object.\n   *\n   * Default: `false`.\n   */\n  getDataset?: boolean;\n\n  /**\n   * Batch size for dataset.\n   *\n   * Applicable only if `getDataset === true`.\n   */\n  datasetBatchSize?: number;\n\n  /**\n   * Validation split for the datasaet.\n   *\n   * Applicable only if `getDataset === true`.\n   *\n   * The data will be divided into two fractions of relative sizes\n   * `[1 - datasetValidationSplit, datasetValidationSplit]`, for the\n   * training and validation `tf.data.Dataset` objects, respectively.\n   *\n   * Must be a number between 0 and 1.\n   * Default: 0.15.\n   */\n  datasetValidationSplit?: number;\n}\n\n// tslint:disable-next-line:no-any\nexport type SpectrogramAndTargetsTfDataset = tf.data.Dataset<{}>;\n\n/**\n * A serializable, mutable set of speech/audio `Example`s;\n */\nexport class Dataset {\n  private examples: {[id: string]: Example};\n  private label2Ids: {[label: string]: string[]};\n\n  /**\n   * Constructor of `Dataset`.\n   *\n   * If called with no arguments (i.e., `artifacts` == null), an empty dataset\n   * will be constructed.\n   *\n   * Else, the dataset will be deserialized from `artifacts`.\n   *\n   * @param serialized Optional serialization artifacts to deserialize.\n   */\n  constructor(serialized?: ArrayBuffer) {\n    this.examples = {};\n    this.label2Ids = {};\n    if (serialized != null) {\n      // Deserialize from the provided artifacts.\n      const artifacts = arrayBuffer2SerializedExamples(serialized);\n      let offset = 0;\n      for (let i = 0; i < artifacts.manifest.length; ++i) {\n        const spec = artifacts.manifest[i];\n        let byteLen = spec.spectrogramNumFrames * spec.spectrogramFrameSize;\n        if (spec.rawAudioNumSamples != null) {\n          byteLen += spec.rawAudioNumSamples;\n        }\n        byteLen *= 4;\n        this.addExample(deserializeExample(\n            {spec, data: artifacts.data.slice(offset, offset + byteLen)}));\n        offset += byteLen;\n      }\n    }\n  }\n\n  /**\n   * Add an `Example` to the `Dataset`\n   *\n   * @param example A `Example`, with a label. The label must be a non-empty\n   *   string.\n   * @returns The UID for the added `Example`.\n   */\n  addExample(example: Example): string {\n    tf.util.assert(example != null, () => 'Got null or undefined example');\n    tf.util.assert(\n        example.label != null && example.label.length > 0,\n        () => `Expected label to be a non-empty string, ` +\n            `but got ${JSON.stringify(example.label)}`);\n    const uid = getUID();\n    this.examples[uid] = example;\n    if (!(example.label in this.label2Ids)) {\n      this.label2Ids[example.label] = [];\n    }\n    this.label2Ids[example.label].push(uid);\n    return uid;\n  }\n\n  /**\n   * Merge the incoming dataset into this dataset\n   *\n   * @param dataset The incoming dataset to be merged into this dataset.\n   */\n  merge(dataset: Dataset): void {\n    tf.util.assert(\n        dataset !== this, () => 'Cannot merge a dataset into itself');\n    const vocab = dataset.getVocabulary();\n    for (const word of vocab) {\n      const examples = dataset.getExamples(word);\n      for (const example of examples) {\n        this.addExample(example.example);\n      }\n    }\n  }\n\n  /**\n   * Get a map from `Example` label to number of `Example`s with the label.\n   *\n   * @returns A map from label to number of example counts under that label.\n   */\n  getExampleCounts(): {[label: string]: number} {\n    const counts: {[label: string]: number} = {};\n    for (const uid in this.examples) {\n      const example = this.examples[uid];\n      if (!(example.label in counts)) {\n        counts[example.label] = 0;\n      }\n      counts[example.label]++;\n    }\n    return counts;\n  }\n\n  /**\n   * Get all examples of a given label, with their UIDs.\n   *\n   * @param label The requested label.\n   * @return All examples of the given `label`, along with their UIDs.\n   *   The examples are sorted in the order in which they are added to the\n   *   `Dataset`.\n   * @throws Error if label is `null` or `undefined`.\n   */\n  getExamples(label: string): Array<{uid: string, example: Example}> {\n    tf.util.assert(\n        label != null,\n        () =>\n            `Expected label to be a string, but got ${JSON.stringify(label)}`);\n    tf.util.assert(\n        label in this.label2Ids,\n        () => `No example of label \"${label}\" exists in dataset`);\n    const output: Array<{uid: string, example: Example}> = [];\n    this.label2Ids[label].forEach(id => {\n      output.push({uid: id, example: this.examples[id]});\n    });\n    return output;\n  }\n\n  /**\n   * Get all examples and labels as tensors.\n   *\n   * - If `label` is provided and exists in the vocabulary of the `Dataset`,\n   *   the spectrograms of all `Example`s under the `label` will be returned\n   *   as a 4D `tf.Tensor` as `xs`. The shape of the `tf.Tensor` will be\n   *     `[numExamples, numFrames, frameSize, 1]`\n   *   where\n   *     - `numExamples` is the number of `Example`s with the label\n   *     - `numFrames` is the number of frames in each spectrogram\n   *     - `frameSize` is the size of each spectrogram frame.\n   *   No label Tensor will be returned.\n   * - If `label` is not provided, all `Example`s will be returned as `xs`.\n   *   In addition, `ys` will contain a one-hot encoded list of labels.\n   *   - The shape of `xs` will be: `[numExamples, numFrames, frameSize, 1]`\n   *   - The shape of `ys` will be: `[numExamples, vocabularySize]`.\n   *\n   * @returns If `config.getDataset` is `true`, returns two `tf.data.Dataset`\n   *   objects, one for training and one for validation.\n   *   Else, xs` and `ys` tensors. See description above.\n   * @throws Error\n   *   - if not all the involved spectrograms have matching `numFrames` and\n   *     `frameSize`, or\n   *   - if `label` is provided and is not present in the vocabulary of the\n   *     `Dataset`, or\n   *   - if the `Dataset` is currently empty.\n   */\n  getData(label?: string, config?: GetDataConfig): {\n    xs: tf.Tensor4D,\n    ys?: tf.Tensor2D\n  }|[SpectrogramAndTargetsTfDataset, SpectrogramAndTargetsTfDataset] {\n    tf.util.assert(\n        this.size() > 0,\n        () =>\n            `Cannot get spectrograms as tensors because the dataset is empty`);\n    const vocab = this.getVocabulary();\n    if (label != null) {\n      tf.util.assert(\n          vocab.indexOf(label) !== -1,\n          () => `Label ${label} is not in the vocabulary ` +\n              `(${JSON.stringify(vocab)})`);\n    } else {\n      // If all words are requested, there must be at least two words in the\n      // vocabulary to make one-hot encoding possible.\n      tf.util.assert(\n          vocab.length > 1,\n          () => `One-hot encoding of labels requires the vocabulary to have ` +\n              `at least two words, but it has only ${vocab.length} word.`);\n    }\n\n    if (config == null) {\n      config = {};\n    }\n\n    // Get the numFrames lengths of all the examples currently held by the\n    // dataset.\n    const sortedUniqueNumFrames = this.getSortedUniqueNumFrames();\n    let numFrames: number;\n    let hopFrames: number;\n    if (sortedUniqueNumFrames.length === 1) {\n      numFrames = config.numFrames == null ? sortedUniqueNumFrames[0] :\n                                             config.numFrames;\n      hopFrames = config.hopFrames == null ? 1 : config.hopFrames;\n    } else {\n      numFrames = config.numFrames;\n      tf.util.assert(\n          numFrames != null && Number.isInteger(numFrames) && numFrames > 0,\n          () => `There are ${\n                    sortedUniqueNumFrames.length} unique lengths among ` +\n              `the ${this.size()} examples of this Dataset, hence numFrames ` +\n              `is required. But it is not provided.`);\n      tf.util.assert(\n          numFrames <= sortedUniqueNumFrames[0],\n          () => `numFrames (${numFrames}) exceeds the minimum numFrames ` +\n              `(${sortedUniqueNumFrames[0]}) among the examples of ` +\n              `the Dataset.`);\n\n      hopFrames = config.hopFrames;\n      tf.util.assert(\n          hopFrames != null && Number.isInteger(hopFrames) && hopFrames > 0,\n          () => `There are ${\n                    sortedUniqueNumFrames.length} unique lengths among ` +\n              `the ${this.size()} examples of this Dataset, hence hopFrames ` +\n              `is required. But it is not provided.`);\n    }\n\n    // Normalization is performed by default.\n    const toNormalize = config.normalize == null ? true : config.normalize;\n\n    return tf.tidy(() => {\n      let xTensors: tf.Tensor3D[] = [];\n      let xArrays: Float32Array[] = [];\n\n      let labelIndices: number[] = [];\n      let uniqueFrameSize: number;\n      for (let i = 0; i < vocab.length; ++i) {\n        const currentLabel = vocab[i];\n        if (label != null && currentLabel !== label) {\n          continue;\n        }\n        const ids = this.label2Ids[currentLabel];\n        for (const id of ids) {\n          const example = this.examples[id];\n          const spectrogram = example.spectrogram;\n          const frameSize = spectrogram.frameSize;\n          if (uniqueFrameSize == null) {\n            uniqueFrameSize = frameSize;\n          } else {\n            tf.util.assert(\n                frameSize === uniqueFrameSize,\n                () => `Mismatch in frameSize  ` +\n                    `(${frameSize} vs ${uniqueFrameSize})`);\n          }\n\n          const snippetLength = spectrogram.data.length / frameSize;\n          let focusIndex = null;\n          if (currentLabel !== BACKGROUND_NOISE_TAG) {\n            focusIndex = spectrogram.keyFrameIndex == null ?\n                getMaxIntensityFrameIndex(spectrogram).dataSync()[0] :\n                spectrogram.keyFrameIndex;\n          }\n          // TODO(cais): See if we can get rid of dataSync();\n\n          const snippet =\n              tf.tensor3d(spectrogram.data, [snippetLength, frameSize, 1]);\n          const windows =\n              getValidWindows(snippetLength, focusIndex, numFrames, hopFrames);\n          for (const window of windows) {\n            const windowedSnippet = tf.tidy(() => {\n              const output = snippet.slice(\n                  [window[0], 0, 0], [window[1] - window[0], -1, -1]);\n              return toNormalize ? normalize(output) : output;\n            });\n            if (config.getDataset) {\n              // TODO(cais): See if we can do away with dataSync();\n              // TODO(cais): Shuffling?\n              xArrays.push(windowedSnippet.dataSync() as Float32Array);\n            } else {\n              xTensors.push(windowedSnippet as tf.Tensor3D);\n            }\n            if (label == null) {\n              labelIndices.push(i);\n            }\n          }\n          tf.dispose(snippet);  // For memory saving.\n        }\n      }\n\n      if (config.augmentByMixingNoiseRatio != null) {\n        this.augmentByMixingNoise(\n            config.getDataset ? xArrays :\n                                xTensors as Array<Float32Array|tf.Tensor>,\n            labelIndices, config.augmentByMixingNoiseRatio);\n      }\n\n      const shuffle = config.shuffle == null ? true : config.shuffle;\n      if (config.getDataset) {\n        const batchSize =\n            config.datasetBatchSize == null ? 32 : config.datasetBatchSize;\n\n        // Split the data into two splits: training and validation.\n        const valSplit = config.datasetValidationSplit == null ?\n            0.15 :\n            config.datasetValidationSplit;\n        tf.util.assert(\n            valSplit > 0 && valSplit < 1,\n            () => `Invalid dataset validation split: ${valSplit}`);\n\n        const zippedXandYArrays =\n            xArrays.map((xArray, i) => [xArray, labelIndices[i]]);\n        tf.util.shuffle(\n            zippedXandYArrays);  // Shuffle the data before splitting.\n        xArrays = zippedXandYArrays.map(item => item[0]) as Float32Array[];\n        const yArrays = zippedXandYArrays.map(item => item[1]) as number[];\n        const {trainXs, trainYs, valXs, valYs} =\n            balancedTrainValSplitNumArrays(xArrays, yArrays, valSplit);\n\n        // TODO(cais): The typing around Float32Array is not working properly\n        // for tf.data currently. Tighten the types when the tf.data bug is\n        // fixed.\n        // tslint:disable:no-any\n        const xTrain =\n            tf.data.array(trainXs as any).map(x => tf.tensor3d(x as any, [\n              numFrames, uniqueFrameSize, 1\n            ]));\n        const yTrain = tf.data.array(trainYs).map(\n            y => tf.oneHot([y], vocab.length).squeeze([0]));\n        // TODO(cais): See if we can tighten the typing.\n        let trainDataset = tf.data.zip({xs: xTrain, ys: yTrain});\n        if (shuffle) {\n          // Shuffle the dataset.\n          trainDataset = trainDataset.shuffle(xArrays.length);\n        }\n        trainDataset = trainDataset.batch(batchSize).prefetch(4);\n\n        const xVal =\n            tf.data.array(valXs as any).map(x => tf.tensor3d(x as any, [\n              numFrames, uniqueFrameSize, 1\n            ]));\n        const yVal = tf.data.array(valYs).map(\n            y => tf.oneHot([y], vocab.length).squeeze([0]));\n        let valDataset = tf.data.zip({xs: xVal, ys: yVal});\n        valDataset = valDataset.batch(batchSize).prefetch(4);\n        // tslint:enable:no-any\n\n        // tslint:disable-next-line:no-any\n        return [trainDataset, valDataset] as any;\n      } else {\n        if (shuffle) {\n          // Shuffle the data.\n          const zipped: Array<{x: tf.Tensor3D, y: number}> = [];\n          xTensors.forEach((xTensor, i) => {\n            zipped.push({x: xTensor, y: labelIndices[i]});\n          });\n          tf.util.shuffle(zipped);\n          xTensors = zipped.map(item => item.x);\n          labelIndices = zipped.map(item => item.y);\n        }\n\n        const targets = label == null ?\n            tf.oneHot(tf.tensor1d(labelIndices, 'int32'), vocab.length)\n                .asType('float32') :\n            undefined;\n        return {\n          xs: tf.stack(xTensors) as tf.Tensor4D,\n          ys: targets as tf.Tensor2D\n        };\n      }\n    });\n  }\n\n  private augmentByMixingNoise<T extends tf.Tensor|Float32Array>(\n      xs: T[], labelIndices: number[], ratio: number): void {\n    if (xs == null || xs.length === 0) {\n      throw new Error(\n          `Cannot perform augmentation because data is null or empty`);\n    }\n    const isTypedArray = xs[0] instanceof Float32Array;\n\n    const vocab = this.getVocabulary();\n    const noiseExampleIndices: number[] = [];\n    const wordExampleIndices: number[] = [];\n    for (let i = 0; i < labelIndices.length; ++i) {\n      if (vocab[labelIndices[i]] === BACKGROUND_NOISE_TAG) {\n        noiseExampleIndices.push(i);\n      } else {\n        wordExampleIndices.push(i);\n      }\n    }\n    if (noiseExampleIndices.length === 0) {\n      throw new Error(\n          `Cannot perform augmentation by mixing with noise when ` +\n          `there is no example with label ${BACKGROUND_NOISE_TAG}`);\n    }\n\n    const mixedXTensors: Array<tf.Tensor|Float32Array> = [];\n    const mixedLabelIndices: number[] = [];\n    for (const index of wordExampleIndices) {\n      const noiseIndex =  // Randomly sample from the noises, with replacement.\n          noiseExampleIndices[getRandomInteger(0, noiseExampleIndices.length)];\n      const signalTensor = isTypedArray ?\n          tf.tensor1d(xs[index] as Float32Array) :\n          xs[index] as tf.Tensor;\n      const noiseTensor = isTypedArray ?\n          tf.tensor1d(xs[noiseIndex] as Float32Array) :\n          xs[noiseIndex] as tf.Tensor;\n      const mixed: tf.Tensor =\n          tf.tidy(() => normalize(signalTensor.add(noiseTensor.mul(ratio))));\n      if (isTypedArray) {\n        mixedXTensors.push(mixed.dataSync() as Float32Array);\n      } else {\n        mixedXTensors.push(mixed);\n      }\n      mixedLabelIndices.push(labelIndices[index]);\n    }\n    console.log(\n        `Data augmentation: mixing noise: added ${mixedXTensors.length} ` +\n        `examples`);\n    mixedXTensors.forEach(tensor => xs.push(tensor as T));\n    labelIndices.push(...mixedLabelIndices);\n  }\n\n  private getSortedUniqueNumFrames(): number[] {\n    const numFramesSet = new Set<number>();\n    const vocab = this.getVocabulary();\n    for (let i = 0; i < vocab.length; ++i) {\n      const label = vocab[i];\n      const ids = this.label2Ids[label];\n      for (const id of ids) {\n        const spectrogram = this.examples[id].spectrogram;\n        const numFrames = spectrogram.data.length / spectrogram.frameSize;\n        numFramesSet.add(numFrames);\n      }\n    }\n    const uniqueNumFrames = [...numFramesSet];\n    uniqueNumFrames.sort();\n    return uniqueNumFrames;\n  }\n\n  /**\n   * Remove an example from the `Dataset`.\n   *\n   * @param uid The UID of the example to remove.\n   * @throws Error if the UID doesn't exist in the `Dataset`.\n   */\n  removeExample(uid: string): void {\n    if (!(uid in this.examples)) {\n      throw new Error(`Nonexistent example UID: ${uid}`);\n    }\n    const label = this.examples[uid].label;\n    delete this.examples[uid];\n    const index = this.label2Ids[label].indexOf(uid);\n    this.label2Ids[label].splice(index, 1);\n    if (this.label2Ids[label].length === 0) {\n      delete this.label2Ids[label];\n    }\n  }\n\n  /**\n   * Set the key frame index of a given example.\n   *\n   * @param uid The UID of the example of which the `keyFrameIndex` is to be\n   *   set.\n   * @param keyFrameIndex The desired value of the `keyFrameIndex`. Must\n   *   be >= 0, < the number of frames of the example, and an integer.\n   * @throws Error If the UID and/or the `keyFrameIndex` value is invalid.\n   */\n  setExampleKeyFrameIndex(uid: string, keyFrameIndex: number) {\n    if (!(uid in this.examples)) {\n      throw new Error(`Nonexistent example UID: ${uid}`);\n    }\n    const spectrogram = this.examples[uid].spectrogram;\n    const numFrames = spectrogram.data.length / spectrogram.frameSize;\n    tf.util.assert(\n        keyFrameIndex >= 0 && keyFrameIndex < numFrames &&\n            Number.isInteger(keyFrameIndex),\n        () => `Invalid keyFrameIndex: ${keyFrameIndex}. ` +\n            `Must be >= 0, < ${numFrames}, and an integer.`);\n    spectrogram.keyFrameIndex = keyFrameIndex;\n  }\n\n  /**\n   * Get the total number of `Example` currently held by the `Dataset`.\n   *\n   * @returns Total `Example` count.\n   */\n  size(): number {\n    return Object.keys(this.examples).length;\n  }\n\n  /**\n   * Get the total duration of the `Example` currently held by `Dataset`,\n   *\n   * in milliseconds.\n   *\n   * @return Total duration in milliseconds.\n   */\n  durationMillis(): number {\n    let durMillis = 0;\n    const DEFAULT_FRAME_DUR_MILLIS = 23.22;\n    for (const key in this.examples) {\n      const spectrogram = this.examples[key].spectrogram;\n      const frameDurMillis =\n          spectrogram.frameDurationMillis | DEFAULT_FRAME_DUR_MILLIS;\n      durMillis +=\n          spectrogram.data.length / spectrogram.frameSize * frameDurMillis;\n    }\n    return durMillis;\n  }\n\n  /**\n   * Query whether the `Dataset` is currently empty.\n   *\n   * I.e., holds zero examples.\n   *\n   * @returns Whether the `Dataset` is currently empty.\n   */\n  empty(): boolean {\n    return this.size() === 0;\n  }\n\n  /**\n   * Remove all `Example`s from the `Dataset`.\n   */\n  clear(): void {\n    this.examples = {};\n  }\n\n  /**\n   * Get the list of labels among all `Example`s the `Dataset` currently holds.\n   *\n   * @returns A sorted Array of labels, for the unique labels that belong to all\n   *   `Example`s currently held by the `Dataset`.\n   */\n  getVocabulary(): string[] {\n    const vocab = new Set<string>();\n    for (const uid in this.examples) {\n      const example = this.examples[uid];\n      vocab.add(example.label);\n    }\n    const sortedVocab = [...vocab];\n    sortedVocab.sort();\n    return sortedVocab;\n  }\n\n  /**\n   * Serialize the `Dataset`.\n   *\n   * The `Examples` are sorted in the following order:\n   *   - First, the labels in the vocabulary are sorted.\n   *   - Second, the `Example`s for every label are sorted by the order in\n   *     which they are added to this `Dataset`.\n   *\n   * @param wordLabels Optional word label(s) to serialize. If specified, only\n   *   the examples with labels matching the argument will be serialized. If\n   *   any specified word label does not exist in the vocabulary of this\n   *   dataset, an Error will be thrown.\n   * @returns A `ArrayBuffer` object amenable to transmission and storage.\n   */\n  serialize(wordLabels?: string|string[]): ArrayBuffer {\n    const vocab = this.getVocabulary();\n    tf.util.assert(!this.empty(), () => `Cannot serialize empty Dataset`);\n\n    if (wordLabels != null) {\n      if (!Array.isArray(wordLabels)) {\n        wordLabels = [wordLabels];\n      }\n      wordLabels.forEach(wordLabel => {\n        if (vocab.indexOf(wordLabel) === -1) {\n          throw new Error(\n              `Word label \"${wordLabel}\" does not exist in the ` +\n              `vocabulary of this dataset. The vocabulary is: ` +\n              `${JSON.stringify(vocab)}.`);\n        }\n      });\n    }\n\n    const manifest: ExampleSpec[] = [];\n    const buffers: ArrayBuffer[] = [];\n    for (const label of vocab) {\n      if (wordLabels != null && wordLabels.indexOf(label) === -1) {\n        continue;\n      }\n      const ids = this.label2Ids[label];\n      for (const id of ids) {\n        const artifact = serializeExample(this.examples[id]);\n        manifest.push(artifact.spec);\n        buffers.push(artifact.data);\n      }\n    }\n    return serializedExamples2ArrayBuffer(\n        {manifest, data: concatenateArrayBuffers(buffers)});\n  }\n}\n\n/** Serialize an `Example`. */\nexport function serializeExample(example: Example):\n    {spec: ExampleSpec, data: ArrayBuffer} {\n  const hasRawAudio = example.rawAudio != null;\n  const spec: ExampleSpec = {\n    label: example.label,\n    spectrogramNumFrames:\n        example.spectrogram.data.length / example.spectrogram.frameSize,\n    spectrogramFrameSize: example.spectrogram.frameSize,\n  };\n  if (example.spectrogram.keyFrameIndex != null) {\n    spec.spectrogramKeyFrameIndex = example.spectrogram.keyFrameIndex;\n  }\n\n  let data = example.spectrogram.data.buffer.slice(0);\n  if (hasRawAudio) {\n    spec.rawAudioNumSamples = example.rawAudio.data.length;\n    spec.rawAudioSampleRateHz = example.rawAudio.sampleRateHz;\n\n    // Account for the fact that the data are all float32.\n    data = concatenateArrayBuffers([data, example.rawAudio.data.buffer]);\n  }\n  return {spec, data};\n}\n\n/** Deserialize an `Example`. */\nexport function deserializeExample(\n    artifact: {spec: ExampleSpec, data: ArrayBuffer}): Example {\n  const spectrogram: SpectrogramData = {\n    frameSize: artifact.spec.spectrogramFrameSize,\n    data: new Float32Array(artifact.data.slice(\n        0,\n        4 * artifact.spec.spectrogramFrameSize *\n            artifact.spec.spectrogramNumFrames))\n  };\n  if (artifact.spec.spectrogramKeyFrameIndex != null) {\n    spectrogram.keyFrameIndex = artifact.spec.spectrogramKeyFrameIndex;\n  }\n  const ex: Example = {label: artifact.spec.label, spectrogram};\n  if (artifact.spec.rawAudioNumSamples != null) {\n    ex.rawAudio = {\n      sampleRateHz: artifact.spec.rawAudioSampleRateHz,\n      data: new Float32Array(artifact.data.slice(\n          4 * artifact.spec.spectrogramFrameSize *\n          artifact.spec.spectrogramNumFrames))\n    };\n  }\n  return ex;\n}\n\n/**\n * Encode intermediate serialization format as an ArrayBuffer.\n *\n * Format of the binary ArrayBuffer:\n *   1. An 8-byte descriptor (see above).\n *   2. A 4-byte version number as Uint32.\n *   3. A 4-byte number for the byte length of the JSON manifest.\n *   4. The encoded JSON manifest\n *   5. The binary data of the spectrograms, and raw audio (if any).\n *\n * @param serialized: Intermediate serialization format of a dataset.\n * @returns The binary conversion result as an ArrayBuffer.\n */\nfunction serializedExamples2ArrayBuffer(serialized: SerializedExamples):\n    ArrayBuffer {\n  const manifestBuffer =\n      string2ArrayBuffer(JSON.stringify(serialized.manifest));\n\n  const descriptorBuffer = string2ArrayBuffer(DATASET_SERIALIZATION_DESCRIPTOR);\n  const version = new Uint32Array([DATASET_SERIALIZATION_VERSION]);\n  const manifestLength = new Uint32Array([manifestBuffer.byteLength]);\n  const headerBuffer = concatenateArrayBuffers(\n      [descriptorBuffer, version.buffer, manifestLength.buffer]);\n\n  return concatenateArrayBuffers(\n      [headerBuffer, manifestBuffer, serialized.data]);\n}\n\n/** Decode an ArrayBuffer as intermediate serialization format. */\nexport function arrayBuffer2SerializedExamples(buffer: ArrayBuffer):\n    SerializedExamples {\n  tf.util.assert(buffer != null, () => 'Received null or undefined buffer');\n  // Check descriptor.\n  let offset = 0;\n  const descriptor = arrayBuffer2String(\n      buffer.slice(offset, DATASET_SERIALIZATION_DESCRIPTOR.length));\n  tf.util.assert(\n      descriptor === DATASET_SERIALIZATION_DESCRIPTOR,\n      () => `Deserialization error: Invalid descriptor`);\n  offset += DATASET_SERIALIZATION_DESCRIPTOR.length;\n  // Skip the version part for now. It may be used in the future.\n  offset += 4;\n\n  // Extract the length of the encoded manifest JSON as a Uint32.\n  const manifestLength = new Uint32Array(buffer, offset, 1);\n  offset += 4;\n  const manifestBeginByte = offset;\n  offset = manifestBeginByte + manifestLength[0];\n  const manifestBytes = buffer.slice(manifestBeginByte, offset);\n  const manifestString = arrayBuffer2String(manifestBytes);\n  const manifest = JSON.parse(manifestString);\n  const data = buffer.slice(offset);\n  return {manifest, data};\n}\n\n/**\n * Get valid windows in a long snippet.\n *\n * Each window is represented by an inclusive left index and an exclusive\n * right index.\n *\n * @param snippetLength Long of the entire snippet. Must be a positive\n *   integer.\n * @param focusIndex Optional. If `null` or `undefined`, an array of\n *   evenly-spaced windows will be generated. The array of windows will\n *   start from the first possible location (i.e., [0, windowLength]).\n *   If not `null` or `undefined`, must be an integer >= 0 and < snippetLength.\n * @param windowLength Length of each window. Must be a positive integer and\n *   <= snippetLength.\n * @param windowHop Hops between successsive windows. Must be a positive\n *   integer.\n * @returns An array of [beginIndex, endIndex] pairs.\n */\nexport function getValidWindows(\n    snippetLength: number, focusIndex: number, windowLength: number,\n    windowHop: number): Array<[number, number]> {\n  tf.util.assert(\n      Number.isInteger(snippetLength) && snippetLength > 0,\n      () =>\n          `snippetLength must be a positive integer, but got ${snippetLength}`);\n  if (focusIndex != null) {\n    tf.util.assert(\n        Number.isInteger(focusIndex) && focusIndex >= 0,\n        () =>\n            `focusIndex must be a non-negative integer, but got ${focusIndex}`);\n  }\n  tf.util.assert(\n      Number.isInteger(windowLength) && windowLength > 0,\n      () => `windowLength must be a positive integer, but got ${windowLength}`);\n  tf.util.assert(\n      Number.isInteger(windowHop) && windowHop > 0,\n      () => `windowHop must be a positive integer, but got ${windowHop}`);\n  tf.util.assert(\n      windowLength <= snippetLength,\n      () => `windowLength (${windowLength}) exceeds snippetLength ` +\n          `(${snippetLength})`);\n  tf.util.assert(\n      focusIndex < snippetLength,\n      () => `focusIndex (${focusIndex}) equals or exceeds snippetLength ` +\n          `(${snippetLength})`);\n\n  if (windowLength === snippetLength) {\n    return [[0, snippetLength]];\n  }\n\n  const windows: Array<[number, number]> = [];\n\n  if (focusIndex == null) {\n    // Deal with the special case of no focus frame:\n    // Output an array of evenly-spaced windows, starting from\n    // the first possible location.\n    let begin = 0;\n    while (begin + windowLength <= snippetLength) {\n      windows.push([begin, begin + windowLength]);\n      begin += windowHop;\n    }\n    return windows;\n  }\n\n  const leftHalf = Math.floor(windowLength / 2);\n  let left = focusIndex - leftHalf;\n  if (left < 0) {\n    left = 0;\n  } else if (left + windowLength > snippetLength) {\n    left = snippetLength - windowLength;\n  }\n\n  while (true) {\n    if (left - windowHop < 0 || focusIndex >= left - windowHop + windowLength) {\n      break;\n    }\n    left -= windowHop;\n  }\n\n  while (left + windowLength <= snippetLength) {\n    if (focusIndex < left) {\n      break;\n    }\n    windows.push([left, left + windowLength]);\n    left += windowHop;\n  }\n  return windows;\n}\n\n/**\n * Calculate an intensity profile from a spectrogram.\n *\n * The intensity at each time frame is caclulated by simply averaging all the\n * spectral values that belong to that time frame.\n *\n * @param spectrogram The input spectrogram.\n * @returns The temporal profile of the intensity as a 1D tf.Tensor of shape\n *   `[numFrames]`.\n */\nexport function spectrogram2IntensityCurve(spectrogram: SpectrogramData):\n    tf.Tensor {\n  return tf.tidy(() => {\n    const numFrames = spectrogram.data.length / spectrogram.frameSize;\n    const x = tf.tensor2d(spectrogram.data, [numFrames, spectrogram.frameSize]);\n    return x.mean(-1);\n  });\n}\n\n/**\n * Get the index to the maximum intensity frame.\n *\n * The intensity of each time frame is calculated as the arithmetic mean of\n * all the spectral values belonging to that time frame.\n *\n * @param spectrogram The input spectrogram.\n * @returns The index to the time frame containing the maximum intensity.\n */\nexport function getMaxIntensityFrameIndex(spectrogram: SpectrogramData):\n    tf.Scalar {\n  return tf.tidy(() => spectrogram2IntensityCurve(spectrogram).argMax());\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/**\n * Utility functions for training and transfer learning of the speech-commands\n * model.\n */\n\nimport * as tf from '@tensorflow/tfjs';\n\n/**\n * Split feature and target tensors into train and validation (val) splits.\n *\n * Given sufficent number of examples, the train and val sets will be\n * balanced with respect to the classes.\n *\n * @param xs Features tensor, of shape [numExamples, ...].\n * @param ys Targets tensors, of shape [numExamples, numClasses]. Assumed to be\n *   one-hot categorical encoding.\n * @param valSplit A number > 0 and < 1, fraction of examples to use\n *   as the validation set.\n * @returns trainXs: training features tensor; trainYs: training targets\n *   tensor; valXs: validation features tensor; valYs: validation targets\n *   tensor.\n */\nexport function balancedTrainValSplit(\n    xs: tf.Tensor, ys: tf.Tensor, valSplit: number): {\n  trainXs: tf.Tensor,\n  trainYs: tf.Tensor,\n  valXs: tf.Tensor,\n  valYs: tf.Tensor\n} {\n  tf.util.assert(\n      valSplit > 0 && valSplit < 1,\n      () => `validationSplit is expected to be >0 and <1, ` +\n          `but got ${valSplit}`);\n\n  return tf.tidy(() => {\n    const classIndices = ys.argMax(-1).dataSync();\n\n    const indicesByClasses: number[][] = [];\n    for (let i = 0; i < classIndices.length; ++i) {\n      const classIndex = classIndices[i];\n      if (indicesByClasses[classIndex] == null) {\n        indicesByClasses[classIndex] = [];\n      }\n      indicesByClasses[classIndex].push(i);\n    }\n    const numClasses = indicesByClasses.length;\n\n    const trainIndices: number[] = [];\n    const valIndices: number[] = [];\n\n    // Randomly shuffle the list of indices in each array.\n    indicesByClasses.map(classIndices => tf.util.shuffle(classIndices));\n    for (let i = 0; i < numClasses; ++i) {\n      const classIndices = indicesByClasses[i];\n      const cutoff = Math.round(classIndices.length * (1 - valSplit));\n      for (let j = 0; j < classIndices.length; ++j) {\n        if (j < cutoff) {\n          trainIndices.push(classIndices[j]);\n        } else {\n          valIndices.push(classIndices[j]);\n        }\n      }\n    }\n\n    const trainXs = tf.gather(xs, trainIndices);\n    const trainYs = tf.gather(ys, trainIndices);\n    const valXs = tf.gather(xs, valIndices);\n    const valYs = tf.gather(ys, valIndices);\n    return {trainXs, trainYs, valXs, valYs};\n  });\n}\n\n/**\n * Same as balancedTrainValSplit, but for number arrays or Float32Arrays.\n */\nexport function balancedTrainValSplitNumArrays(\n    xs: number[][]|Float32Array[], ys: number[], valSplit: number): {\n  trainXs: number[][]|Float32Array[],\n  trainYs: number[],\n  valXs: number[][]|Float32Array[],\n  valYs: number[]\n} {\n  tf.util.assert(\n      valSplit > 0 && valSplit < 1,\n      () => `validationSplit is expected to be >0 and <1, ` +\n          `but got ${valSplit}`);\n  const isXsFloat32Array = !Array.isArray(xs[0]);\n\n  const classIndices = ys;\n\n  const indicesByClasses: number[][] = [];\n  for (let i = 0; i < classIndices.length; ++i) {\n    const classIndex = classIndices[i];\n    if (indicesByClasses[classIndex] == null) {\n      indicesByClasses[classIndex] = [];\n    }\n    indicesByClasses[classIndex].push(i);\n  }\n  const numClasses = indicesByClasses.length;\n\n  const trainIndices: number[] = [];\n  const valIndices: number[] = [];\n\n  // Randomly shuffle the list of indices in each array.\n  indicesByClasses.map(classIndices => tf.util.shuffle(classIndices));\n  for (let i = 0; i < numClasses; ++i) {\n    const classIndices = indicesByClasses[i];\n    const cutoff = Math.round(classIndices.length * (1 - valSplit));\n    for (let j = 0; j < classIndices.length; ++j) {\n      if (j < cutoff) {\n        trainIndices.push(classIndices[j]);\n      } else {\n        valIndices.push(classIndices[j]);\n      }\n    }\n  }\n\n  if (isXsFloat32Array) {\n    const trainXs: Float32Array[] = [];\n    const trainYs: number[] = [];\n    const valXs: Float32Array[] = [];\n    const valYs: number[] = [];\n    for (const index of trainIndices) {\n      trainXs.push(xs[index] as Float32Array);\n      trainYs.push(ys[index]);\n    }\n    for (const index of valIndices) {\n      valXs.push(xs[index] as Float32Array);\n      valYs.push(ys[index]);\n    }\n    return {trainXs, trainYs, valXs, valYs};\n  } else {\n    const trainXs: number[][] = [];\n    const trainYs: number[] = [];\n    const valXs: number[][] = [];\n    const valYs: number[] = [];\n    for (const index of trainIndices) {\n      trainXs.push(xs[index] as number[]);\n      trainYs.push(ys[index]);\n    }\n    for (const index of valIndices) {\n      valXs.push(xs[index] as number[]);\n      valYs.push(ys[index]);\n    }\n    return {trainXs, trainYs, valXs, valYs};\n  }\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '0.4.1';\nexport {version};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs';\n\nimport {BrowserFftFeatureExtractor, SpectrogramCallback} from './browser_fft_extractor';\nimport {loadMetadataJson, normalize, normalizeFloat32Array} from './browser_fft_utils';\nimport {BACKGROUND_NOISE_TAG, Dataset} from './dataset';\nimport {concatenateFloat32Arrays} from './generic_utils';\nimport {balancedTrainValSplit} from './training_utils';\nimport {AudioDataAugmentationOptions, EvaluateConfig, EvaluateResult, Example, ExampleCollectionOptions, RecognizeConfig, RecognizerCallback, RecognizerParams, ROCCurve, SpectrogramData, SpeechCommandRecognizer, SpeechCommandRecognizerMetadata, SpeechCommandRecognizerResult, StreamingRecognitionConfig, TransferLearnConfig, TransferSpeechCommandRecognizer} from './types';\nimport {version} from './version';\n\nexport const UNKNOWN_TAG = '_unknown_';\n\n// Key to the local-storage item that holds a map from model name to word\n// list.\nexport const SAVED_MODEL_METADATA_KEY =\n    'tfjs-speech-commands-saved-model-metadata';\nexport const SAVE_PATH_PREFIX = 'indexeddb://tfjs-speech-commands-model/';\n\n// Export a variable for injection during unit testing.\n// tslint:disable-next-line:no-any\nexport let localStorageWrapper = {\n  localStorage: typeof window === 'undefined' ? null : window.localStorage\n};\n\nexport function getMajorAndMinorVersion(version: string) {\n  const versionItems = version.split('.');\n  return versionItems.slice(0, 2).join('.');\n}\n\n/**\n * Default window hop ratio used for extracting multiple\n * windows from a long spectrogram.\n */\nconst DEFAULT_WINDOW_HOP_RATIO = 0.25;\n\n/**\n * Speech-Command Recognizer using browser-native (WebAudio) spectral featutres.\n */\nexport class BrowserFftSpeechCommandRecognizer implements\n    SpeechCommandRecognizer {\n  static readonly VALID_VOCABULARY_NAMES: string[] = ['18w', 'directional4w'];\n  static readonly DEFAULT_VOCABULARY_NAME = '18w';\n\n  readonly MODEL_URL_PREFIX =\n      `https://storage.googleapis.com/tfjs-models/tfjs/speech-commands/v${\n          getMajorAndMinorVersion(version)}/browser_fft`;\n\n  private readonly SAMPLE_RATE_HZ = 44100;\n  private readonly FFT_SIZE = 1024;\n  private readonly DEFAULT_SUPPRESSION_TIME_MILLIS = 0;\n\n  model: tf.LayersModel;\n  modelWithEmbeddingOutput: tf.LayersModel;\n  readonly vocabulary: string;\n  readonly parameters: RecognizerParams;\n  protected words: string[];\n\n  protected streaming = false;\n\n  protected nonBatchInputShape: [number, number, number];\n  private elementsPerExample: number;\n  protected audioDataExtractor: BrowserFftFeatureExtractor;\n\n  private transferRecognizers:\n      {[name: string]: TransferBrowserFftSpeechCommandRecognizer} = {};\n\n  private modelArtifactsOrURL: tf.io.ModelArtifacts|string;\n  private metadataOrURL: SpeechCommandRecognizerMetadata|string;\n\n  // The second-last dense layer in the base model.\n  // To be used for unfreezing during fine-tuning.\n  protected secondLastBaseDenseLayer: tf.layers.Layer;\n\n  /**\n   * Constructor of BrowserFftSpeechCommandRecognizer.\n   *\n   * @param vocabulary An optional vocabulary specifier. Mutually exclusive\n   *   with `modelURL` and `metadataURL`.\n   * @param modelArtifactsOrURL An optional, custom model URL pointing to a\n   *     model.json, or modelArtifacts in the format of `tf.io.ModelArtifacts`.\n   *   file. Supported schemes: http://, https://, and node.js-only: file://.\n   *   Mutually exclusive with `vocabulary`. If provided, `metadatURL`\n   *   most also be provided.\n   * @param metadataOrURL A custom metadata URL pointing to a metadata.json\n   *   file. Or it can be a metadata JSON object itself. Must be provided\n   *   together with `modelArtifactsOrURL`.\n   */\n  constructor(\n      vocabulary?: string, modelArtifactsOrURL?: tf.io.ModelArtifacts|string,\n      metadataOrURL?: SpeechCommandRecognizerMetadata|string) {\n    // TODO(cais): Consolidate the fields into a single config object when\n    // upgrading to v1.0.\n    tf.util.assert(\n        modelArtifactsOrURL == null && metadataOrURL == null ||\n            modelArtifactsOrURL != null && metadataOrURL != null,\n        () => `modelURL and metadataURL must be both provided or ` +\n            `both not provided.`);\n    if (modelArtifactsOrURL == null) {\n      if (vocabulary == null) {\n        vocabulary = BrowserFftSpeechCommandRecognizer.DEFAULT_VOCABULARY_NAME;\n      } else {\n        tf.util.assert(\n            BrowserFftSpeechCommandRecognizer.VALID_VOCABULARY_NAMES.indexOf(\n                vocabulary) !== -1,\n            () => `Invalid vocabulary name: '${vocabulary}'`);\n      }\n      this.vocabulary = vocabulary;\n      this.modelArtifactsOrURL =\n          `${this.MODEL_URL_PREFIX}/${this.vocabulary}/model.json`;\n      this.metadataOrURL =\n          `${this.MODEL_URL_PREFIX}/${this.vocabulary}/metadata.json`;\n    } else {\n      tf.util.assert(\n          vocabulary == null,\n          () => `vocabulary name must be null or undefined when modelURL is ` +\n              `provided`);\n      this.modelArtifactsOrURL = modelArtifactsOrURL;\n      this.metadataOrURL = metadataOrURL;\n    }\n\n    this.parameters = {\n      sampleRateHz: this.SAMPLE_RATE_HZ,\n      fftSize: this.FFT_SIZE\n    };\n  }\n\n  /**\n   * Start streaming recognition.\n   *\n   * To stop the recognition, use `stopListening()`.\n   *\n   * Example: TODO(cais): Add exapmle code snippet.\n   *\n   * @param callback The callback invoked whenever a word is recognized\n   *   with a probability score greater than `config.probabilityThreshold`.\n   *   It has the signature:\n   *     (result: SpeechCommandRecognizerResult) => Promise<void>\n   *   wherein result has the two fields:\n   *   - scores: A Float32Array that contains the probability scores for all\n   *     the words.\n   *   - spectrogram: The spectrogram data, provided only if\n   *     `config.includeSpectrogram` is `true`.\n   * @param config The configurations for the streaming recognition to\n   *   be started.\n   *   The `modelName` field of `config` specifies the model to be used for\n   *   online recognition. If not specified, it defaults to the name of the\n   *   base model ('base'), i.e., the pretrained model not from transfer\n   *   learning. If the recognizer instance has one or more transfer-learning\n   *   models ready (as a result of calls to `collectTransferExample`\n   *   and `trainTransferModel`), you can let this call use that\n   *   model for prediction by specifying the corresponding `modelName`.\n   * @throws Error, if streaming recognition is already started or\n   *   if `config` contains invalid values.\n   */\n  async listen(\n      callback: RecognizerCallback,\n      config?: StreamingRecognitionConfig): Promise<void> {\n    if (this.streaming) {\n      throw new Error(\n          'Cannot start streaming again when streaming is ongoing.');\n    }\n\n    await this.ensureModelLoaded();\n\n    if (config == null) {\n      config = {};\n    }\n    let probabilityThreshold =\n        config.probabilityThreshold == null ? 0 : config.probabilityThreshold;\n    if (config.includeEmbedding) {\n      // Override probability threshold to 0 if includeEmbedding is true.\n      probabilityThreshold = 0;\n    }\n    tf.util.assert(\n        probabilityThreshold >= 0 && probabilityThreshold <= 1,\n        () => `Invalid probabilityThreshold value: ${probabilityThreshold}`);\n    let invokeCallbackOnNoiseAndUnknown =\n        config.invokeCallbackOnNoiseAndUnknown == null ?\n        false :\n        config.invokeCallbackOnNoiseAndUnknown;\n    if (config.includeEmbedding) {\n      // Override invokeCallbackOnNoiseAndUnknown threshold to true if\n      // includeEmbedding is true.\n      invokeCallbackOnNoiseAndUnknown = true;\n    }\n\n    if (config.suppressionTimeMillis < 0) {\n      throw new Error(\n          `suppressionTimeMillis is expected to be >= 0, ` +\n          `but got ${config.suppressionTimeMillis}`);\n    }\n\n    const overlapFactor =\n        config.overlapFactor == null ? 0.5 : config.overlapFactor;\n    tf.util.assert(\n        overlapFactor >= 0 && overlapFactor < 1,\n        () => `Expected overlapFactor to be >= 0 and < 1, but got ${\n            overlapFactor}`);\n\n    const spectrogramCallback: SpectrogramCallback =\n        async (x: tf.Tensor, timeData?: tf.Tensor) => {\n      const normalizedX = normalize(x);\n      let y: tf.Tensor;\n      let embedding: tf.Tensor;\n      if (config.includeEmbedding) {\n        await this.ensureModelWithEmbeddingOutputCreated();\n        [y, embedding] =\n            this.modelWithEmbeddingOutput.predict(normalizedX) as tf.Tensor[];\n      } else {\n        y = this.model.predict(normalizedX) as tf.Tensor;\n      }\n\n      const scores = await y.data() as Float32Array;\n      const maxIndexTensor = y.argMax(-1);\n      const maxIndex = (await maxIndexTensor.data())[0];\n      const maxScore = Math.max(...scores);\n      tf.dispose([y, maxIndexTensor, normalizedX]);\n\n      if (maxScore < probabilityThreshold) {\n        return false;\n      } else {\n        let spectrogram: SpectrogramData = undefined;\n        if (config.includeSpectrogram) {\n          spectrogram = {\n            data: await x.data() as Float32Array,\n            frameSize: this.nonBatchInputShape[1],\n          };\n        }\n\n        let wordDetected = true;\n        if (!invokeCallbackOnNoiseAndUnknown) {\n          // Skip background noise and unknown tokens.\n          if (this.words[maxIndex] === BACKGROUND_NOISE_TAG ||\n              this.words[maxIndex] === UNKNOWN_TAG) {\n            wordDetected = false;\n          }\n        }\n        if (wordDetected) {\n          callback({scores, spectrogram, embedding});\n        }\n        // Trigger suppression only if the word is neither unknown or\n        // background noise.\n        return wordDetected;\n      }\n    };\n\n    const suppressionTimeMillis = config.suppressionTimeMillis == null ?\n        this.DEFAULT_SUPPRESSION_TIME_MILLIS :\n        config.suppressionTimeMillis;\n    this.audioDataExtractor = new BrowserFftFeatureExtractor({\n      sampleRateHz: this.parameters.sampleRateHz,\n      numFramesPerSpectrogram: this.nonBatchInputShape[0],\n      columnTruncateLength: this.nonBatchInputShape[1],\n      suppressionTimeMillis,\n      spectrogramCallback,\n      overlapFactor\n    });\n\n    await this.audioDataExtractor.start(config.audioTrackConstraints);\n\n    this.streaming = true;\n  }\n\n  /**\n   * Load the underlying tf.LayersModel instance and associated metadata.\n   *\n   * If the model and the metadata are already loaded, do nothing.\n   */\n  async ensureModelLoaded() {\n    if (this.model != null) {\n      return;\n    }\n\n    await this.ensureMetadataLoaded();\n\n    let model: tf.LayersModel;\n    if (typeof this.modelArtifactsOrURL === 'string') {\n      model = await tf.loadLayersModel(this.modelArtifactsOrURL);\n    } else {\n      // this.modelArtifactsOrURL is an instance of `tf.io.ModelArtifacts`.\n      model = await tf.loadLayersModel(tf.io.fromMemory(\n          this.modelArtifactsOrURL.modelTopology,\n          this.modelArtifactsOrURL.weightSpecs,\n          this.modelArtifactsOrURL.weightData));\n    }\n\n    // Check the validity of the model's input shape.\n    if (model.inputs.length !== 1) {\n      throw new Error(\n          `Expected model to have 1 input, but got a model with ` +\n          `${model.inputs.length} inputs`);\n    }\n    if (model.inputs[0].shape.length !== 4) {\n      throw new Error(\n          `Expected model to have an input shape of rank 4, ` +\n          `but got an input shape of rank ${model.inputs[0].shape.length}`);\n    }\n    if (model.inputs[0].shape[3] !== 1) {\n      throw new Error(\n          `Expected model to have an input shape with 1 as the last ` +\n          `dimension, but got input shape` +\n          `${JSON.stringify(model.inputs[0].shape[3])}}`);\n    }\n    // Check the consistency between the word labels and the model's output\n    // shape.\n    const outputShape = model.outputShape as tf.Shape;\n    if (outputShape.length !== 2) {\n      throw new Error(\n          `Expected loaded model to have an output shape of rank 2,` +\n          `but received shape ${JSON.stringify(outputShape)}`);\n    }\n    if (outputShape[1] !== this.words.length) {\n      throw new Error(\n          `Mismatch between the last dimension of model's output shape ` +\n          `(${outputShape[1]}) and number of words ` +\n          `(${this.words.length}).`);\n    }\n\n    this.model = model;\n    this.freezeModel();\n\n    this.nonBatchInputShape =\n        model.inputs[0].shape.slice(1) as [number, number, number];\n    this.elementsPerExample = 1;\n    model.inputs[0].shape.slice(1).forEach(\n        dimSize => this.elementsPerExample *= dimSize);\n    this.warmUpModel();\n    const frameDurationMillis =\n        this.parameters.fftSize / this.parameters.sampleRateHz * 1e3;\n    const numFrames = model.inputs[0].shape[1];\n    this.parameters.spectrogramDurationMillis = numFrames * frameDurationMillis;\n  }\n\n  /**\n   * Construct a two-output model that includes the following outputs:\n   *\n   * 1. The same softmax probability output as the original model's output\n   * 2. The embedding, i.e., activation from the second-last dense layer of\n   *    the original model.\n   */\n  protected async ensureModelWithEmbeddingOutputCreated() {\n    if (this.modelWithEmbeddingOutput != null) {\n      return;\n    }\n    await this.ensureModelLoaded();\n\n    // Find the second last dense layer of the original model.\n    let secondLastDenseLayer: tf.layers.Layer;\n    for (let i = this.model.layers.length - 2; i >= 0; --i) {\n      if (this.model.layers[i].getClassName() === 'Dense') {\n        secondLastDenseLayer = this.model.layers[i];\n        break;\n      }\n    }\n    if (secondLastDenseLayer == null) {\n      throw new Error(\n          'Failed to find second last dense layer in the original model.');\n    }\n    this.modelWithEmbeddingOutput = tf.model({\n      inputs: this.model.inputs,\n      outputs: [\n        this.model.outputs[0], secondLastDenseLayer.output as tf.SymbolicTensor\n      ]\n    });\n  }\n\n  private warmUpModel() {\n    tf.tidy(() => {\n      const x = tf.zeros([1].concat(this.nonBatchInputShape));\n      for (let i = 0; i < 3; ++i) {\n        this.model.predict(x);\n      }\n    });\n  }\n\n  private async ensureMetadataLoaded() {\n    if (this.words != null) {\n      return;\n    }\n\n    const metadataJSON = typeof this.metadataOrURL === 'string' ?\n        await loadMetadataJson(this.metadataOrURL) :\n        this.metadataOrURL;\n\n    if (metadataJSON.wordLabels == null) {\n      // In some legacy formats, the field 'words', instead of 'wordLabels',\n      // was populated. This branch ensures backward compatibility with those\n      // formats.\n      // tslint:disable-next-line:no-any\n      const legacyWords = (metadataJSON as any)['words'] as string[];\n      if (legacyWords == null) {\n        throw new Error(\n            'Cannot find field \"words\" or \"wordLabels\" in metadata JSON file');\n      }\n      this.words = legacyWords;\n    } else {\n      this.words = metadataJSON.wordLabels;\n    }\n  }\n\n  /**\n   * Stop streaming recognition.\n   *\n   * @throws Error if there is not ongoing streaming recognition.\n   */\n  async stopListening(): Promise<void> {\n    if (!this.streaming) {\n      throw new Error('Cannot stop streaming when streaming is not ongoing.');\n    }\n    await this.audioDataExtractor.stop();\n    this.streaming = false;\n  }\n\n  /**\n   * Check if streaming recognition is ongoing.\n   */\n  isListening(): boolean {\n    return this.streaming;\n  }\n\n  /**\n   * Get the array of word labels.\n   *\n   * @throws Error If this model is called before the model is loaded.\n   */\n  wordLabels(): string[] {\n    return this.words;\n  }\n\n  /**\n   * Get the parameters of this instance of BrowserFftSpeechCommandRecognizer.\n   *\n   * @returns Parameters of this instance.\n   */\n  params(): RecognizerParams {\n    return this.parameters;\n  }\n\n  /**\n   * Get the input shape of the underlying tf.LayersModel.\n   *\n   * @returns The input shape.\n   */\n  modelInputShape(): tf.Shape {\n    if (this.model == null) {\n      throw new Error(\n          'Model has not been loaded yet. Load model by calling ' +\n          'ensureModelLoaded(), recognize(), or listen().');\n    }\n    return this.model.inputs[0].shape;\n  }\n\n  /**\n   * Run offline (non-streaming) recognition on a spectrogram.\n   *\n   * @param input Spectrogram. Either a `tf.Tensor` of a `Float32Array`.\n   *   - If a `tf.Tensor`, must be rank-4 and match the model's expected\n   *     input shape in 2nd dimension (# of spectrogram columns), the 3rd\n   *     dimension (# of frequency-domain points per column), and the 4th\n   *     dimension (always 1). The 1st dimension can be 1, for single-example\n   *     recogntion, or any value >1, for batched recognition.\n   *   - If a `Float32Array`, must have a length divisible by the number\n   *     of elements per spectrogram, i.e.,\n   *     (# of spectrogram columns) * (# of frequency-domain points per column).\n   * @param config Optional configuration object.\n   * @returns Result of the recognition, with the following field:\n   *   scores:\n   *   - A `Float32Array` if there is only one input exapmle.\n   *   - An `Array` of `Float32Array`, if there are multiple input examples.\n   */\n  async recognize(input?: tf.Tensor|Float32Array, config?: RecognizeConfig):\n      Promise<SpeechCommandRecognizerResult> {\n    if (config == null) {\n      config = {};\n    }\n\n    await this.ensureModelLoaded();\n\n    if (input == null) {\n      // If `input` is not provided, draw audio data from WebAudio and us it\n      // for recognition.\n      const spectrogramData = await this.recognizeOnline();\n      input = spectrogramData.data;\n    }\n\n    let numExamples: number;\n    let inputTensor: tf.Tensor;\n    let outTensor: tf.Tensor;\n    if (input instanceof tf.Tensor) {\n      // Check input shape.\n      this.checkInputTensorShape(input);\n      inputTensor = input;\n      numExamples = input.shape[0];\n    } else {\n      if (input.length % this.elementsPerExample) {\n        throw new Error(\n            `The length of the input Float32Array ${input.length} ` +\n            `is not divisible by the number of tensor elements per ` +\n            `per example expected by the model ${this.elementsPerExample}.`);\n      }\n\n      numExamples = input.length / this.elementsPerExample;\n      inputTensor = tf.tensor4d(input, [\n        numExamples\n      ].concat(this.nonBatchInputShape) as [number, number, number, number]);\n    }\n\n    const output: SpeechCommandRecognizerResult = {scores: null};\n    if (config.includeEmbedding) {\n      // Optional inclusion of embedding (internal activation).\n      await this.ensureModelWithEmbeddingOutputCreated();\n      const outAndEmbedding =\n          this.modelWithEmbeddingOutput.predict(inputTensor) as tf.Tensor[];\n      outTensor = outAndEmbedding[0];\n      output.embedding = outAndEmbedding[1];\n    } else {\n      outTensor = this.model.predict(inputTensor) as tf.Tensor;\n    }\n\n    if (numExamples === 1) {\n      output.scores = await outTensor.data() as Float32Array;\n    } else {\n      const unstacked = tf.unstack(outTensor);\n      const scorePromises = unstacked.map(item => item.data());\n      output.scores = await Promise.all(scorePromises) as Float32Array[];\n      tf.dispose(unstacked);\n    }\n\n    if (config.includeSpectrogram) {\n      output.spectrogram = {\n        data: (input instanceof tf.Tensor ? await input.data() : input) as\n            Float32Array,\n        frameSize: this.nonBatchInputShape[1],\n      };\n    }\n\n    tf.dispose(outTensor);\n    return output;\n  }\n\n  private async recognizeOnline(): Promise<SpectrogramData> {\n    return new Promise<SpectrogramData>((resolve, reject) => {\n      const spectrogramCallback: SpectrogramCallback = async (x: tf.Tensor) => {\n        const normalizedX = normalize(x);\n        await this.audioDataExtractor.stop();\n        resolve({\n          data: await normalizedX.data() as Float32Array,\n          frameSize: this.nonBatchInputShape[1],\n        });\n        normalizedX.dispose();\n        return false;\n      };\n      this.audioDataExtractor = new BrowserFftFeatureExtractor({\n        sampleRateHz: this.parameters.sampleRateHz,\n        numFramesPerSpectrogram: this.nonBatchInputShape[0],\n        columnTruncateLength: this.nonBatchInputShape[1],\n        suppressionTimeMillis: 0,\n        spectrogramCallback,\n        overlapFactor: 0\n      });\n      this.audioDataExtractor.start();\n    });\n  }\n\n  createTransfer(name: string): TransferSpeechCommandRecognizer {\n    if (this.model == null) {\n      throw new Error(\n          'Model has not been loaded yet. Load model by calling ' +\n          'ensureModelLoaded(), recognizer(), or listen().');\n    }\n    tf.util.assert(\n        name != null && typeof name === 'string' && name.length > 1,\n        () => `Expected the name for a transfer-learning recognized to be a ` +\n            `non-empty string, but got ${JSON.stringify(name)}`);\n    tf.util.assert(\n        this.transferRecognizers[name] == null,\n        () => `There is already a transfer-learning model named '${name}'`);\n    const transfer = new TransferBrowserFftSpeechCommandRecognizer(\n        name, this.parameters, this.model);\n    this.transferRecognizers[name] = transfer;\n    return transfer;\n  }\n\n  protected freezeModel(): void {\n    for (const layer of this.model.layers) {\n      layer.trainable = false;\n    }\n  }\n\n  private checkInputTensorShape(input: tf.Tensor) {\n    const expectedRank = this.model.inputs[0].shape.length;\n    if (input.shape.length !== expectedRank) {\n      throw new Error(\n          `Expected input Tensor to have rank ${expectedRank}, ` +\n          `but got rank ${input.shape.length} that differs `);\n    }\n    const nonBatchedShape = input.shape.slice(1);\n    const expectedNonBatchShape = this.model.inputs[0].shape.slice(1);\n    if (!tf.util.arraysEqual(nonBatchedShape, expectedNonBatchShape)) {\n      throw new Error(\n          `Expected input to have shape [null,${expectedNonBatchShape}], ` +\n          `but got shape [null,${nonBatchedShape}]`);\n    }\n  }\n}\n\n/**\n * A subclass of BrowserFftSpeechCommandRecognizer: Transfer-learned model.\n */\nclass TransferBrowserFftSpeechCommandRecognizer extends\n    BrowserFftSpeechCommandRecognizer implements\n        TransferSpeechCommandRecognizer {\n  private dataset: Dataset;\n  private transferHead: tf.Sequential;\n\n  /**\n   * Constructor of TransferBrowserFftSpeechCommandRecognizer.\n   *\n   * @param name Name of the transfer-learned recognizer. Must be a non-empty\n   *   string.\n   * @param parameters Parameters from the base recognizer.\n   * @param baseModel Model from the base recognizer.\n   */\n  constructor(\n      readonly name: string, readonly parameters: RecognizerParams,\n      readonly baseModel: tf.LayersModel) {\n    super();\n    tf.util.assert(\n        name != null && typeof name === 'string' && name.length > 0,\n        () => `The name of a transfer model must be a non-empty string, ` +\n            `but got ${JSON.stringify(name)}`);\n    this.nonBatchInputShape =\n        this.baseModel.inputs[0].shape.slice(1) as [number, number, number];\n    this.words = null;\n    this.dataset = new Dataset();\n  }\n\n  /**\n   * Collect an example for transfer learning via WebAudio.\n   *\n   * @param {string} word Name of the word. Must not overlap with any of the\n   *   words the base model is trained to recognize.\n   * @param {ExampleCollectionOptions}\n   * @returns {SpectrogramData} The spectrogram of the acquired the example.\n   * @throws Error, if word belongs to the set of words the base model is\n   *   trained to recognize.\n   */\n  async collectExample(word: string, options?: ExampleCollectionOptions):\n      Promise<SpectrogramData> {\n    tf.util.assert(\n        !this.streaming,\n        () => 'Cannot start collection of transfer-learning example because ' +\n            'a streaming recognition or transfer-learning example collection ' +\n            'is ongoing');\n    tf.util.assert(\n        word != null && typeof word === 'string' && word.length > 0,\n        () => `Must provide a non-empty string when collecting transfer-` +\n            `learning example`);\n\n    if (options == null) {\n      options = {};\n    }\n    if (options.durationMultiplier != null && options.durationSec != null) {\n      throw new Error(\n          `durationMultiplier and durationSec are mutually exclusive, ` +\n          `but are both specified.`);\n    }\n\n    let numFramesPerSpectrogram: number;\n    if (options.durationSec != null) {\n      tf.util.assert(\n          options.durationSec > 0,\n          () =>\n              `Expected durationSec to be > 0, but got ${options.durationSec}`);\n      const frameDurationSec =\n          this.parameters.fftSize / this.parameters.sampleRateHz;\n      numFramesPerSpectrogram =\n          Math.ceil(options.durationSec / frameDurationSec);\n    } else if (options.durationMultiplier != null) {\n      tf.util.assert(\n          options.durationMultiplier >= 1,\n          () => `Expected duration multiplier to be >= 1, ` +\n              `but got ${options.durationMultiplier}`);\n      numFramesPerSpectrogram =\n          Math.round(this.nonBatchInputShape[0] * options.durationMultiplier);\n    } else {\n      numFramesPerSpectrogram = this.nonBatchInputShape[0];\n    }\n\n    if (options.snippetDurationSec != null) {\n      tf.util.assert(\n          options.snippetDurationSec > 0,\n          () => `snippetDurationSec is expected to be > 0, but got ` +\n              `${options.snippetDurationSec}`);\n      tf.util.assert(\n          options.onSnippet != null,\n          () => `onSnippet must be provided if snippetDurationSec ` +\n              `is provided.`);\n    }\n    if (options.onSnippet != null) {\n      tf.util.assert(\n          options.snippetDurationSec != null,\n          () => `snippetDurationSec must be provided if onSnippet ` +\n              `is provided.`);\n    }\n    const frameDurationSec =\n        this.parameters.fftSize / this.parameters.sampleRateHz;\n    const totalDurationSec = frameDurationSec * numFramesPerSpectrogram;\n\n    this.streaming = true;\n    return new Promise<SpectrogramData>(resolve => {\n      const stepFactor = options.snippetDurationSec == null ?\n          1 :\n          options.snippetDurationSec / totalDurationSec;\n      const overlapFactor = 1 - stepFactor;\n      const callbackCountTarget = Math.round(1 / stepFactor);\n      let callbackCount = 0;\n      let lastIndex = -1;\n      const spectrogramSnippets: Float32Array[] = [];\n\n      const spectrogramCallback: SpectrogramCallback =\n          async (freqData: tf.Tensor, timeData?: tf.Tensor) => {\n        // TODO(cais): can we consolidate the logic in the two branches?\n        if (options.onSnippet == null) {\n          const normalizedX = normalize(freqData);\n          this.dataset.addExample({\n            label: word,\n            spectrogram: {\n              data: await normalizedX.data() as Float32Array,\n              frameSize: this.nonBatchInputShape[1],\n            },\n            rawAudio: options.includeRawAudio ? {\n              data: await timeData.data() as Float32Array,\n              sampleRateHz: this.audioDataExtractor.sampleRateHz\n            } :\n                                                undefined\n          });\n          normalizedX.dispose();\n          await this.audioDataExtractor.stop();\n          this.streaming = false;\n          this.collateTransferWords();\n          resolve({\n            data: await freqData.data() as Float32Array,\n            frameSize: this.nonBatchInputShape[1],\n          });\n        } else {\n          const data = await freqData.data() as Float32Array;\n          if (lastIndex === -1) {\n            lastIndex = data.length;\n          }\n          let i = lastIndex - 1;\n          while (data[i] !== 0 && i >= 0) {\n            i--;\n          }\n          const increment = lastIndex - i - 1;\n          lastIndex = i + 1;\n          const snippetData = data.slice(data.length - increment, data.length);\n          spectrogramSnippets.push(snippetData);\n\n          if (options.onSnippet != null) {\n            options.onSnippet(\n                {data: snippetData, frameSize: this.nonBatchInputShape[1]});\n          }\n\n          if (callbackCount++ === callbackCountTarget) {\n            await this.audioDataExtractor.stop();\n            this.streaming = false;\n            this.collateTransferWords();\n\n            const normalized = normalizeFloat32Array(\n                concatenateFloat32Arrays(spectrogramSnippets));\n            const finalSpectrogram: SpectrogramData = {\n              data: normalized,\n              frameSize: this.nonBatchInputShape[1]\n            };\n            this.dataset.addExample({\n              label: word,\n              spectrogram: finalSpectrogram,\n              rawAudio: options.includeRawAudio ? {\n                data: await timeData.data() as Float32Array,\n                sampleRateHz: this.audioDataExtractor.sampleRateHz\n              } :\n                                                  undefined\n            });\n            // TODO(cais): Fix 1-tensor memory leak.\n            resolve(finalSpectrogram);\n          }\n        }\n        return false;\n      };\n      this.audioDataExtractor = new BrowserFftFeatureExtractor({\n        sampleRateHz: this.parameters.sampleRateHz,\n        numFramesPerSpectrogram,\n        columnTruncateLength: this.nonBatchInputShape[1],\n        suppressionTimeMillis: 0,\n        spectrogramCallback,\n        overlapFactor,\n        includeRawAudio: options.includeRawAudio\n      });\n      this.audioDataExtractor.start(options.audioTrackConstraints);\n    });\n  }\n\n  /**\n   * Clear all transfer learning examples collected so far.\n   */\n  clearExamples(): void {\n    tf.util.assert(\n        this.words != null && this.words.length > 0 && !this.dataset.empty(),\n        () =>\n            `No transfer learning examples exist for model name ${this.name}`);\n    this.dataset.clear();\n    this.words = null;\n  }\n\n  /**\n   * Get counts of the word examples that have been collected for a\n   * transfer-learning model.\n   *\n   * @returns {{[word: string]: number}} A map from word name to number of\n   *   examples collected for that word so far.\n   */\n  countExamples(): {[word: string]: number} {\n    if (this.dataset.empty()) {\n      throw new Error(\n          `No examples have been collected for transfer-learning model ` +\n          `named '${this.name}' yet.`);\n    }\n    return this.dataset.getExampleCounts();\n  }\n\n  /**\n   * Get examples currently held by the transfer-learning recognizer.\n   *\n   * @param label Label requested.\n   * @returns An array of `Example`s, along with their UIDs.\n   */\n  getExamples(label: string): Array<{uid: string, example: Example}> {\n    return this.dataset.getExamples(label);\n  }\n\n  /** Set the key frame index of a given example. */\n  setExampleKeyFrameIndex(uid: string, keyFrameIndex: number): void {\n    this.dataset.setExampleKeyFrameIndex(uid, keyFrameIndex);\n  }\n\n  /**\n   * Remove an example from the current dataset.\n   *\n   * @param uid The UID of the example to remove.\n   */\n  removeExample(uid: string): void {\n    this.dataset.removeExample(uid);\n    this.collateTransferWords();\n  }\n\n  /**\n   * Check whether the underlying dataset is empty.\n   *\n   * @returns A boolean indicating whether the underlying dataset is empty.\n   */\n  isDatasetEmpty(): boolean {\n    return this.dataset.empty();\n  }\n\n  /**\n   * Load an array of serialized examples.\n   *\n   * @param serialized The examples in their serialized format.\n   * @param clearExisting Whether to clear the existing examples while\n   *   performing the loading (default: false).\n   */\n  loadExamples(serialized: ArrayBuffer, clearExisting = false): void {\n    const incomingDataset = new Dataset(serialized);\n    if (clearExisting) {\n      this.clearExamples();\n    }\n\n    const incomingVocab = incomingDataset.getVocabulary();\n    for (const label of incomingVocab) {\n      const examples = incomingDataset.getExamples(label);\n      for (const example of examples) {\n        this.dataset.addExample(example.example);\n      }\n    }\n\n    this.collateTransferWords();\n  }\n\n  /**\n   * Serialize the existing examples.\n   *\n   * @param wordLabels Optional word label(s) to serialize. If specified, only\n   *   the examples with labels matching the argument will be serialized. If\n   *   any specified word label does not exist in the vocabulary of this\n   *   transfer recognizer, an Error will be thrown.\n   * @returns An `ArrayBuffer` object amenable to transmission and storage.\n   */\n  serializeExamples(wordLabels?: string|string[]): ArrayBuffer {\n    return this.dataset.serialize(wordLabels);\n  }\n\n  /**\n   * Collect the vocabulary of this transfer-learned recognizer.\n   *\n   * The words are put in an alphabetically sorted order.\n   */\n  private collateTransferWords() {\n    this.words = this.dataset.getVocabulary();\n  }\n\n  /**\n   * Collect the transfer-learning data as `tf.Tensor`s.\n   *\n   * Used for training and evaluation when the amount of data is relatively\n   * small.\n   *\n   * @param windowHopRatio Ratio betwen hop length in number of frames and the\n   *   number of frames in a long spectrogram. Used during extraction\n   *   of multiple windows from the long spectrogram.\n   * @returns xs: The feature tensors (xs), a 4D tf.Tensor.\n   *          ys: The target tensors (ys), one-hot encoding, a 2D tf.Tensor.\n   */\n  private collectTransferDataAsTensors(\n      windowHopRatio?: number,\n      augmentationOptions?: AudioDataAugmentationOptions):\n      {xs: tf.Tensor, ys: tf.Tensor} {\n    const numFrames = this.nonBatchInputShape[0];\n    windowHopRatio = windowHopRatio || DEFAULT_WINDOW_HOP_RATIO;\n    const hopFrames = Math.round(windowHopRatio * numFrames);\n    const out = this.dataset.getData(\n                    null, {numFrames, hopFrames, ...augmentationOptions}) as\n        {xs: tf.Tensor4D, ys?: tf.Tensor2D};\n    return {xs: out.xs, ys: out.ys as tf.Tensor};\n  }\n\n  /**\n   * Same as `collectTransferDataAsTensors`, but returns `tf.data.Dataset`s.\n   *\n   * Used for training and evaluation when the amount of data is large.\n   *\n   * @param windowHopRatio Ratio betwen hop length in number of frames and the\n   *   number of frames in a long spectrogram. Used during extraction\n   *   of multiple windows from the long spectrogram.\n   * @param validationSplit The validation split to be used for splitting\n   *   the raw data between the `tf.data.Dataset` objects for training and\n   *   validation.\n   * @param batchSize Batch size used for the `tf.data.Dataset.batch()` call\n   *   during the creation of the dataset objects.\n   * @return Two `tf.data.Dataset` objects, one for training and one for\n   *   validation. Each of the objects may be directly fed into\n   *   `this.model.fitDataset`.\n   */\n  private collectTransferDataAsTfDataset(\n      windowHopRatio?: number, validationSplit = 0.15, batchSize = 32,\n      augmentationOptions?: AudioDataAugmentationOptions):\n      [tf.data.Dataset<{}>, tf.data.Dataset<{}>] {\n    const numFrames = this.nonBatchInputShape[0];\n    windowHopRatio = windowHopRatio || DEFAULT_WINDOW_HOP_RATIO;\n    const hopFrames = Math.round(windowHopRatio * numFrames);\n    return this.dataset.getData(null, {\n      numFrames,\n      hopFrames,\n      getDataset: true,\n      datasetBatchSize: batchSize,\n      datasetValidationSplit: validationSplit,\n      ...augmentationOptions\n    }) as [tf.data.Dataset<{}>, tf.data.Dataset<{}>];\n    // TODO(cais): See if we can tighten the typing.\n  }\n\n  /**\n   * Train the transfer-learning model.\n   *\n   * The last dense layer of the base model is replaced with new softmax dense\n   * layer.\n   *\n   * It is assume that at least one category of data has been collected (using\n   * multiple calls to the `collectTransferExample` method).\n   *\n   * @param config {TransferLearnConfig} Optional configurations fot the\n   *   training of the transfer-learning model.\n   * @returns {tf.History} A history object with the loss and accuracy values\n   *   from the training of the transfer-learning model.\n   * @throws Error, if `modelName` is invalid or if not sufficient training\n   *   examples have been collected yet.\n   */\n  async train(config?: TransferLearnConfig):\n      Promise<tf.History|[tf.History, tf.History]> {\n    tf.util.assert(\n        this.words != null && this.words.length > 0,\n        () =>\n            `Cannot train transfer-learning model '${this.name}' because no ` +\n            `transfer learning example has been collected.`);\n    tf.util.assert(\n        this.words.length > 1,\n        () => `Cannot train transfer-learning model '${\n                  this.name}' because only ` +\n            `1 word label ('${JSON.stringify(this.words)}') ` +\n            `has been collected for transfer learning. Requires at least 2.`);\n    if (config.fineTuningEpochs != null) {\n      tf.util.assert(\n          config.fineTuningEpochs >= 0 &&\n              Number.isInteger(config.fineTuningEpochs),\n          () => `If specified, fineTuningEpochs must be a non-negative ` +\n              `integer, but received ${config.fineTuningEpochs}`);\n    }\n\n    if (config == null) {\n      config = {};\n    }\n\n    if (this.model == null) {\n      this.createTransferModelFromBaseModel();\n    }\n\n    // This layer needs to be frozen for the initial phase of the\n    // transfer learning. During subsequent fine-tuning (if any), it will\n    // be unfrozen.\n    this.secondLastBaseDenseLayer.trainable = false;\n\n    // Compile model for training.\n    this.model.compile({\n      loss: 'categoricalCrossentropy',\n      optimizer: config.optimizer || 'sgd',\n      metrics: ['acc']\n    });\n\n    // Use `tf.data.Dataset` objects for training of the total duration of\n    // the recordings exceeds 60 seconds. Otherwise, use `tf.Tensor` objects.\n    const datasetDurationMillisThreshold =\n        config.fitDatasetDurationMillisThreshold == null ?\n        60e3 :\n        config.fitDatasetDurationMillisThreshold;\n    if (this.dataset.durationMillis() > datasetDurationMillisThreshold) {\n      console.log(\n          `Detected large dataset: total duration = ` +\n          `${this.dataset.durationMillis()} ms > ` +\n          `${datasetDurationMillisThreshold} ms. ` +\n          `Training transfer model using fitDataset() instead of fit()`);\n      return this.trainOnDataset(config);\n    } else {\n      return this.trainOnTensors(config);\n    }\n  }\n\n  /** Helper function for training on tf.data.Dataset objects. */\n  private async trainOnDataset(config?: TransferLearnConfig):\n      Promise<tf.History|[tf.History, tf.History]> {\n    tf.util.assert(config.epochs > 0, () => `Invalid config.epochs`);\n    // Train transfer-learning model using fitDataset\n\n    const batchSize = config.batchSize == null ? 32 : config.batchSize;\n    const windowHopRatio = config.windowHopRatio || DEFAULT_WINDOW_HOP_RATIO;\n    const [trainDataset, valDataset] = this.collectTransferDataAsTfDataset(\n        windowHopRatio, config.validationSplit, batchSize,\n        {augmentByMixingNoiseRatio: config.augmentByMixingNoiseRatio});\n    const t0 = tf.util.now();\n    const history = await this.model.fitDataset(trainDataset, {\n      epochs: config.epochs,\n      validationData: config.validationSplit > 0 ? valDataset : null,\n      callbacks: config.callback == null ? null : [config.callback]\n    });\n    console.log(`fitDataset() took ${(tf.util.now() - t0).toFixed(2)} ms`);\n\n    if (config.fineTuningEpochs != null && config.fineTuningEpochs > 0) {\n      // Perform fine-tuning.\n      const t0 = tf.util.now();\n      const fineTuningHistory = await this.fineTuningUsingTfDatasets(\n          config, trainDataset, valDataset);\n      console.log(\n          `fitDataset() (fine-tuning) took ` +\n          `${(tf.util.now() - t0).toFixed(2)} ms`);\n      return [history, fineTuningHistory];\n    } else {\n      return history;\n    }\n  }\n\n  /** Helper function for training on tf.Tensor objects. */\n  private async trainOnTensors(config?: TransferLearnConfig):\n      Promise<tf.History|[tf.History, tf.History]> {\n    // Prepare the data.\n    const windowHopRatio = config.windowHopRatio || DEFAULT_WINDOW_HOP_RATIO;\n    const {xs, ys} = this.collectTransferDataAsTensors(\n        windowHopRatio,\n        {augmentByMixingNoiseRatio: config.augmentByMixingNoiseRatio});\n    console.log(\n        `Training data: xs.shape = ${xs.shape}, ys.shape = ${ys.shape}`);\n\n    let trainXs: tf.Tensor;\n    let trainYs: tf.Tensor;\n    let valData: [tf.Tensor, tf.Tensor];\n    try {\n      // TODO(cais): The balanced split may need to be pushed down to the\n      //   level of the Dataset class to avoid leaks between train and val\n      //   splits.\n      if (config.validationSplit != null) {\n        const splits = balancedTrainValSplit(xs, ys, config.validationSplit);\n        trainXs = splits.trainXs;\n        trainYs = splits.trainYs;\n        valData = [splits.valXs, splits.valYs];\n      } else {\n        trainXs = xs;\n        trainYs = ys;\n      }\n\n      const history = await this.model.fit(trainXs, trainYs, {\n        epochs: config.epochs == null ? 20 : config.epochs,\n        validationData: valData,\n        batchSize: config.batchSize,\n        callbacks: config.callback == null ? null : [config.callback]\n      });\n\n      if (config.fineTuningEpochs != null && config.fineTuningEpochs > 0) {\n        // Fine tuning: unfreeze the second-last dense layer of the base\n        // model.\n        const fineTuningHistory = await this.fineTuningUsingTensors(\n            config, trainXs, trainYs, valData);\n        return [history, fineTuningHistory];\n      } else {\n        return history;\n      }\n    } finally {\n      tf.dispose([xs, ys, trainXs, trainYs, valData]);\n    }\n  }\n\n  private async fineTuningUsingTfDatasets(\n      config: TransferLearnConfig, trainDataset: tf.data.Dataset<{}>,\n      valDataset: tf.data.Dataset<{}>): Promise<tf.History> {\n    const originalTrainableValue = this.secondLastBaseDenseLayer.trainable;\n    this.secondLastBaseDenseLayer.trainable = true;\n\n    // Recompile model after unfreezing layer.\n    const fineTuningOptimizer: string|tf.Optimizer =\n        config.fineTuningOptimizer == null ? 'sgd' : config.fineTuningOptimizer;\n    this.model.compile({\n      loss: 'categoricalCrossentropy',\n      optimizer: fineTuningOptimizer,\n      metrics: ['acc']\n    });\n\n    const fineTuningHistory = await this.model.fitDataset(trainDataset, {\n      epochs: config.fineTuningEpochs,\n      validationData: valDataset,\n      callbacks: config.callback == null ? null : [config.callback]\n    });\n    // Set the trainable attribute of the fine-tuning layer to its\n    // previous value.\n    this.secondLastBaseDenseLayer.trainable = originalTrainableValue;\n    return fineTuningHistory;\n  }\n\n  private async fineTuningUsingTensors(\n      config: TransferLearnConfig, trainXs: tf.Tensor, trainYs: tf.Tensor,\n      valData: [tf.Tensor, tf.Tensor]): Promise<tf.History> {\n    const originalTrainableValue = this.secondLastBaseDenseLayer.trainable;\n    this.secondLastBaseDenseLayer.trainable = true;\n\n    // Recompile model after unfreezing layer.\n    const fineTuningOptimizer: string|tf.Optimizer =\n        config.fineTuningOptimizer == null ? 'sgd' : config.fineTuningOptimizer;\n    this.model.compile({\n      loss: 'categoricalCrossentropy',\n      optimizer: fineTuningOptimizer,\n      metrics: ['acc']\n    });\n\n    const fineTuningHistory = await this.model.fit(trainXs, trainYs, {\n      epochs: config.fineTuningEpochs,\n      validationData: valData,\n      batchSize: config.batchSize,\n      callbacks: config.fineTuningCallback == null ? null :\n                                                     [config.fineTuningCallback]\n    });\n    // Set the trainable attribute of the fine-tuning layer to its\n    // previous value.\n    this.secondLastBaseDenseLayer.trainable = originalTrainableValue;\n    return fineTuningHistory;\n  }\n\n  /**\n   * Perform evaluation of the model using the examples that the model\n   * has loaded.\n   *\n   * @param config Configuration object for the evaluation.\n   * @returns A Promise of the result of evaluation.\n   */\n  async evaluate(config: EvaluateConfig): Promise<EvaluateResult> {\n    tf.util.assert(\n        config.wordProbThresholds != null &&\n            config.wordProbThresholds.length > 0,\n        () => `Received null or empty wordProbThresholds`);\n\n    // TODO(cais): Maybe relax this requirement.\n    const NOISE_CLASS_INDEX = 0;\n    tf.util.assert(\n        this.words[NOISE_CLASS_INDEX] === BACKGROUND_NOISE_TAG,\n        () => `Cannot perform evaluation when the first tag is not ` +\n            `${BACKGROUND_NOISE_TAG}`);\n\n    return tf.tidy(() => {\n      const rocCurve: ROCCurve = [];\n      let auc = 0;\n      const {xs, ys} = this.collectTransferDataAsTensors(config.windowHopRatio);\n      const indices = ys.argMax(-1).dataSync();\n      const probs = this.model.predict(xs) as tf.Tensor;\n\n      // To calcaulte ROC, we collapse all word probabilites into a single\n      // positive class, while _background_noise_ is treated as the\n      // negative class.\n      const maxWordProbs =\n          probs.slice([0, 1], [probs.shape[0], probs.shape[1] - 1]).max(-1);\n      const total = probs.shape[0];\n\n      // Calculate ROC curve.\n      for (let i = 0; i < config.wordProbThresholds.length; ++i) {\n        const probThreshold = config.wordProbThresholds[i];\n        const isWord =\n            maxWordProbs.greater(tf.scalar(probThreshold)).dataSync();\n\n        let negatives = 0;\n        let positives = 0;\n        let falsePositives = 0;\n        let truePositives = 0;\n        for (let i = 0; i < total; ++i) {\n          if (indices[i] === NOISE_CLASS_INDEX) {\n            negatives++;\n            if (isWord[i]) {\n              falsePositives++;\n            }\n          } else {\n            positives++;\n            if (isWord[i]) {\n              truePositives++;\n            }\n          }\n        }\n\n        // TODO(cais): Calculate per-hour false-positive rate.\n        const fpr = falsePositives / negatives;\n        const tpr = truePositives / positives;\n\n        rocCurve.push({probThreshold, fpr, tpr});\n        console.log(\n            `ROC thresh=${probThreshold}: ` +\n            `fpr=${fpr.toFixed(4)}, tpr=${tpr.toFixed(4)}`);\n\n        if (i > 0) {\n          // Accumulate to AUC.\n          auc += Math.abs((rocCurve[i - 1].fpr - rocCurve[i].fpr)) *\n              (rocCurve[i - 1].tpr + rocCurve[i].tpr) / 2;\n        }\n      }\n      return {rocCurve, auc};\n    });\n  }\n\n  /**\n   * Create an instance of tf.LayersModel for transfer learning.\n   *\n   * The top dense layer of the base model is replaced with a new softmax\n   * dense layer.\n   */\n  private createTransferModelFromBaseModel(): void {\n    tf.util.assert(\n        this.words != null,\n        () =>\n            `No word example is available for tranfer-learning model of name ` +\n            this.name);\n\n    // Find the second last dense layer.\n    const layers = this.baseModel.layers;\n    let layerIndex = layers.length - 2;\n    while (layerIndex >= 0) {\n      if (layers[layerIndex].getClassName().toLowerCase() === 'dense') {\n        break;\n      }\n      layerIndex--;\n    }\n    if (layerIndex < 0) {\n      throw new Error('Cannot find a hidden dense layer in the base model.');\n    }\n    this.secondLastBaseDenseLayer = layers[layerIndex];\n    const truncatedBaseOutput =\n        this.secondLastBaseDenseLayer.output as tf.SymbolicTensor;\n\n    this.transferHead = tf.sequential();\n    this.transferHead.add(tf.layers.dense({\n      units: this.words.length,\n      activation: 'softmax',\n      inputShape: truncatedBaseOutput.shape.slice(1),\n      name: 'NewHeadDense'\n    }));\n    const transferOutput =\n        this.transferHead.apply(truncatedBaseOutput) as tf.SymbolicTensor;\n    this.model =\n        tf.model({inputs: this.baseModel.inputs, outputs: transferOutput});\n  }\n\n  /**\n   * Get the input shape of the underlying tf.LayersModel.\n   *\n   * @returns The input shape.\n   */\n  modelInputShape(): tf.Shape {\n    return this.baseModel.inputs[0].shape;\n  }\n\n  getMetadata(): SpeechCommandRecognizerMetadata {\n    return {\n      tfjsSpeechCommandsVersion: version,\n      modelName: this.name,\n      timeStamp: new Date().toISOString(),\n      wordLabels: this.wordLabels()\n    };\n  }\n\n  async save(handlerOrURL?: string|tf.io.IOHandler): Promise<tf.io.SaveResult> {\n    const isCustomPath = handlerOrURL != null;\n    handlerOrURL = handlerOrURL || getCanonicalSavePath(this.name);\n\n    if (!isCustomPath) {\n      // First, save the words and other metadata.\n      const metadataMapStr =\n          localStorageWrapper.localStorage.getItem(SAVED_MODEL_METADATA_KEY);\n      const metadataMap =\n          metadataMapStr == null ? {} : JSON.parse(metadataMapStr);\n      metadataMap[this.name] = this.getMetadata();\n      localStorageWrapper.localStorage.setItem(\n          SAVED_MODEL_METADATA_KEY, JSON.stringify(metadataMap));\n    }\n    console.log(`Saving model to ${handlerOrURL}`);\n    return this.model.save(handlerOrURL);\n  }\n\n  async load(handlerOrURL?: string|tf.io.IOHandler): Promise<void> {\n    const isCustomPath = handlerOrURL != null;\n    handlerOrURL = handlerOrURL || getCanonicalSavePath(this.name);\n\n    if (!isCustomPath) {\n      // First, load the words and other metadata.\n      const metadataMap = JSON.parse(\n          localStorageWrapper.localStorage.getItem(SAVED_MODEL_METADATA_KEY));\n      if (metadataMap == null || metadataMap[this.name] == null) {\n        throw new Error(\n            `Cannot find metadata for transfer model named ${this.name}\"`);\n      }\n      this.words = metadataMap[this.name].wordLabels;\n      console.log(\n          `Loaded word list for model named ${this.name}: ${this.words}`);\n    }\n    this.model = await tf.loadLayersModel(handlerOrURL);\n    console.log(`Loaded model from ${handlerOrURL}:`);\n    this.model.summary();\n  }\n\n  /**\n   * Overridden method to prevent creating a nested transfer-learning\n   * recognizer.\n   *\n   * @param name\n   */\n  createTransfer(name: string): TransferBrowserFftSpeechCommandRecognizer {\n    throw new Error(\n        'Creating transfer-learned recognizer from a transfer-learned ' +\n        'recognizer is not supported.');\n  }\n}\n\nfunction getCanonicalSavePath(name: string): string {\n  return `${SAVE_PATH_PREFIX}${name}`;\n}\n\n/**\n * List the model that are currently saved locally in the browser.\n *\n * @returns An array of transfer-learned speech-commands models\n *   that are currently saved in the browser locally.\n */\nexport async function listSavedTransferModels(): Promise<string[]> {\n  const models = await tf.io.listModels();\n  const keys = [];\n  for (const key in models) {\n    if (key.startsWith(SAVE_PATH_PREFIX)) {\n      keys.push(key.slice(SAVE_PATH_PREFIX.length));\n    }\n  }\n  return keys;\n}\n\n/**\n * Delete a locally-saved, transfer-learned speech-commands model.\n *\n * @param name The name of the transfer-learned model to be deleted.\n */\nexport async function deleteSavedTransferModel(name: string): Promise<void> {\n  // Delete the words from local storage.\n  let metadataMap = JSON.parse(\n      localStorageWrapper.localStorage.getItem(SAVED_MODEL_METADATA_KEY));\n  if (metadataMap == null) {\n    metadataMap = {};\n  }\n  if (metadataMap[name] != null) {\n    delete metadataMap[name];\n  }\n  localStorageWrapper.localStorage.setItem(\n      SAVED_MODEL_METADATA_KEY, JSON.stringify(metadataMap));\n  await tf.io.removeModel(getCanonicalSavePath(name));\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs';\n\nimport {BrowserFftSpeechCommandRecognizer} from './browser_fft_recognizer';\nimport {playRawAudio} from './browser_fft_utils';\nimport {concatenateFloat32Arrays} from './generic_utils';\nimport {FFT_TYPE, SpeechCommandRecognizer, SpeechCommandRecognizerMetadata} from './types';\n\n/**\n * Create an instance of speech-command recognizer.\n *\n * @param fftType Type of FFT. The currently availble option(s):\n *   - BROWSER_FFT: Obtains audio spectrograms using browser's native Fourier\n *     transform.\n * @param vocabulary The vocabulary of the model to load. Possible options:\n *   - '18w' (default): The 18-word vocaulbary, consisting of:\n *     'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven',\n *     'eight', 'nine', 'up', 'down', 'left', 'right', 'go', 'stop',\n *     'yes', and 'no', in addition to '_background_noise_' and '_unknown_'.\n *   - 'directional4w': The four directional words: 'up', 'down', 'left', and\n *     'right', in addition to '_background_noise_' and '_unknown_'.\n *   Choosing a smaller vocabulary leads to better accuracy on the words of\n *   interest and a slightly smaller model size.\n * @param customModelArtifactsOrURL A custom model URL pointing to a model.json\n *     file, or a set of modelArtifacts in `tf.io.ModelArtifacts` format.\n *   Supported schemes: http://, https://, and node.js-only: file://.\n *   Mutually exclusive with `vocabulary`. If provided, `customMetadatURL`\n *   most also be provided.\n * @param customMetadataOrURL A custom metadata URL pointing to a metadata.json\n *   file. Must be provided together with `customModelURL`, or a metadata\n *   object.\n * @returns An instance of SpeechCommandRecognizer.\n * @throws Error on invalid value of `fftType`.\n */\nexport function create(\n    fftType: FFT_TYPE, vocabulary?: string,\n    customModelArtifactsOrURL?: tf.io.ModelArtifacts|string,\n    customMetadataOrURL?: SpeechCommandRecognizerMetadata|\n    string): SpeechCommandRecognizer {\n  tf.util.assert(\n      customModelArtifactsOrURL == null && customMetadataOrURL == null ||\n          customModelArtifactsOrURL != null && customMetadataOrURL != null,\n      () => `customModelURL and customMetadataURL must be both provided or ` +\n          `both not provided.`);\n  if (customModelArtifactsOrURL != null) {\n    tf.util.assert(\n        vocabulary == null,\n        () => `vocabulary name must be null or undefined when modelURL ` +\n            `is provided.`);\n  }\n\n  if (fftType === 'BROWSER_FFT') {\n    return new BrowserFftSpeechCommandRecognizer(\n        vocabulary, customModelArtifactsOrURL, customMetadataOrURL);\n  } else if (fftType === 'SOFT_FFT') {\n    throw new Error(\n        'SOFT_FFT SpeechCommandRecognizer has not been implemented yet.');\n  } else {\n    throw new Error(`Invalid fftType: '${fftType}'`);\n  }\n}\n\nconst utils = {\n  concatenateFloat32Arrays,\n  playRawAudio\n};\n\nexport {BACKGROUND_NOISE_TAG, Dataset, GetDataConfig as GetSpectrogramsAsTensorsConfig, getMaxIntensityFrameIndex, spectrogram2IntensityCurve, SpectrogramAndTargetsTfDataset} from './dataset';\nexport {AudioDataAugmentationOptions, Example, FFT_TYPE, RawAudioData, RecognizerParams, SpectrogramData, SpeechCommandRecognizer, SpeechCommandRecognizerMetadata, SpeechCommandRecognizerResult, StreamingRecognitionConfig, TransferLearnConfig, TransferSpeechCommandRecognizer} from './types';\nexport {deleteSavedTransferModel, listSavedTransferModels, UNKNOWN_TAG} from './browser_fft_recognizer';\nexport {utils};\nexport {version} from './version';\n"],"names":["EPSILON","normalize","x","tf.backend","epsilon","tf.tidy","_a","mean","variance","sub","div","sqrt","add","config","Error","spectrogramCallback","numFramesPerSpectrogram","suppressionTimeMillis","this","numFrames","sampleRateHz","fftSize","frameDurationMillis","columnTruncateLength","overlapFactor","includeRawAudio","tf.util","assert","_this","audioContextConstructor","window","AudioContext","webkitAudioContext","BrowserFftFeatureExtractor","audioTrackConstraints","frameIntervalTask","navigator","mediaDevices","getUserMedia","audio","video","getAudioMediaStream","stream","_b","audioContext","sampleRate","console","warn","streamSource","createMediaStreamSource","analyser","createAnalyser","smoothingTimeConstant","connect","freqDataQueue","freqData","Float32Array","timeDataQueue","timeData","period","Math","max","round","tracker","Tracker","setInterval","onAudioFrame","bind","getFloatFrequencyData","Infinity","push","slice","getFloatTimeDomainData","length","shift","tick","flattenQueue","freqDataTensor","getInputTensorFromFrequencyData","timeDataTensor","suppress","tf.dispose","clearInterval","disconnect","close","getTracks","stop","params","queue","frameSize","forEach","data","i","set","shape","vals","sizeFromShape","tf.tensor","suppressionPeriod","suppressionTime","counter","suppressionOnset","concatenateArrayBuffers","buffers","totalByteLength","buffer","byteLength","temp","Uint8Array","offset","concatenateFloat32Arrays","xs","totalLength","concatenated","index","string2ArrayBuffer","str","strUTF8","unescape","encodeURIComponent","buf","charCodeAt","arrayBuffer2String","decodeURIComponent","escape","String","fromCharCode","DATASET_SERIALIZATION_DESCRIPTOR","DATASET_SERIALIZATION_VERSION","serialized","examples","label2Ids","artifacts","descriptor","manifestLength","Uint32Array","manifestBeginByte","manifestString","manifest","JSON","parse","arrayBuffer2SerializedExamples","spec","byteLen","spectrogramNumFrames","spectrogramFrameSize","rawAudioNumSamples","addExample","deserializeExample","Dataset","example","label","stringify","uid","s4","floor","random","toString","substring","getUID","dataset","vocab","getVocabulary","vocab_1","tslib_1.__values","word","getExamples","examples_1","counts","output","id","size","indexOf","hopFrames","sortedUniqueNumFrames","getSortedUniqueNumFrames","Number","isInteger","toNormalize","uniqueFrameSize","xTensors","xArrays","labelIndices","currentLabel","ids","spectrogram","snippetLength","focusIndex","keyFrameIndex","getMaxIntensityFrameIndex","dataSync","snippet","tf.tensor3d","windows","getValidWindows","window_1","windowedSnippet","getDataset","windows_1","ids_1","augmentByMixingNoiseRatio","augmentByMixingNoise","shuffle","batchSize","datasetBatchSize","valSplit_1","datasetValidationSplit","zippedXandYArrays","map","xArray","item","yArrays","ys","valSplit","isXsFloat32Array","Array","isArray","classIndices","indicesByClasses","classIndex","numClasses","trainIndices","valIndices","classIndices_2","cutoff","j","trainXs","trainYs","valXs","valYs","trainIndices_1","valIndices_1","trainIndices_2","valIndices_2","xTrain","tf.data","array","yTrain","y","tf.oneHot","squeeze","trainDataset","zip","batch","prefetch","xVal","yVal","valDataset","zipped_1","xTensor","targets","tf.tensor1d","asType","undefined","tf.stack","ratio","isTypedArray","noiseExampleIndices","wordExampleIndices","mixedXTensors","mixedLabelIndices","min","noiseIndex","signalTensor","noiseTensor","mixed","mul","wordExampleIndices_1","log","tensor","numFramesSet","Set","ids_2","uniqueNumFrames","sort","splice","Object","keys","durMillis","key","frameDurMillis","sortedVocab","wordLabels","empty","wordLabel","manifestBuffer","descriptorBuffer","version","vocab_2","ids_3","artifact","serializeExample","hasRawAudio","rawAudio","spectrogramKeyFrameIndex","rawAudioSampleRateHz","ex","windowLength","windowHop","begin","leftHalf","left","spectrogram2IntensityCurve","tf.tensor2d","argMax","SAVED_MODEL_METADATA_KEY","SAVE_PATH_PREFIX","localStorageWrapper","localStorage","vocabulary","modelArtifactsOrURL","metadataOrURL","split","join","BrowserFftSpeechCommandRecognizer","DEFAULT_VOCABULARY_NAME","VALID_VOCABULARY_NAMES","MODEL_URL_PREFIX","parameters","SAMPLE_RATE_HZ","FFT_SIZE","callback","streaming","ensureModelLoaded","probabilityThreshold","includeEmbedding","invokeCallbackOnNoiseAndUnknown","normalizedX","ensureModelWithEmbeddingOutputCreated","_c","embedding","model","predict","scores","maxIndexTensor","maxIndex","maxScore","includeSpectrogram","nonBatchInputShape","wordDetected","words","DEFAULT_SUPPRESSION_TIME_MILLIS","audioDataExtractor","start","ensureMetadataLoaded","tf.loadLayersModel","tf.io","fromMemory","modelTopology","weightSpecs","weightData","inputs","outputShape","freezeModel","elementsPerExample","dimSize","warmUpModel","spectrogramDurationMillis","modelWithEmbeddingOutput","layers","getClassName","secondLastDenseLayer","tf.model","outputs","tf.zeros","concat","url","HTTP_SCHEME","HTTPS_SCHEME","FILE_SCHEME","fetch","json","fs","require","readFile","promisify","encoding","loadMetadataJson","metadataJSON","legacyWords","input","_f","recognizeOnline","spectrogramData","tf.Tensor","checkInputTensorShape","inputTensor","numExamples","tf.tensor4d","outAndEmbedding","outTensor","unstacked","tf.unstack","scorePromises","Promise","all","_e","_d","resolve","reject","dispose","name","transferRecognizers","transfer","TransferBrowserFftSpeechCommandRecognizer","trainable","expectedRank","nonBatchedShape","expectedNonBatchShape","arraysEqual","baseModel","_super","tslib_1.__extends","options","durationMultiplier","durationSec","frameDurationSec_1","ceil","snippetDurationSec","onSnippet","frameDurationSec","totalDurationSec","stepFactor","callbackCountTarget","callbackCount","lastIndex","spectrogramSnippets","_p","collateTransferWords","_g","_h","increment","snippetData","normalized","meanVal","arraySync","stdVal","yArray","from","normalizeFloat32Array","finalSpectrogram","_k","_j","_o","_m","_l","clear","getExampleCounts","setExampleKeyFrameIndex","removeExample","clearExisting","incomingDataset","clearExamples","incomingVocab","incomingVocab_1","serialize","windowHopRatio","augmentationOptions","out","getData","validationSplit","fineTuningEpochs","createTransferModelFromBaseModel","secondLastBaseDenseLayer","compile","loss","optimizer","metrics","datasetDurationMillisThreshold","fitDatasetDurationMillisThreshold","durationMillis","trainOnDataset","trainOnTensors","epochs","tslib_1.__read","collectTransferDataAsTfDataset","t0","now","fitDataset","validationData","callbacks","history","toFixed","t0_1","fineTuningUsingTfDatasets","fineTuningHistory","collectTransferDataAsTensors","splits","classIndices_1","tf.gather","balancedTrainValSplit","valData","fit","history_1","fineTuningUsingTensors","originalTrainableValue","fineTuningOptimizer","fineTuningCallback","wordProbThresholds","NOISE_CLASS_INDEX","rocCurve","auc","indices","probs","maxWordProbs","total","probThreshold","isWord","greater","tf.scalar","negatives","positives","falsePositives","truePositives","i_1","fpr","tpr","abs","layerIndex","toLowerCase","truncatedBaseOutput","transferHead","tf.sequential","tf.layers","dense","units","activation","inputShape","transferOutput","apply","tfjsSpeechCommandsVersion","modelName","timeStamp","Date","toISOString","handlerOrURL","isCustomPath","getCanonicalSavePath","metadataMapStr","getItem","metadataMap","getMetadata","setItem","save","summary","utils","playRawAudio","onEnded","arrayBuffer","createBuffer","getChannelData","source","createBufferSource","destination","onended","fftType","customModelArtifactsOrURL","customMetadataOrURL","removeModel","listModels","models","startsWith"],"mappings":";;;;;;;;;;;;;;;;q+EA8CA,IAAIA,EAAkB,cAWNC,EAAUC,GAIxB,OAHe,MAAXF,IACFA,EAAUG,YAAaC,WAElBC,OAAQ,WACP,IAAAC,eAACC,SAAMC,aAEb,OAAON,EAAEO,IAAIF,GAAMG,IAAIF,EAASG,OAAOC,IAAIZ,MCuB/C,iBAyCE,WAAYa,GAAZ,WACE,GAAc,MAAVA,EACF,MAAM,IAAIC,MACN,uFAIN,GAAkC,MAA9BD,EAAOE,oBACT,MAAM,IAAID,MAAM,mDAGlB,KAAMD,EAAOG,wBAA0B,GACrC,MAAM,IAAIF,MACN,6CACGD,EAAOG,yBAGhB,GAAIH,EAAOI,sBAAwB,EACjC,MAAM,IAAIH,MACN,sDACWD,EAAOI,uBAkBxB,GAhBAC,KAAKD,sBAAwBJ,EAAOI,sBAEpCC,KAAKH,oBAAsBF,EAAOE,oBAClCG,KAAKC,UAAYN,EAAOG,wBACxBE,KAAKE,aAAeP,EAAOO,cAAgB,MAC3CF,KAAKG,QAAUR,EAAOQ,SAAW,KACjCH,KAAKI,oBAAsBJ,KAAKG,QAAUH,KAAKE,aAAe,IAC9DF,KAAKK,qBAAuBV,EAAOU,sBAAwBL,KAAKG,QAChEH,KAAKM,cAAgBX,EAAOW,cAC5BN,KAAKO,gBAAkBZ,EAAOY,gBAE9BC,OAAQC,OACJT,KAAKM,eAAiB,GAAKN,KAAKM,cAAgB,EAChD,WAAM,MAAA,sDACSI,EAAKJ,gBAEpBN,KAAKK,qBAAuBL,KAAKG,QACnC,MAAM,IAAIP,MACN,wBAAwBI,KAAKK,0CACjBL,KAAKG,cAGvBH,KAAKW,wBD7ECC,OAAeC,cAAiBD,OAAeE,mBCiLzD,OAjGQC,kBAAN,SAAYC,qGAEV,GAA8B,MAA1BhB,KAAKiB,kBACP,MAAM,IAAIrB,MACN,2DAGQ,OAAdR,EAAAY,iBDnFAgB,oEACF,SAAOE,UAAUC,aAAaC,cAC5BC,MAAgC,MAAzBL,GAAuCA,EAC9CM,OAAO,SCgFaC,CAAoBP,kBAAxC5B,EAAKoC,OAASC,SAEdzB,KAAK0B,aAAe,IAAI1B,KAAKW,wBACzBX,KAAK0B,aAAaC,aAAe3B,KAAKE,cACxC0B,QAAQC,KACJ,wCACa7B,KAAKE,0BACPF,KAAK0B,aAAaC,YAE7BG,EAAe9B,KAAK0B,aAAaK,wBAAwB/B,KAAKwB,QACpExB,KAAKgC,SAAWhC,KAAK0B,aAAaO,iBAClCjC,KAAKgC,SAAS7B,QAAyB,EAAfH,KAAKG,QAC7BH,KAAKgC,SAASE,sBAAwB,EACtCJ,EAAaK,QAAQnC,KAAKgC,UAE1BhC,KAAKoC,iBACLpC,KAAKqC,SAAW,IAAIC,aAAatC,KAAKG,SAClCH,KAAKO,kBACPP,KAAKuC,iBACLvC,KAAKwC,SAAW,IAAIF,aAAatC,KAAKG,UAElCsC,EACFC,KAAKC,IAAI,EAAGD,KAAKE,MAAM5C,KAAKC,WAAa,EAAID,KAAKM,iBACtDN,KAAK6C,QAAU,IAAIC,EACfL,EACAC,KAAKE,MAAM5C,KAAKD,sBAAwBC,KAAKI,sBACjDJ,KAAKiB,kBAAoB8B,YACrB/C,KAAKgD,aAAaC,KAAKjD,MAAOA,KAAKG,QAAUH,KAAKE,aAAe,eAGzDa,yBAAd,+GAEE,OADAf,KAAKgC,SAASkB,sBAAsBlD,KAAKqC,UACrCrC,KAAKqC,SAAS,MAAQc,EAAAA,OAI1BnD,KAAKoC,cAAcgB,KAAKpD,KAAKqC,SAASgB,MAAM,EAAGrD,KAAKK,uBAChDL,KAAKO,kBACPP,KAAKgC,SAASsB,uBAAuBtD,KAAKwC,UAC1CxC,KAAKuC,cAAca,KAAKpD,KAAKwC,SAASa,UAEpCrD,KAAKoC,cAAcmB,OAASvD,KAAKC,WAEnCD,KAAKoC,cAAcoB,QAEFxD,KAAK6C,QAAQY,QAExBpB,EAAWqB,EAAa1D,KAAKoC,eAC7BuB,EAAiBC,EACnBvB,GAAW,EAAGrC,KAAKC,UAAWD,KAAKK,qBAAsB,IACzDwD,SACA7D,KAAKO,kBACDiC,EAAWkB,EAAa1D,KAAKuC,eACnCsB,EAAiBD,EACbpB,GAAW,EAAGxC,KAAKC,UAAYD,KAAKG,cAGhCH,KAAKH,oBAAoB8D,EAAgBE,mBAA/CzE,UAEFY,KAAK6C,QAAQiB,WAEfC,WAAYJ,EAAgBE,qCAI1B9C,iBAAN,4EACE,GAA8B,MAA1Bf,KAAKiB,kBACP,MAAM,IAAIrB,MACN,sEAENoE,cAAchE,KAAKiB,mBACnBjB,KAAKiB,kBAAoB,KACzBjB,KAAKgC,SAASiC,aACdjE,KAAK0B,aAAawC,QACC,MAAflE,KAAKwB,QAAkBxB,KAAKwB,OAAO2C,YAAYZ,OAAS,GAC1DvD,KAAKwB,OAAO2C,YAAY,GAAGC,gBAI/BrD,sBAAA,SAAUsD,GACR,MAAM,IAAIzE,MACN,mEAGNmB,wBAAA,WACE,MAAM,IAAInB,MACN,wJAMQ8D,EAAaY,GAC3B,IAAMC,EAAYD,EAAM,GAAGf,OACrBlB,EAAW,IAAIC,aAAagC,EAAMf,OAASgB,GAEjD,OADAD,EAAME,QAAQ,SAACC,EAAMC,GAAM,OAAArC,EAASsC,IAAIF,EAAMC,EAAIH,KAC3ClC,WAGOuB,EACZvB,EAAwBuC,GAC1B,IAAMC,EAAO,IAAIvC,aAAa9B,OAAQsE,cAAcF,IAGpD,OADAC,EAAKF,IAAItC,EAAUwC,EAAKtB,OAASlB,EAASkB,QACnCwB,SAAUF,EAAMD,GAOzB,iBAaE,WAAYnC,EAAgBuC,GAA5B,WACEhF,KAAKyC,OAASA,EACdzC,KAAKiF,gBAAuC,MAArBD,EAA4B,EAAIA,EACvDhF,KAAKkF,QAAU,EAEf1E,OAAQC,OACJT,KAAKyC,OAAS,EACd,WAAM,MAAA,2CAA2C/B,EAAK+B,SAsB9D,OAdEK,iBAAA,WAKE,OAJA9C,KAAKkF,UACelF,KAAKkF,QAAUlF,KAAKyC,QAAW,IACrB,MAAzBzC,KAAKmF,kBACLnF,KAAKkF,QAAUlF,KAAKmF,iBAAmBnF,KAAKiF,kBAOnDnC,qBAAA,WACE9C,KAAKmF,iBAAmBnF,KAAKkF,uBCtTjBE,EAAwBC,GACtC,IAAIC,EAAkB,EACtBD,EAAQb,QAAQ,SAACe,GACfD,GAAmBC,EAAOC,aAG5B,IAAMC,EAAO,IAAIC,WAAWJ,GACxBK,EAAS,EAKb,OAJAN,EAAQb,QAAQ,SAACe,GACfE,EAAKd,IAAI,IAAIe,WAAWH,GAASI,GACjCA,GAAUJ,EAAOC,aAEZC,EAAKF,gBASEK,EAAyBC,GACvC,IAAIC,EAAc,EAClBD,EAAGrB,QAAQ,SAAAxF,GAAK,OAAA8G,GAAe9G,EAAEuE,SACjC,IAAMwC,EAAe,IAAIzD,aAAawD,GAClCE,EAAQ,EAKZ,OAJAH,EAAGrB,QAAQ,SAAAxF,GACT+G,EAAapB,IAAI3F,EAAGgH,GACpBA,GAAShH,EAAEuE,SAENwC,WAIOE,EAAmBC,GACjC,GAAW,MAAPA,EACF,MAAM,IAAItG,MAAM,oCAMlB,IAFA,IAAMuG,EAAUC,SAASC,mBAAmBH,IACtCI,EAAM,IAAIZ,WAAWS,EAAQ5C,QAC1BmB,EAAI,EAAGA,EAAIyB,EAAQ5C,SAAUmB,EACpC4B,EAAI5B,GAAKyB,EAAQI,WAAW7B,GAE9B,OAAO4B,EAAIf,gBAIGiB,EAAmBjB,GACjC,GAAc,MAAVA,EACF,MAAM,IAAI3F,MAAM,oCAElB,IAAM0G,EAAM,IAAIZ,WAAWH,GAC3B,OAAOkB,mBAAmBC,OAAOC,OAAOC,mBAAPD,SAAuBL,MCnDnD,IAAMO,EAAmC,WAOnCC,EAAgC,eAgK3C,WAAYC,GAGV,GAFA/G,KAAKgH,YACLhH,KAAKiH,aACa,MAAdF,EAIF,IAFA,IAAMG,WAsnBmC3B,GAE7C/E,OAAQC,OAAiB,MAAV8E,EAAgB,WAAM,MAAA,sCAErC,IAAII,EAAS,EACPwB,EAAaX,EACfjB,EAAOlC,MAAMsC,EAAQkB,EAAiCtD,SAC1D/C,OAAQC,OACJ0G,IAAeN,EACf,WAAM,MAAA,8CACVlB,GAAUkB,EAAiCtD,OAE3CoC,GAAU,EAGV,IAAMyB,EAAiB,IAAIC,YAAY9B,EAAQI,EAAQ,GAEjD2B,EADN3B,GAAU,EAEVA,EAAS2B,EAAoBF,EAAe,GAC5C,IACMG,EAAiBf,EADDjB,EAAOlC,MAAMiE,EAAmB3B,IAEhD6B,EAAWC,KAAKC,MAAMH,GACtB9C,EAAOc,EAAOlC,MAAMsC,GAC1B,OAAQ6B,WAAU/C,QA7oBIkD,CAA+BZ,GAC7CpB,EAAS,EACJjB,EAAI,EAAGA,EAAIwC,EAAUM,SAASjE,SAAUmB,EAAG,CAClD,IAAMkD,EAAOV,EAAUM,SAAS9C,GAC5BmD,EAAUD,EAAKE,qBAAuBF,EAAKG,qBAChB,MAA3BH,EAAKI,qBACPH,GAAWD,EAAKI,oBAElBH,GAAW,EACX7H,KAAKiI,WAAWC,GACXN,OAAMnD,KAAMyC,EAAUzC,KAAKpB,MAAMsC,EAAQA,EAASkC,MACvDlC,GAAUkC,GA0hBlB,OA9gBEM,uBAAA,SAAWC,GACT5H,OAAQC,OAAkB,MAAX2H,EAAiB,WAAM,MAAA,kCACtC5H,OAAQC,OACa,MAAjB2H,EAAQC,OAAiBD,EAAQC,MAAM9E,OAAS,EAChD,WAAM,MAAA,oDACSkE,KAAKa,UAAUF,EAAQC,SAC1C,IAAME,aDjJR,SAASC,IACP,OAAO9F,KAAK+F,MAA4B,OAArB,EAAI/F,KAAKgG,WAAqBC,SAAS,IAAIC,UAAU,GAE1E,OAAOJ,IAAOA,IAAO,IAAMA,IAAO,IAAMA,IAAO,IAAMA,IAAO,IAAMA,IAC9DA,IAAOA,IC6IGK,GAMZ,OALA7I,KAAKgH,SAASuB,GAAOH,EACfA,EAAQC,SAASrI,KAAKiH,YAC1BjH,KAAKiH,UAAUmB,EAAQC,WAEzBrI,KAAKiH,UAAUmB,EAAQC,OAAOjF,KAAKmF,GAC5BA,GAQTJ,kBAAA,SAAMW,eACJtI,OAAQC,OACJqI,IAAY9I,KAAM,WAAM,MAAA,uCAC5B,IAAM+I,EAAQD,EAAQE,oBACtB,IAAmB,IAAAC,EAAAC,EAAAH,iCAAO,CAArB,IAAMI,UACHnC,EAAW8B,EAAQM,YAAYD,OACrC,IAAsB,IAAAE,YAAAH,EAAAlC,kCAAU,CAA3B,IAAMoB,UACTpI,KAAKiI,WAAWG,EAAQA,gNAU9BD,6BAAA,WACE,IAAMmB,KACN,IAAK,IAAMf,KAAOvI,KAAKgH,SAAU,CAC/B,IAAMoB,EAAUpI,KAAKgH,SAASuB,GACxBH,EAAQC,SAASiB,IACrBA,EAAOlB,EAAQC,OAAS,GAE1BiB,EAAOlB,EAAQC,SAEjB,OAAOiB,GAYTnB,wBAAA,SAAYE,GAAZ,WACE7H,OAAQC,OACK,MAAT4H,EACA,WACI,MAAA,0CAA0CZ,KAAKa,UAAUD,KACjE7H,OAAQC,OACJ4H,KAASrI,KAAKiH,UACd,WAAM,MAAA,wBAAwBoB,0BAClC,IAAMkB,KAIN,OAHAvJ,KAAKiH,UAAUoB,GAAO7D,QAAQ,SAAAgF,GAC5BD,EAAOnG,MAAMmF,IAAKiB,EAAIpB,QAAS1H,EAAKsG,SAASwC,OAExCD,GA8BTpB,oBAAA,SAAQE,EAAgB1I,GAAxB,WAIEa,OAAQC,OACJT,KAAKyJ,OAAS,EACd,WACI,MAAA,oEACR,IAAMV,EAAQ/I,KAAKgJ,gBACN,MAATX,EACF7H,OAAQC,QACsB,IAA1BsI,EAAMW,QAAQrB,GACd,WAAM,MAAA,SAASA,gCACPZ,KAAKa,UAAUS,SAI3BvI,OAAQC,OACJsI,EAAMxF,OAAS,EACf,WAAM,MAAA,kGACqCwF,EAAMxF,kBAGzC,MAAV5D,IACFA,MAKF,IACIM,EACA0J,EAFEC,EAAwB5J,KAAK6J,2BAGE,IAAjCD,EAAsBrG,QACxBtD,EAAgC,MAApBN,EAAOM,UAAoB2J,EAAsB,GACtBjK,EAAOM,UAC9C0J,EAAgC,MAApBhK,EAAOgK,UAAoB,EAAIhK,EAAOgK,YAElD1J,EAAYN,EAAOM,UACnBO,OAAQC,OACS,MAAbR,GAAqB6J,OAAOC,UAAU9J,IAAcA,EAAY,EAChE,WAAM,MAAA,aACI2J,EAAsBrG,oCACrB7C,EAAK+I,2FAEpBjJ,OAAQC,OACJR,GAAa2J,EAAsB,GACnC,WAAM,MAAA,cAAc3J,sCACZ2J,EAAsB,4CAGlCD,EAAYhK,EAAOgK,UACnBnJ,OAAQC,OACS,MAAbkJ,GAAqBG,OAAOC,UAAUJ,IAAcA,EAAY,EAChE,WAAM,MAAA,aACIC,EAAsBrG,oCACrB7C,EAAK+I,4FAKtB,IAAMO,EAAkC,MAApBrK,EAAOZ,WAA2BY,EAAOZ,UAE7D,OAAOI,OAAQ,WAMb,YADI8K,EAJAC,KACAC,KAEAC,KAEK1F,EAAI,EAAGA,EAAIqE,EAAMxF,SAAUmB,EAAG,CACrC,IAAM2F,EAAetB,EAAMrE,GAC3B,GAAa,MAAT2D,GAAiBgC,IAAiBhC,EAAtC,CAGA,IAAMiC,EAAM5J,EAAKuG,UAAUoD,cAChBb,WAEHe,EADU7J,EAAKsG,SAASwC,GACFe,YACtBhG,EAAYgG,EAAYhG,UACP,MAAnB0F,EACFA,EAAkB1F,EAElB/D,OAAQC,OACJ8D,IAAc0F,EACd,WAAM,MAAA,2BACE1F,SAAgB0F,QAG9B,IAAMO,EAAgBD,EAAY9F,KAAKlB,OAASgB,EAC5CkG,EAAa,KA/TS,uBAgUtBJ,IACFI,EAA0C,MAA7BF,EAAYG,cACrBC,EAA0BJ,GAAaK,WAAW,GAClDL,EAAYG,eAIlB,IAAMG,EACFC,WAAYP,EAAY9F,MAAO+F,EAAejG,EAAW,IACvDwG,EACFC,EAAgBR,EAAeC,EAAYxK,EAAW0J,cAC/CsB,GACT,IAAMC,EAAkB/L,OAAQ,WAC9B,IAAMoK,EAASsB,EAAQxH,OAClB4H,EAAO,GAAI,EAAG,IAAKA,EAAO,GAAKA,EAAO,IAAK,GAAI,IACpD,OAAOjB,EAAcjL,EAAUwK,GAAUA,IAEvC5J,EAAOwL,WAGThB,EAAQ/G,KAAK8H,EAAgBN,YAE7BV,EAAS9G,KAAK8H,GAEH,MAAT7C,GACF+B,EAAahH,KAAKsB,QAdtB,IAAqB,IAAA0G,YAAAlC,EAAA6B,gJAiBrBhH,UAAW8G,QA3Cb,IAAiB,IAAAQ,YAAAnC,EAAAoB,kJA+CqB,MAApC3K,EAAO2L,2BACT5K,EAAK6K,qBACD5L,EAAOwL,WAAahB,EACAD,EACpBE,EAAczK,EAAO2L,2BAG3B,IAAME,EAA4B,MAAlB7L,EAAO6L,SAAyB7L,EAAO6L,QACvD,GAAI7L,EAAOwL,WAAY,CACrB,IAAMM,EACyB,MAA3B9L,EAAO+L,iBAA2B,GAAK/L,EAAO+L,iBAG5CC,EAA4C,MAAjChM,EAAOiM,uBACpB,IACAjM,EAAOiM,uBACXpL,OAAQC,OACJkL,EAAW,GAAKA,EAAW,EAC3B,WAAM,MAAA,qCAAqCA,IAE/C,IAAME,EACF1B,EAAQ2B,IAAI,SAACC,EAAQrH,GAAM,OAACqH,EAAQ3B,EAAa1F,MACrDlE,OAAQgL,QACJK,GACJ1B,EAAU0B,EAAkBC,IAAI,SAAAE,GAAQ,OAAAA,EAAK,KAC7C,IAAMC,EAAUJ,EAAkBC,IAAI,SAAAE,GAAQ,OAAAA,EAAK,KAC7CvK,WCvXVoE,EAA+BqG,EAAcC,uBAM/C3L,OAAQC,OACJ0L,EAAW,GAAKA,EAAW,EAC3B,WAAM,MAAA,wDACSA,IAMnB,IALA,IAAMC,GAAoBC,MAAMC,QAAQzG,EAAG,IAErC0G,EAAeL,EAEfM,KACG9H,EAAI,EAAGA,EAAI6H,EAAahJ,SAAUmB,EAAG,CAC5C,IAAM+H,EAAaF,EAAa7H,GACI,MAAhC8H,EAAiBC,KACnBD,EAAiBC,OAEnBD,EAAiBC,GAAYrJ,KAAKsB,GAEpC,IAAMgI,EAAaF,EAAiBjJ,OAE9BoJ,KACAC,KAIN,IADAJ,EAAiBV,IAAI,SAAAS,GAAgB,OAAA/L,OAAQgL,QAAQe,KAC5C7H,EAAI,EAAGA,EAAIgI,IAAchI,EAGhC,IAFA,IAAMmI,EAAeL,EAAiB9H,GAChCoI,EAASpK,KAAKE,MAAMiK,EAAatJ,QAAU,EAAI4I,IAC5CY,EAAI,EAAGA,EAAIF,EAAatJ,SAAUwJ,EACrCA,EAAID,EACNH,EAAavJ,KAAKyJ,EAAaE,IAE/BH,EAAWxJ,KAAKyJ,EAAaE,IAKnC,GAAIX,EAAkB,CACpB,IAAMY,KACAC,KACAC,KACAC,SACN,IAAoB,IAAAC,EAAAlE,EAAAyD,iCAAc,CAA7B,IAAM3G,UACTgH,EAAQ5J,KAAKyC,EAAGG,IAChBiH,EAAQ7J,KAAK8I,EAAGlG,0GAElB,IAAoB,IAAAqH,EAAAnE,EAAA0D,iCAAT5G,UACTkH,EAAM9J,KAAKyC,EAAGG,IACdmH,EAAM/J,KAAK8I,EAAGlG,qGAEhB,OAAQgH,UAASC,UAASC,QAAOC,SAE3BH,KACAC,KACAC,KACAC,SACN,IAAoB,IAAAG,EAAApE,EAAAyD,iCAAT3G,UACTgH,EAAQ5J,KAAKyC,EAAGG,IAChBiH,EAAQ7J,KAAK8I,EAAGlG,yGAElB,IAAoB,IAAAuH,EAAArE,EAAA0D,iCAAT5G,UACTkH,EAAM9J,KAAKyC,EAAGG,IACdmH,EAAM/J,KAAK8I,EAAGlG,qGAEhB,OAAQgH,UAASC,UAASC,QAAOC,iBDmTtBH,YAASC,YAASC,UAAOC,UAO1BK,EACFC,OAAQC,MAAMV,GAAgBlB,IAAI,SAAA9M,GAAK,OAAA8L,WAAY9L,GACjDiB,EAAWgK,EAAiB,MAE5B0D,EAASF,OAAQC,MAAMT,GAASnB,IAClC,SAAA8B,GAAK,OAAAC,UAAWD,GAAI7E,EAAMxF,QAAQuK,SAAS,MAE3CC,EAAeN,OAAQO,KAAKnI,GAAI2H,EAAQtB,GAAIyB,IAC5CnC,IAEFuC,EAAeA,EAAavC,QAAQrB,EAAQ5G,SAE9CwK,EAAeA,EAAaE,MAAMxC,GAAWyC,SAAS,GAEtD,IAAMC,EACFV,OAAQC,MAAMR,GAAcpB,IAAI,SAAA9M,GAAK,OAAA8L,WAAY9L,GAC/CiB,EAAWgK,EAAiB,MAE5BmE,EAAOX,OAAQC,MAAMP,GAAOrB,IAC9B,SAAA8B,GAAK,OAAAC,UAAWD,GAAI7E,EAAMxF,QAAQuK,SAAS,MAC3CO,EAAaZ,OAAQO,KAAKnI,GAAIsI,EAAMjC,GAAIkC,IAK5C,OAAQL,EAJRM,EAAaA,EAAWJ,MAAMxC,GAAWyC,SAAS,IAMlD,GAAI1C,EAAS,CAEX,IAAM8C,KACNpE,EAAS1F,QAAQ,SAAC+J,EAAS7J,GACzB4J,EAAOlL,MAAMpE,EAAGuP,EAASX,EAAGxD,EAAa1F,OAE3ClE,OAAQgL,QAAQ8C,GAChBpE,EAAWoE,EAAOxC,IAAI,SAAAE,GAAQ,OAAAA,EAAKhN,IACnCoL,EAAekE,EAAOxC,IAAI,SAAAE,GAAQ,OAAAA,EAAK4B,IAGzC,IAAMY,EAAmB,MAATnG,EACZwF,SAAUY,WAAYrE,EAAc,SAAUrB,EAAMxF,QAC/CmL,OAAO,gBACZC,EACJ,OACE9I,GAAI+I,QAAS1E,GACbgC,GAAIsC,MAMJrG,iCAAR,SACItC,EAASuE,EAAwByE,WACnC,GAAU,MAANhJ,GAA4B,IAAdA,EAAGtC,OACnB,MAAM,IAAI3D,MACN,6DAON,IALA,IAAMkP,EAAejJ,EAAG,aAAcvD,aAEhCyG,EAAQ/I,KAAKgJ,gBACb+F,KACAC,KACGtK,EAAI,EAAGA,EAAI0F,EAAa7G,SAAUmB,EA9bX,uBA+b1BqE,EAAMqB,EAAa1F,IACrBqK,EAAoB3L,KAAKsB,GAEzBsK,EAAmB5L,KAAKsB,GAG5B,GAAmC,IAA/BqK,EAAoBxL,OACtB,MAAM,IAAI3D,MACN,2GAIN,IAAMqP,KACAC,gBACKlJ,GACT,ID/c2BmJ,EAAaxM,EC+clCyM,EACFL,GDhduBI,ECgdc,EDhdDxM,ECgdIoM,EAAoBxL,OD/c7Db,KAAK+F,OAAO9F,EAAMwM,GAAOzM,KAAKgG,UAAYyG,ICgdvCE,EAAeP,EACjBL,WAAY5I,EAAGG,IACfH,EAAGG,GACDsJ,EAAcR,EAChBL,WAAY5I,EAAGuJ,IACfvJ,EAAGuJ,GACDG,EACFpQ,OAAQ,WAAM,OAAAJ,EAAUsQ,EAAa3P,IAAI4P,EAAYE,IAAIX,OACzDC,EACFG,EAAc7L,KAAKmM,EAAM3E,YAEzBqE,EAAc7L,KAAKmM,GAErBL,EAAkB9L,KAAKgH,EAAapE,SAhBtC,IAAoB,IAAAyJ,EAAAvG,EAAA8F,+IAkBpBpN,QAAQ8N,IACJ,0CAA0CT,EAAc1L,oBAE5D0L,EAAczK,QAAQ,SAAAmL,GAAU,OAAA9J,EAAGzC,KAAKuM,KACxCvF,EAAahH,WAAbgH,IAAqB8E,KAGf/G,qCAAR,WAGE,YAFMyH,EAAe,IAAIC,IACnB9G,EAAQ/I,KAAKgJ,gBACVtE,EAAI,EAAGA,EAAIqE,EAAMxF,SAAUmB,EAAG,CACrC,IAAM2D,EAAQU,EAAMrE,GACd4F,EAAMtK,KAAKiH,UAAUoB,OAC3B,IAAiB,IAAAyH,YAAA5G,EAAAoB,kCAAK,CAAjB,IAAMd,UACHe,EAAcvK,KAAKgH,SAASwC,GAAIe,YAChCtK,EAAYsK,EAAY9F,KAAKlB,OAASgH,EAAYhG,UACxDqL,EAAalQ,IAAIO,sGAGrB,IAAM8P,IAAsBH,GAE5B,OADAG,EAAgBC,OACTD,GAST5H,0BAAA,SAAcI,GACZ,KAAMA,KAAOvI,KAAKgH,UAChB,MAAM,IAAIpH,MAAM,4BAA4B2I,GAE9C,IAAMF,EAAQrI,KAAKgH,SAASuB,GAAKF,aAC1BrI,KAAKgH,SAASuB,GACrB,IAAMvC,EAAQhG,KAAKiH,UAAUoB,GAAOqB,QAAQnB,GAC5CvI,KAAKiH,UAAUoB,GAAO4H,OAAOjK,EAAO,GACC,IAAjChG,KAAKiH,UAAUoB,GAAO9E,eACjBvD,KAAKiH,UAAUoB,IAa1BF,oCAAA,SAAwBI,EAAamC,GACnC,KAAMnC,KAAOvI,KAAKgH,UAChB,MAAM,IAAIpH,MAAM,4BAA4B2I,GAE9C,IAAMgC,EAAcvK,KAAKgH,SAASuB,GAAKgC,YACjCtK,EAAYsK,EAAY9F,KAAKlB,OAASgH,EAAYhG,UACxD/D,OAAQC,OACJiK,GAAiB,GAAKA,EAAgBzK,GAClC6J,OAAOC,UAAUW,GACrB,WAAM,MAAA,0BAA0BA,uBACTzK,wBAC3BsK,EAAYG,cAAgBA,GAQ9BvC,iBAAA,WACE,OAAO+H,OAAOC,KAAKnQ,KAAKgH,UAAUzD,QAUpC4E,2BAAA,WACE,IAAIiI,EAAY,EAEhB,IAAK,IAAMC,KAAOrQ,KAAKgH,SAAU,CAC/B,IAAMuD,EAAcvK,KAAKgH,SAASqJ,GAAK9F,YACjC+F,EAHyB,MAI3B/F,EAAYnK,oBAChBgQ,GACI7F,EAAY9F,KAAKlB,OAASgH,EAAYhG,UAAY+L,EAExD,OAAOF,GAUTjI,kBAAA,WACE,OAAuB,IAAhBnI,KAAKyJ,QAMdtB,kBAAA,WACEnI,KAAKgH,aASPmB,0BAAA,WACE,IAAMY,EAAQ,IAAI8G,IAClB,IAAK,IAAMtH,KAAOvI,KAAKgH,SAAU,CAC/B,IAAMoB,EAAUpI,KAAKgH,SAASuB,GAC9BQ,EAAMrJ,IAAI0I,EAAQC,OAEpB,IAAMkI,IAAkBxH,GAExB,OADAwH,EAAYP,OACLO,GAiBTpI,sBAAA,SAAUqI,eACFzH,EAAQ/I,KAAKgJ,gBACnBxI,OAAQC,QAAQT,KAAKyQ,QAAS,WAAM,MAAA,mCAElB,MAAdD,IACGnE,MAAMC,QAAQkE,KACjBA,GAAcA,IAEhBA,EAAWhM,QAAQ,SAAAkM,GACjB,IAAkC,IAA9B3H,EAAMW,QAAQgH,GAChB,MAAM,IAAI9Q,MACN,eAAe8Q,4EAEZjJ,KAAKa,UAAUS,WAK5B,IAiFoChC,EAEhC4J,EAGAC,EACAC,EACAzJ,EAxFEI,KACAnC,SACN,IAAoB,IAAAyL,EAAA5H,EAAAH,iCAAO,CAAtB,IAAMV,UACT,GAAkB,MAAdmI,IAAqD,IAA/BA,EAAW9G,QAAQrB,GAA7C,CAGA,IAAMiC,EAAMtK,KAAKiH,UAAUoB,OAC3B,IAAiB,IAAA0I,YAAA7H,EAAAoB,kCAAK,CAAjB,IAAMd,UACHwH,EAAWC,EAAiBjR,KAAKgH,SAASwC,IAChDhC,EAASpE,KAAK4N,EAASpJ,MACvBvC,EAAQjC,KAAK4N,EAASvM,4MAG1B,OAoEoCsC,GAnE/BS,WAAU/C,KAAMW,EAAwBC,IAqEzCsL,EACF1K,EAAmBwB,KAAKa,UAAUvB,EAAWS,WAE3CoJ,EAAmB3K,EAAmBY,GACtCgK,EAAU,IAAIxJ,aAAaP,IAC3BM,EAAiB,IAAIC,aAAasJ,EAAenL,aAIhDJ,GAHcA,GAChBwL,EAAkBC,EAAQtL,OAAQ6B,EAAe7B,SAGnCoL,EAAgB5J,EAAWtC,sBA1EhCwM,EAAiB7I,GAE/B,IAAM8I,EAAkC,MAApB9I,EAAQ+I,SACtBvJ,GACJS,MAAOD,EAAQC,MACfP,qBACIM,EAAQmC,YAAY9F,KAAKlB,OAAS6E,EAAQmC,YAAYhG,UAC1DwD,qBAAsBK,EAAQmC,YAAYhG,WAEH,MAArC6D,EAAQmC,YAAYG,gBACtB9C,EAAKwJ,yBAA2BhJ,EAAQmC,YAAYG,eAGtD,IAAIjG,EAAO2D,EAAQmC,YAAY9F,KAAKc,OAAOlC,MAAM,GAQjD,OAPI6N,IACFtJ,EAAKI,mBAAqBI,EAAQ+I,SAAS1M,KAAKlB,OAChDqE,EAAKyJ,qBAAuBjJ,EAAQ+I,SAASjR,aAG7CuE,EAAOW,GAAyBX,EAAM2D,EAAQ+I,SAAS1M,KAAKc,WAEtDqC,OAAMnD,iBAIAyD,EACZ8I,GACF,IAAMzG,GACJhG,UAAWyM,EAASpJ,KAAKG,qBACzBtD,KAAM,IAAInC,aAAa0O,EAASvM,KAAKpB,MACjC,EACA,EAAI2N,EAASpJ,KAAKG,qBACdiJ,EAASpJ,KAAKE,wBAEsB,MAA1CkJ,EAASpJ,KAAKwJ,2BAChB7G,EAAYG,cAAgBsG,EAASpJ,KAAKwJ,0BAE5C,IAAME,GAAejJ,MAAO2I,EAASpJ,KAAKS,MAAOkC,eASjD,OARwC,MAApCyG,EAASpJ,KAAKI,qBAChBsJ,EAAGH,UACDjR,aAAc8Q,EAASpJ,KAAKyJ,qBAC5B5M,KAAM,IAAInC,aAAa0O,EAASvM,KAAKpB,MACjC,EAAI2N,EAASpJ,KAAKG,qBAClBiJ,EAASpJ,KAAKE,yBAGfwJ,WA4EOtG,EACZR,EAAuBC,EAAoB8G,EAC3CC,GA0BF,GAzBAhR,OAAQC,OACJqJ,OAAOC,UAAUS,IAAkBA,EAAgB,EACnD,WACI,MAAA,qDAAqDA,IAC3C,MAAdC,GACFjK,OAAQC,OACJqJ,OAAOC,UAAUU,IAAeA,GAAc,EAC9C,WACI,MAAA,sDAAsDA,IAEhEjK,OAAQC,OACJqJ,OAAOC,UAAUwH,IAAiBA,EAAe,EACjD,WAAM,MAAA,oDAAoDA,IAC9D/Q,OAAQC,OACJqJ,OAAOC,UAAUyH,IAAcA,EAAY,EAC3C,WAAM,MAAA,iDAAiDA,IAC3DhR,OAAQC,OACJ8Q,GAAgB/G,EAChB,WAAM,MAAA,iBAAiB+G,8BACf/G,QACZhK,OAAQC,OACJgK,EAAaD,EACb,WAAM,MAAA,eAAeC,wCACbD,QAER+G,IAAiB/G,EACnB,QAAS,EAAGA,IAGd,IAAMO,KAEN,GAAkB,MAAdN,EAAoB,CAKtB,IADA,IAAIgH,EAAQ,EACLA,EAAQF,GAAgB/G,GAC7BO,EAAQ3H,MAAMqO,EAAOA,EAAQF,IAC7BE,GAASD,EAEX,OAAOzG,EAGT,IAAM2G,EAAWhP,KAAK+F,MAAM8I,EAAe,GACvCI,EAAOlH,EAAaiH,EAOxB,IANIC,EAAO,EACTA,EAAO,EACEA,EAAOJ,EAAe/G,IAC/BmH,EAAOnH,EAAgB+G,KAInBI,EAAOH,EAAY,GAAK/G,GAAckH,EAAOH,EAAYD,IAG7DI,GAAQH,EAGV,KAAOG,EAAOJ,GAAgB/G,KACxBC,EAAakH,IAGjB5G,EAAQ3H,MAAMuO,EAAMA,EAAOJ,IAC3BI,GAAQH,EAEV,OAAOzG,WAaO6G,EAA2BrH,GAEzC,OAAOpL,OAAQ,WACb,IAAMc,EAAYsK,EAAY9F,KAAKlB,OAASgH,EAAYhG,UAExD,OADUsN,WAAYtH,EAAY9F,MAAOxE,EAAWsK,EAAYhG,YACvDlF,MAAM,cAaHsL,EAA0BJ,GAExC,OAAOpL,OAAQ,WAAM,OAAAyS,EAA2BrH,GAAauH,eE18BzDjB,EAAU,QC4BHkB,EACT,4CACSC,EAAmB,0CAIrBC,GACTC,aAAgC,oBAAXtR,OAAyB,KAAOA,OAAOsR,cAY9D,iBAsDE,WACIC,EAAqBC,EACrBC,GA9CKrS,sBACL,oEAC4B6Q,EApBHyB,MAAM,KACfjP,MAAM,EAAG,GAAGkP,KAAK,oBAqBpBvS,oBAAiB,MACjBA,cAAW,KACXA,qCAAkC,EAQzCA,gBAAY,EAMdA,4BA6BNQ,OAAQC,OACmB,MAAvB2R,GAAgD,MAAjBC,GACJ,MAAvBD,GAAgD,MAAjBC,EACnC,WAAM,MAAA,yEAEiB,MAAvBD,GACgB,MAAdD,EACFA,EAAaK,EAAkCC,wBAE/CjS,OAAQC,QAEiB,IADrB+R,EAAkCE,uBAAuBhJ,QACrDyI,GACJ,WAAM,MAAA,6BAA6BA,QAEzCnS,KAAKmS,WAAaA,EAClBnS,KAAKoS,oBACEpS,KAAK2S,qBAAoB3S,KAAKmS,yBACrCnS,KAAKqS,cACErS,KAAK2S,qBAAoB3S,KAAKmS,8BAErC3R,OAAQC,OACU,MAAd0R,EACA,WAAM,MAAA,wEAEVnS,KAAKoS,oBAAsBA,EAC3BpS,KAAKqS,cAAgBA,GAGvBrS,KAAK4S,YACH1S,aAAcF,KAAK6S,eACnB1S,QAASH,KAAK8S,UAkepB,OAlcQN,mBAAN,SACIO,EACApT,gHACF,GAAIK,KAAKgT,UACP,MAAM,IAAIpT,MACN,2DAGN,SAAMI,KAAKiT,4BAwBX,GAxBA7T,SAEc,MAAVO,IACFA,MAEEuT,EAC+B,MAA/BvT,EAAOuT,qBAA+B,EAAIvT,EAAOuT,qBACjDvT,EAAOwT,mBAETD,EAAuB,GAEzB1S,OAAQC,OACJyS,GAAwB,GAAKA,GAAwB,EACrD,WAAM,MAAA,uCAAuCA,IAC7CE,EAC0C,MAA1CzT,EAAOyT,iCAEPzT,EAAOyT,gCACPzT,EAAOwT,mBAGTC,GAAkC,GAGhCzT,EAAOI,sBAAwB,EACjC,MAAM,IAAIH,MACN,yDACWD,EAAOI,uBAqExB,OAlEMO,EACsB,MAAxBX,EAAOW,cAAwB,GAAMX,EAAOW,cAChDE,OAAQC,OACJH,GAAiB,GAAKA,EAAgB,EACtC,WAAM,MAAA,sDACFA,IAEFT,EACF,SAAOb,EAAcwD,yHACjB6Q,EAActU,EAAUC,GAG1BW,EAAOwT,oBACHnT,KAAKsT,6DAAXC,SACA9R,gDAACmM,OAAG4F,oBAGJ5F,EAAI5N,KAAKyT,MAAMC,QAAQL,oBAGV,SAAMzF,EAAEnJ,eAEL,OAFZkP,EAASJ,aACTK,EAAiBhG,EAAEkE,QAAQ,IACMrN,sBAAjCoP,EAAYN,SAA6B,GACzCO,EAAWpR,KAAKC,UAALD,OAAYiR,IAC7B5P,WAAY6J,EAAGgG,EAAgBP,IAE3BS,EAAWZ,MACN,uBAEH3I,OAA+BoE,EAC/BhP,EAAOoU,4BAEK/U,EAAEyF,sBAAdrF,OAAMmU,SACNnU,YAAWY,KAAKgU,mBAAmB,GAFrCzJ,qBAmBF,OAbI0J,GAAe,EACdb,GH7JuB,uBG+JtBpT,KAAKkU,MAAML,IA9NE,cA+Nb7T,KAAKkU,MAAML,KACbI,GAAe,GAGfA,GACFlB,GAAUY,SAAQpJ,cAAaiJ,iBAI1BS,SAILlU,EAAwD,MAAhCJ,EAAOI,sBACjCC,KAAKmU,gCACLxU,EAAOI,sBACXC,KAAKoU,mBAAqB,IAAIrT,GAC5Bb,aAAcF,KAAK4S,WAAW1S,aAC9BJ,wBAAyBE,KAAKgU,mBAAmB,GACjD3T,qBAAsBL,KAAKgU,mBAAmB,GAC9CjU,wBACAF,sBACAS,qBAGIN,KAAKoU,mBAAmBC,MAAM1U,EAAOqB,sCAA3C5B,SAEAY,KAAKgT,WAAY,YAQbR,8BAAN,sHACE,OAAkB,MAAdxS,KAAKyT,aAIHzT,KAAKsU,sCAAXlV,SAGwC,iBAA7BY,KAAKoS,6BACAmC,kBAAmBvU,KAAKoS,oCAAtCqB,EAAQrU,sBAGA,SAAMmV,kBAAmBC,KAAMC,WACnCzU,KAAKoS,oBAAoBsC,cACzB1U,KAAKoS,oBAAoBuC,YACzB3U,KAAKoS,oBAAoBwC,qBAH7BnB,EAAQrU,0BAOV,GAA4B,IAAxBqU,EAAMoB,OAAOtR,OACf,MAAM,IAAI3D,MACN,wDACG6T,EAAMoB,OAAOtR,kBAEtB,GAAqC,IAAjCkQ,EAAMoB,OAAO,GAAGjQ,MAAMrB,OACxB,MAAM,IAAI3D,MACN,mFACkC6T,EAAMoB,OAAO,GAAGjQ,MAAMrB,QAE9D,GAAiC,IAA7BkQ,EAAMoB,OAAO,GAAGjQ,MAAM,GACxB,MAAM,IAAIhF,MACN,0FAEG6H,KAAKa,UAAUmL,EAAMoB,OAAO,GAAGjQ,MAAM,SAK9C,GAA2B,KADrBkQ,EAAcrB,EAAMqB,aACVvR,OACd,MAAM,IAAI3D,MACN,8EACsB6H,KAAKa,UAAUwM,IAE3C,GAAIA,EAAY,KAAO9U,KAAKkU,MAAM3Q,OAChC,MAAM,IAAI3D,MACN,gEACIkV,EAAY,6BACZ9U,KAAKkU,MAAM3Q,oBAGrBvD,KAAKyT,MAAQA,EACbzT,KAAK+U,cAEL/U,KAAKgU,mBACDP,EAAMoB,OAAO,GAAGjQ,MAAMvB,MAAM,GAChCrD,KAAKgV,mBAAqB,EAC1BvB,EAAMoB,OAAO,GAAGjQ,MAAMvB,MAAM,GAAGmB,QAC3B,SAAAyQ,GAAW,OAAAvU,EAAKsU,oBAAsBC,IAC1CjV,KAAKkV,cACC9U,EACFJ,KAAK4S,WAAWzS,QAAUH,KAAK4S,WAAW1S,aAAe,IACvDD,EAAYwT,EAAMoB,OAAO,GAAGjQ,MAAM,GACxC5E,KAAK4S,WAAWuC,0BAA4BlV,EAAYG,YAU1CoS,kDAAhB,2GACE,OAAqC,MAAjCxS,KAAKoV,gCAGHpV,KAAKiT,4BAIX,IAJA7T,SAISsF,EAAI1E,KAAKyT,MAAM4B,OAAO9R,OAAS,EAAGmB,GAAK,IAAKA,EACnD,GAA4C,UAAxC1E,KAAKyT,MAAM4B,OAAO3Q,GAAG4Q,eAA4B,CACnDC,EAAuBvV,KAAKyT,MAAM4B,OAAO3Q,GACzC,MAGJ,GAA4B,MAAxB6Q,EACF,MAAM,IAAI3V,MACN,wEAENI,KAAKoV,yBAA2BI,SAC9BX,OAAQ7U,KAAKyT,MAAMoB,OACnBY,SACEzV,KAAKyT,MAAMgC,QAAQ,GAAIF,EAAqBhM,oBAK1CiJ,wBAAR,WAAA,WACErT,OAAQ,WAEN,IADA,IAAMH,EAAI0W,SAAU,GAAGC,OAAOjV,EAAKsT,qBAC1BtP,EAAI,EAAGA,EAAI,IAAKA,EACvBhE,EAAK+S,MAAMC,QAAQ1U,MAKXwT,iCAAd,6GACE,OAAkB,MAAdxS,KAAKkU,UAI0C,iBAAvBlU,KAAKqS,gCNvXEuD,oHAE/BC,EAAc,UACdC,EAAe,WACfC,EAAc,UACa,IAA7BH,EAAIlM,QAAQmM,IAAoD,IAA9BD,EAAIlM,QAAQoM,YACzBE,MAAMJ,WACd,SADErC,SACa0C,eAC9B,SADe1C,wBAEuB,IAA7BqC,EAAIlM,QAAQqM,UAEfG,EAAKC,QAAQ,MACbC,EAAWC,YAAUH,EAAGE,UAEvB3U,GAAArC,EAAAqI,MAAKC,SACF0O,EAASR,EAAIvS,MAAM0S,EAAYxS,SAAU+S,SAAU,mBAD7D,SAAO7U,WACH8R,mBAEJ,MAAM,IAAI3T,MACN,2CAA2CgW,iFMsWrCW,CAAiBvW,KAAKqS,8BAA5BjT,EAAAqC,sBACArC,EAAAY,KAAKqS,+BAET,GAA+B,OAJzBmE,KAIWhG,WAAoB,CAMnC,GAAmB,OADbiG,EAAeD,EAA4B,OAE/C,MAAM,IAAI5W,MACN,mEAENI,KAAKkU,MAAQuC,OAEbzW,KAAKkU,MAAQsC,EAAahG,2BASxBgC,0BAAN,mGACE,IAAKxS,KAAKgT,UACR,MAAM,IAAIpT,MAAM,wDAElB,SAAMI,KAAKoU,mBAAmBhQ,sBAA9BhF,SACAY,KAAKgT,WAAY,YAMnBR,wBAAA,WACE,OAAOxS,KAAKgT,WAQdR,uBAAA,WACE,OAAOxS,KAAKkU,OAQd1B,mBAAA,WACE,OAAOxS,KAAK4S,YAQdJ,4BAAA,WACE,GAAkB,MAAdxS,KAAKyT,MACP,MAAM,IAAI7T,MACN,uGAGN,OAAOI,KAAKyT,MAAMoB,OAAO,GAAGjQ,OAqBxB4N,sBAAN,SAAgBkE,EAAgC/W,yHAM9C,OAJc,MAAVA,IACFA,SAGIK,KAAKiT,mCAAX0D,SAEa,MAATD,WAG4B1W,KAAK4W,0BAA7BC,EAAkBF,SACxBD,EAAQG,EAAgBpS,sBAM1B,GAAIiS,aAAiBI,SAEnB9W,KAAK+W,sBAAsBL,GAC3BM,EAAcN,EACdO,EAAcP,EAAM9R,MAAM,OACrB,CACL,GAAI8R,EAAMnT,OAASvD,KAAKgV,mBACtB,MAAM,IAAIpV,MACN,wCAAwC8W,EAAMnT,mGAETvD,KAAKgV,wBAGhDiC,EAAcP,EAAMnT,OAASvD,KAAKgV,mBAClCgC,EAAcE,WAAYR,GACxBO,GACAtB,OAAO3V,KAAKgU,4BAGVzK,GAAyCoK,OAAQ,MACnDhU,EAAOwT,oBAEHnT,KAAKsT,6DAAXqD,SACMQ,EACFnX,KAAKoV,yBAAyB1B,QAAQsD,GAC1CI,EAAYD,EAAgB,GAC5B5N,EAAOiK,UAAY2D,EAAgB,gBAEnCC,EAAYpX,KAAKyT,MAAMC,QAAQsD,2BAGb,IAAhBC,SACF7X,EAAAmK,KAAsB6N,EAAU3S,uBAAhCrF,EAAOuU,OAASgD,uBAIA,OAFVU,EAAYC,UAAWF,GACvBG,EAAgBF,EAAUvL,IAAI,SAAAE,GAAQ,OAAAA,EAAKvH,SACjDhD,EAAA8H,KAAsBiO,QAAQC,IAAIF,WAAlC9V,EAAOkS,OAASgD,SAChB5S,UAAWsT,6BAGT1X,EAAOoU,oBACTR,EAAAhK,OACSmN,aAAiBI,YAAkBJ,EAAMjS,sCAAZiT,EAAAf,wBAAqBe,EAAAhB,qBAD3DnD,EAAOhJ,aACLoN,SAEAA,YAAW3X,KAAKgU,mBAAmB,yBAKvC,OADAjQ,UAAWqT,MACJ7N,SAGKiJ,4BAAd,uFACE,SAAO,IAAIgF,QAAyB,SAACI,EAASC,GAW5CnX,EAAK0T,mBAAqB,IAAIrT,GAC5Bb,aAAcQ,EAAKkS,WAAW1S,aAC9BJ,wBAAyBY,EAAKsT,mBAAmB,GACjD3T,qBAAsBK,EAAKsT,mBAAmB,GAC9CjU,sBAAuB,EACvBF,oBAf+C,SAAOb,kGAEtD,OADMqU,EAActU,EAAUC,MACxBgB,KAAKoU,mBAAmBhQ,eAEtB,OAFRmP,SACAnU,EAAAwY,UACcvE,EAAY5O,eAI1B,OALArF,iBACEqC,OAAM8R,SACN9R,YAAWzB,KAAKgU,mBAAmB,QAErCX,EAAYyE,cACL,SAQPxX,cAAe,IAEjBI,EAAK0T,mBAAmBC,gBAI5B7B,2BAAA,SAAeuF,GACb,GAAkB,MAAd/X,KAAKyT,MACP,MAAM,IAAI7T,MACN,wGAGNY,OAAQC,OACI,MAARsX,GAAgC,iBAATA,GAAqBA,EAAKxU,OAAS,EAC1D,WAAM,MAAA,0FAC2BkE,KAAKa,UAAUyP,KACpDvX,OAAQC,OAC8B,MAAlCT,KAAKgY,oBAAoBD,GACzB,WAAM,MAAA,qDAAqDA,QAC/D,IAAME,EAAW,IAAIC,EACjBH,EAAM/X,KAAK4S,WAAY5S,KAAKyT,OAEhC,OADAzT,KAAKgY,oBAAoBD,GAAQE,EAC1BA,GAGCzF,wBAAV,uBACE,IAAoB,IAAA/Q,EAAAyH,EAAAlJ,KAAKyT,MAAM4B,sCAAQ,SAC/B8C,WAAY,sGAId3F,kCAAR,SAA8BkE,GAC5B,IAAM0B,EAAepY,KAAKyT,MAAMoB,OAAO,GAAGjQ,MAAMrB,OAChD,GAAImT,EAAM9R,MAAMrB,SAAW6U,EACzB,MAAM,IAAIxY,MACN,sCAAsCwY,oBACtB1B,EAAM9R,MAAMrB,yBAElC,IAAM8U,EAAkB3B,EAAM9R,MAAMvB,MAAM,GACpCiV,EAAwBtY,KAAKyT,MAAMoB,OAAO,GAAGjQ,MAAMvB,MAAM,GAC/D,IAAK7C,OAAQ+X,YAAYF,EAAiBC,GACxC,MAAM,IAAI1Y,MACN,sCAAsC0Y,4BACfD,QAjjBf7F,0BAAoC,MAAO,iBAC3CA,0BAA0B,yBAskB1C,WACauF,EAAuBnF,EACvB4F,GAFb,MAGEC,0BAFW/X,OAAAqX,EAAuBrX,aAAAkS,EACvBlS,YAAA8X,EAEXhY,OAAQC,OACI,MAARsX,GAAgC,iBAATA,GAAqBA,EAAKxU,OAAS,EAC1D,WAAM,MAAA,oEACSkE,KAAKa,UAAUyP,KAClCrX,EAAKsT,mBACDtT,EAAK8X,UAAU3D,OAAO,GAAGjQ,MAAMvB,MAAM,GACzC3C,EAAKwT,MAAQ,KACbxT,EAAKoI,QAAU,IAAIX,IA+tBvB,kIAvvBIuQ,MAqCIR,2BAAN,SAAqB/O,EAAcwP,uFAejC,GAbAnY,OAAQC,QACHT,KAAKgT,UACN,WAAM,MAAA,4IAGVxS,OAAQC,OACI,MAAR0I,GAAgC,iBAATA,GAAqBA,EAAK5F,OAAS,EAC1D,WAAM,MAAA,8EAGK,MAAXoV,IACFA,MAEgC,MAA9BA,EAAQC,oBAAqD,MAAvBD,EAAQE,YAChD,MAAM,IAAIjZ,MACN,sFA8CN,OAzC2B,MAAvB+Y,EAAQE,aACVrY,OAAQC,OACJkY,EAAQE,YAAc,EACtB,WACI,MAAA,2CAA2CF,EAAQE,cACrDC,EACF9Y,KAAK4S,WAAWzS,QAAUH,KAAK4S,WAAW1S,aAC9CJ,EACI4C,KAAKqW,KAAKJ,EAAQE,YAAcC,IACG,MAA9BH,EAAQC,oBACjBpY,OAAQC,OACJkY,EAAQC,oBAAsB,EAC9B,WAAM,MAAA,oDACSD,EAAQC,qBAC3B9Y,EACI4C,KAAKE,MAAM5C,KAAKgU,mBAAmB,GAAK2E,EAAQC,qBAEpD9Y,EAA0BE,KAAKgU,mBAAmB,GAGlB,MAA9B2E,EAAQK,qBACVxY,OAAQC,OACJkY,EAAQK,mBAAqB,EAC7B,WAAM,MAAA,qDACCL,EAAQK,qBACnBxY,OAAQC,OACiB,MAArBkY,EAAQM,UACR,WAAM,MAAA,mEAGa,MAArBN,EAAQM,WACVzY,OAAQC,OAC0B,MAA9BkY,EAAQK,mBACR,WAAM,MAAA,kEAGNE,EACFlZ,KAAK4S,WAAWzS,QAAUH,KAAK4S,WAAW1S,aACxCiZ,EAAmBD,EAAmBpZ,EAE5CE,KAAKgT,WAAY,KACV,IAAIwE,QAAyB,SAAAI,GAClC,IAAMwB,EAA2C,MAA9BT,EAAQK,mBACvB,EACAL,EAAQK,mBAAqBG,EAC3B7Y,EAAgB,EAAI8Y,EACpBC,EAAsB3W,KAAKE,MAAM,EAAIwW,GACvCE,EAAgB,EAChBC,GAAa,EACXC,KAwEN9Y,EAAK0T,mBAAqB,IAAIrT,GAC5Bb,aAAcQ,EAAKkS,WAAW1S,aAC9BJ,0BACAO,qBAAsBK,EAAKsT,mBAAmB,GAC9CjU,sBAAuB,EACvBF,oBA1EE,SAAOwC,EAAqBG,2IAEL,MAArBmW,EAAQM,iBACJ5F,EAActU,EAAUsD,GAC9BZ,GAAArC,EAAAY,KAAK8I,SAAQb,cACXI,MAAOc,WAEOkK,EAAY5O,uBAD1B8O,eACEoE,OAAM8B,SACN9B,YAAW3X,KAAKgU,mBAAmB,MAE3B2E,EAAQpY,yBACJiC,EAASiC,6BAArBkS,OAAM8C,SACN9C,eAAc3W,KAAKoU,mBAAmBlU,aAFJwX,iBAIAA,OAAA/I,mBAGtC,OAbAlN,YAME8R,kBAMFF,EAAYyE,aACN9X,KAAKoU,mBAAmBhQ,eAItB,OAJRqV,SACAzZ,KAAKgT,WAAY,EACjBhT,KAAK0Z,uBACLC,EAAA/B,UACcvV,EAASoC,sBADvBkV,iBACEC,OAAMH,SACNG,YAAW5Z,KAAKgU,mBAAmB,sBAGxB,SAAM3R,EAASoC,eAK5B,IALMA,EAAOgV,UACM,IAAfF,IACFA,EAAY9U,EAAKlB,QAEfmB,EAAI6U,EAAY,EACD,IAAZ9U,EAAKC,IAAYA,GAAK,GAC3BA,WAEImV,EAAYN,EAAY7U,EAAI,EAClC6U,EAAY7U,EAAI,EACVoV,EAAcrV,EAAKpB,MAAMoB,EAAKlB,OAASsW,EAAWpV,EAAKlB,QAC7DiW,EAAoBpW,KAAK0W,GAEA,MAArBnB,EAAQM,WACVN,EAAQM,WACHxU,KAAMqV,EAAavV,UAAWvE,KAAKgU,mBAAmB,KAGzDsF,MAAoBD,YAChBrZ,KAAKoU,mBAAmBhQ,sBAA9BqV,SACAzZ,KAAKgT,WAAY,EACjBhT,KAAK0Z,uBAECK,WNtsBoB/a,GACpC,GAAIA,EAAEuE,OAAS,EACb,MAAM,IAAI3D,MACN,+DAKN,OAHe,MAAXd,IACFA,EAAUG,YAAaC,WAElBC,OAAQ,WACP,IAAAC,2BAACC,SAAMC,aACP0a,EAAU3a,EAAK4a,YACfC,EAASxX,KAAKjD,KAAKH,EAAS2a,aAC5BE,EAAS9N,MAAM+N,KAAKpb,GAAG8M,IAAI,SAAA8B,GAAK,OAACA,EAAIoM,IAAYE,EAASpb,KAChE,OAAO,IAAIwD,aAAa6X,KMyrBGE,CACfzU,EAAyB4T,IACvBc,GACJ7V,KAAMsV,EACNxV,UAAWvE,KAAKgU,mBAAmB,IAErCuG,GAAAC,EAAAxa,KAAK8I,SAAQb,cACXI,MAAOc,EACPoB,YAAa+P,GACH3B,EAAQpY,yBACJiC,EAASiC,+BAArBgW,OAAMhB,SACNgB,eAAcza,KAAKoU,mBAAmBlU,aAFJwa,mBAIAA,OAAA/L,qBAPtC4L,YAGEI,kBAOF/C,EAAQ0C,sBAGZ,UAAO,SAQPha,gBACAC,gBAAiBoY,EAAQpY,kBAE3BG,EAAK0T,mBAAmBC,MAAMsE,EAAQ3X,+BAO1CkX,0BAAA,WAAA,WACE1X,OAAQC,OACU,MAAdT,KAAKkU,OAAiBlU,KAAKkU,MAAM3Q,OAAS,IAAMvD,KAAK8I,QAAQ2H,QAC7D,WACI,MAAA,sDAAsD/P,EAAKqX,OACnE/X,KAAK8I,QAAQ8R,QACb5a,KAAKkU,MAAQ,MAUfgE,0BAAA,WACE,GAAIlY,KAAK8I,QAAQ2H,QACf,MAAM,IAAI7Q,MACN,sEACUI,KAAK+X,eAErB,OAAO/X,KAAK8I,QAAQ+R,oBAStB3C,wBAAA,SAAY7P,GACV,OAAOrI,KAAK8I,QAAQM,YAAYf,IAIlC6P,oCAAA,SAAwB3P,EAAamC,GACnC1K,KAAK8I,QAAQgS,wBAAwBvS,EAAKmC,IAQ5CwN,0BAAA,SAAc3P,GACZvI,KAAK8I,QAAQiS,cAAcxS,GAC3BvI,KAAK0Z,wBAQPxB,2BAAA,WACE,OAAOlY,KAAK8I,QAAQ2H,SAUtByH,yBAAA,SAAanR,EAAyBiU,4BAAAA,MACpC,IAAMC,EAAkB,IAAI9S,EAAQpB,GAChCiU,GACFhb,KAAKkb,gBAGP,IAAMC,EAAgBF,EAAgBjS,oBACtC,IAAoB,IAAAoS,EAAAlS,EAAAiS,iCAAe,CAA9B,IAAM9S,UACHrB,EAAWiU,EAAgB7R,YAAYf,OAC7C,IAAsB,IAAAgB,YAAAH,EAAAlC,kCAAU,CAA3B,IAAMoB,UACTpI,KAAK8I,QAAQb,WAAWG,EAAQA,8MAIpCpI,KAAK0Z,wBAYPxB,8BAAA,SAAkB1H,GAChB,OAAOxQ,KAAK8I,QAAQuS,UAAU7K,IAQxB0H,iCAAR,WACElY,KAAKkU,MAAQlU,KAAK8I,QAAQE,iBAepBkP,yCAAR,SACIoD,EACAC,GAEF,IAAMtb,EAAYD,KAAKgU,mBAAmB,GAC1CsH,EAAiBA,GA/3BY,IAg4B7B,IAAM3R,EAAYjH,KAAKE,MAAM0Y,EAAiBrb,GACxCub,EAAMxb,KAAK8I,QAAQ2S,QACT,QAAOxb,YAAW0J,aAAc4R,IAEhD,OAAQ1V,GAAI2V,EAAI3V,GAAIqG,GAAIsP,EAAItP,KAoBtBgM,2CAAR,SACIoD,EAAyBI,EAAwBjQ,EACjD8P,gBADyBG,oBAAwBjQ,MAGnD,IAAMxL,EAAYD,KAAKgU,mBAAmB,GAC1CsH,EAAiBA,GA75BY,IA85B7B,IAAM3R,EAAYjH,KAAKE,MAAM0Y,EAAiBrb,GAC9C,OAAOD,KAAK8I,QAAQ2S,QAAQ,QAC1Bxb,YACA0J,YACAwB,YAAY,EACZO,iBAAkBD,EAClBG,uBAAwB8P,GACrBH,KAqBDrD,kBAAN,SAAYvY,iFA+CV,OA7CAa,OAAQC,OACU,MAAdT,KAAKkU,OAAiBlU,KAAKkU,MAAM3Q,OAAS,EAC1C,WACI,MAAA,yCAAyC7C,EAAKqX,oEAEtDvX,OAAQC,OACJT,KAAKkU,MAAM3Q,OAAS,EACpB,WAAM,MAAA,yCACI7C,EAAKqX,sCACOtQ,KAAKa,UAAU5H,EAAKwT,6EAEf,MAA3BvU,EAAOgc,kBACTnb,OAAQC,OACJd,EAAOgc,kBAAoB,GACvB7R,OAAOC,UAAUpK,EAAOgc,kBAC5B,WAAM,MAAA,+EACuBhc,EAAOgc,mBAG5B,MAAVhc,IACFA,MAGgB,MAAdK,KAAKyT,OACPzT,KAAK4b,mCAMP5b,KAAK6b,yBAAyB1D,WAAY,EAG1CnY,KAAKyT,MAAMqI,SACTC,KAAM,0BACNC,UAAWrc,EAAOqc,WAAa,MAC/BC,SAAU,SAKNC,EAC0C,MAA5Cvc,EAAOwc,kCACP,IACAxc,EAAOwc,kCACPnc,KAAK8I,QAAQsT,iBAAmBF,GAClCta,QAAQ8N,IACJ,4CACG1P,KAAK8I,QAAQsT,0BACbF,yEAEAlc,KAAKqc,eAAe1c,QAEpBK,KAAKsc,eAAe3c,SAKjBuY,2BAAd,SAA6BvY,iHAWX,OAThBa,OAAQC,OAAOd,EAAO4c,OAAS,EAAG,WAAM,MAAA,0BAGlC9Q,EAAgC,MAApB9L,EAAO8L,UAAoB,GAAK9L,EAAO8L,UACnD6P,EAAiB3b,EAAO2b,gBA5/BD,IA6/BvBlc,EAAAod,EAA6Bxc,KAAKyc,+BACpCnB,EAAgB3b,EAAO+b,gBAAiBjQ,GACvCH,0BAA2B3L,EAAO2L,+BAFhCyC,OAAcM,OAGfqO,EAAKlc,OAAQmc,SACG3c,KAAKyT,MAAMmJ,WAAW7O,GAC1CwO,OAAQ5c,EAAO4c,OACfM,eAAgBld,EAAO+b,gBAAkB,EAAIrN,EAAa,KAC1DyO,UAA8B,MAAnBnd,EAAOoT,SAAmB,MAAQpT,EAAOoT,2BAHhDgK,EAAUtb,SAKhBG,QAAQ8N,IAAI,sBAAsBlP,OAAQmc,MAAQD,GAAIM,QAAQ,UAE/B,MAA3Brd,EAAOgc,kBAA4Bhc,EAAOgc,iBAAmB,GAEzDsB,EAAKzc,OAAQmc,SACa3c,KAAKkd,0BACjCvd,EAAQoO,EAAcM,kBAI1B,OALM8O,EAAoB1b,SAE1BG,QAAQ8N,IACJ,oCACIlP,OAAQmc,MAAQM,GAAID,QAAQ,cAC5BD,EAASI,WAEjB,SAAOJ,SAKG7E,2BAAd,SAA6BvY,mHAGrB2b,EAAiB3b,EAAO2b,gBA1hCD,IA2hCvBlc,EAAWY,KAAKod,6BAClB9B,GACChQ,0BAA2B3L,EAAO2L,4BAFhCzF,OAAIqG,OAGXtK,QAAQ8N,IACJ,6BAA6B7J,EAAGjB,sBAAqBsH,EAAGtH,wBAmB1C,6BAVc,MAA1BjF,EAAO+b,iBACH2B,WFnjCVxX,EAAeqG,EAAeC,GAWhC,OALA3L,OAAQC,OACJ0L,EAAW,GAAKA,EAAW,EAC3B,WAAM,MAAA,wDACSA,IAEZhN,OAAQ,WAIb,IAHA,IAAMoN,EAAeL,EAAG4F,QAAQ,GAAGlH,WAE7B4B,KACG9H,EAAI,EAAGA,EAAI6H,EAAahJ,SAAUmB,EAAG,CAC5C,IAAM+H,EAAaF,EAAa7H,GACI,MAAhC8H,EAAiBC,KACnBD,EAAiBC,OAEnBD,EAAiBC,GAAYrJ,KAAKsB,GAEpC,IAAMgI,EAAaF,EAAiBjJ,OAE9BoJ,KACAC,KAIN,IADAJ,EAAiBV,IAAI,SAAAS,GAAgB,OAAA/L,OAAQgL,QAAQe,KAC5C7H,EAAI,EAAGA,EAAIgI,IAAchI,EAGhC,IAFA,IAAM4Y,EAAe9Q,EAAiB9H,GAChCoI,EAASpK,KAAKE,MAAM0a,EAAa/Z,QAAU,EAAI4I,IAC5CY,EAAI,EAAGA,EAAIuQ,EAAa/Z,SAAUwJ,EACrCA,EAAID,EACNH,EAAavJ,KAAKka,EAAavQ,IAE/BH,EAAWxJ,KAAKka,EAAavQ,IASnC,OAAQC,QAJQuQ,SAAU1X,EAAI8G,GAIbM,QAHDsQ,SAAUrR,EAAIS,GAGJO,MAFZqQ,SAAU1X,EAAI+G,GAEKO,MADnBoQ,SAAUrR,EAAIU,MEugCT4Q,CAAsB3X,EAAIqG,EAAIvM,EAAO+b,iBACpD1O,EAAUqQ,EAAOrQ,QACjBC,EAAUoQ,EAAOpQ,QACjBwQ,GAAWJ,EAAOnQ,MAAOmQ,EAAOlQ,SAEhCH,EAAUnH,EACVoH,EAAUf,MAGUlM,KAAKyT,MAAMiK,IAAI1Q,EAASC,GAC5CsP,OAAyB,MAAjB5c,EAAO4c,OAAiB,GAAK5c,EAAO4c,OAC5CM,eAAgBY,EAChBhS,UAAW9L,EAAO8L,UAClBqR,UAA8B,MAAnBnd,EAAOoT,SAAmB,MAAQpT,EAAOoT,2BAJhD4K,EAAUlc,SAOe,MAA3B9B,EAAOgc,kBAA4Bhc,EAAOgc,iBAAmB,KAG/B3b,KAAK4d,uBACjCje,EAAQqN,EAASC,EAASwQ,iBAC9B,OAFMN,EAAoB1b,aAElBkc,EAASR,WAEjB,SAAOQ,oCAGT5Z,WAAY8B,EAAIqG,EAAIc,EAASC,EAASwQ,+BAI5BvF,sCAAd,SACIvY,EAA6BoO,EAC7BM,qGAawB,OAZpBwP,EAAyB7d,KAAK6b,yBAAyB1D,UAC7DnY,KAAK6b,yBAAyB1D,WAAY,EAGpC2F,EAC4B,MAA9Bne,EAAOme,oBAA8B,MAAQne,EAAOme,oBACxD9d,KAAKyT,MAAMqI,SACTC,KAAM,0BACNC,UAAW8B,EACX7B,SAAU,YAGoBjc,KAAKyT,MAAMmJ,WAAW7O,GACpDwO,OAAQ5c,EAAOgc,iBACfkB,eAAgBxO,EAChByO,UAA8B,MAAnBnd,EAAOoT,SAAmB,MAAQpT,EAAOoT,oBAKtD,OARMoK,EAAoB/d,SAO1BY,KAAK6b,yBAAyB1D,UAAY0F,KACnCV,SAGKjF,mCAAd,SACIvY,EAA6BqN,EAAoBC,EACjDwQ,qGAawB,OAZpBI,EAAyB7d,KAAK6b,yBAAyB1D,UAC7DnY,KAAK6b,yBAAyB1D,WAAY,EAGpC2F,EAC4B,MAA9Bne,EAAOme,oBAA8B,MAAQne,EAAOme,oBACxD9d,KAAKyT,MAAMqI,SACTC,KAAM,0BACNC,UAAW8B,EACX7B,SAAU,YAGoBjc,KAAKyT,MAAMiK,IAAI1Q,EAASC,GACtDsP,OAAQ5c,EAAOgc,iBACfkB,eAAgBY,EAChBhS,UAAW9L,EAAO8L,UAClBqR,UAAwC,MAA7Bnd,EAAOoe,mBAA6B,MACCpe,EAAOoe,8BAKzD,OAVMZ,EAAoB/d,SAS1BY,KAAK6b,yBAAyB1D,UAAY0F,KACnCV,SAUHjF,qBAAN,SAAevY,iFAab,OAZAa,OAAQC,OACyB,MAA7Bd,EAAOqe,oBACHre,EAAOqe,mBAAmBza,OAAS,EACvC,WAAM,MAAA,8CAGJ0a,EAAoB,EAC1Bzd,OAAQC,OHpmCwB,uBGqmC5BT,KAAKkU,MAAM+J,GACX,WAAM,MAAA,8EAGH9e,OAAQ,WAeb,IAdA,IAAM+e,KACFC,EAAM,EACJ/e,mDAACyG,OACDuY,OAAatM,QAAQ,GAAGlH,WACxByT,EAAQ3d,EAAK+S,MAAMC,QAAQ7N,GAK3ByY,EACFD,EAAMhb,OAAO,EAAG,IAAKgb,EAAMzZ,MAAM,GAAIyZ,EAAMzZ,MAAM,GAAK,IAAIjC,KAAK,GAC7D4b,EAAQF,EAAMzZ,MAAM,GAGjBF,EAAI,EAAGA,EAAI/E,EAAOqe,mBAAmBza,SAAUmB,EAAG,CASzD,IARA,IAAM8Z,EAAgB7e,EAAOqe,mBAAmBtZ,GAC1C+Z,EACFH,EAAaI,QAAQC,SAAUH,IAAgB5T,WAE/CgU,EAAY,EACZC,EAAY,EACZC,EAAiB,EACjBC,EAAgB,EACXC,EAAI,EAAGA,EAAIT,IAASS,EACvBZ,EAAQY,KAAOf,GACjBW,IACIH,EAAOO,IACTF,MAGFD,IACIJ,EAAOO,IACTD,KAMN,IAAME,EAAMH,EAAiBF,EACvBM,EAAMH,EAAgBF,EAE5BX,EAAS9a,MAAMob,gBAAeS,MAAKC,QACnCtd,QAAQ8N,IACJ,cAAc8O,WACPS,EAAIjC,QAAQ,YAAWkC,EAAIlC,QAAQ,IAE1CtY,EAAI,IAENyZ,GAAOzb,KAAKyc,IAAKjB,EAASxZ,EAAI,GAAGua,IAAMf,EAASxZ,GAAGua,MAC9Cf,EAASxZ,EAAI,GAAGwa,IAAMhB,EAASxZ,GAAGwa,KAAO,GAGlD,OAAQhB,WAAUC,eAUdjG,6CAAR,WAAA,WACE1X,OAAQC,OACU,MAAdT,KAAKkU,MACL,WACI,MAAA,mEACAxT,EAAKqX,OAKb,IAFA,IAAM1C,EAASrV,KAAKwY,UAAUnD,OAC1B+J,EAAa/J,EAAO9R,OAAS,EAC1B6b,GAAc,GACqC,UAApD/J,EAAO+J,GAAY9J,eAAe+J,eAGtCD,IAEF,GAAIA,EAAa,EACf,MAAM,IAAIxf,MAAM,uDAElBI,KAAK6b,yBAA2BxG,EAAO+J,GACvC,IAAME,EACFtf,KAAK6b,yBAAyBtS,OAElCvJ,KAAKuf,aAAeC,eACpBxf,KAAKuf,aAAa7f,IAAI+f,SAAUC,OAC9BC,MAAO3f,KAAKkU,MAAM3Q,OAClBqc,WAAY,UACZC,WAAYP,EAAoB1a,MAAMvB,MAAM,GAC5C0U,KAAM,kBAER,IAAM+H,EACF9f,KAAKuf,aAAaQ,MAAMT,GAC5Btf,KAAKyT,MACD+B,SAAUX,OAAQ7U,KAAKwY,UAAU3D,OAAQY,QAASqK,KAQxD5H,4BAAA,WACE,OAAOlY,KAAKwY,UAAU3D,OAAO,GAAGjQ,OAGlCsT,wBAAA,WACE,OACE8H,0BAA2BnP,EAC3BoP,UAAWjgB,KAAK+X,KAChBmI,WAAW,IAAIC,MAAOC,cACtB5P,WAAYxQ,KAAKwQ,eAIf0H,iBAAN,SAAWmI,8EAeT,OAdMC,EAA+B,MAAhBD,EACrBA,EAAeA,GAAgBE,EAAqBvgB,KAAK+X,MAEpDuI,IAEGE,EACFvO,EAAoBC,aAAauO,QAAQ1O,IACvC2O,EACgB,MAAlBF,KAA8B/Y,KAAKC,MAAM8Y,IACjCxgB,KAAK+X,MAAQ/X,KAAK2gB,cAC9B1O,EAAoBC,aAAa0O,QAC7B7O,EAA0BtK,KAAKa,UAAUoY,KAE/C9e,QAAQ8N,IAAI,mBAAmB2Q,MACxBrgB,KAAKyT,MAAMoN,KAAKR,SAGnBnI,iBAAN,SAAWmI,qGAIT,GAHMC,EAA+B,MAAhBD,EACrBA,EAAeA,GAAgBE,EAAqBvgB,KAAK+X,OAEpDuI,EAAc,CAIjB,GAAmB,OAFbI,EAAcjZ,KAAKC,MACrBuK,EAAoBC,aAAauO,QAAQ1O,MACQ,MAA1B2O,EAAY1gB,KAAK+X,MAC1C,MAAM,IAAInY,MACN,iDAAiDI,KAAK+X,UAE5D/X,KAAKkU,MAAQwM,EAAY1gB,KAAK+X,MAAMvH,WACpC5O,QAAQ8N,IACJ,oCAAoC1P,KAAK+X,UAAS/X,KAAKkU,OAEhD,OAAb9U,EAAAY,QAAmBuU,kBAAmB8L,kBAAtCjhB,EAAKqU,MAAQhS,SACbG,QAAQ8N,IAAI,qBAAqB2Q,OACjCrgB,KAAKyT,MAAMqN,oBASb5I,2BAAA,SAAeH,GACb,MAAM,IAAInY,MACN,iGApvBJ4S,GAyvBJ,SAAS+N,EAAqBxI,GAC5B,MAAO,GAAG/F,EAAmB+F,MC/xCzBgJ,GACJnb,2BACAob,sBPgCE7P,EAAwB8P,GAC1B,IAGMvf,EAA6B,IAD9Bd,OAAeC,cAAiBD,OAAeE,oBAE9CogB,EACFxf,EAAayf,aAAa,EAAGhQ,EAAS1M,KAAKlB,OAAQ4N,EAASjR,cAC3CghB,EAAYE,eAAe,GACnCzc,IAAIwM,EAAS1M,MAC1B,IAAM4c,EAAS3f,EAAa4f,qBAC5BD,EAAO9b,OAAS2b,EAChBG,EAAOlf,QAAQT,EAAa6f,aAC5BF,EAAOhN,QACPgN,EAAOG,QAAU,WACA,MAAXP,GACFA,yBO5EFQ,EAAmBtP,EACnBuP,EACAC,GAcF,GAZAnhB,OAAQC,OACyB,MAA7BihB,GAA4D,MAAvBC,GACJ,MAA7BD,GAA4D,MAAvBC,EACzC,WAAM,MAAA,qFAEuB,MAA7BD,GACFlhB,OAAQC,OACU,MAAd0R,EACA,WAAM,MAAA,yEAII,gBAAZsP,EACF,OAAO,IAAIjP,EACPL,EAAYuP,EAA2BC,GACtC,KAAgB,aAAZF,EACH,IAAI7hB,MACN,kEAEE,IAAIA,MAAM,qBAAqB6hB,yCJgBL,kIG4yCW1J,iGAY7C,OARmB,OAFf2I,EAAcjZ,KAAKC,MACnBuK,EAAoBC,aAAauO,QAAQ1O,OAE3C2O,MAEuB,MAArBA,EAAY3I,WACP2I,EAAY3I,GAErB9F,EAAoBC,aAAa0O,QAC7B7O,EAA0BtK,KAAKa,UAAUoY,OACvClM,KAAMoN,YAAYrB,EAAqBxI,mBAA7C3Y,0JA3Be,SAAMoV,KAAMqN,qBAE3B,IAAWxR,KAFLyR,EAAS1iB,SACT+Q,KACY2R,EACZzR,EAAI0R,WAAW/P,IACjB7B,EAAK/M,KAAKiN,EAAIhN,MAAM2O,EAAiBzO,SAGzC,SAAO4M,uBAn2CkB"}